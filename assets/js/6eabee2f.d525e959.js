"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[135],{8453(n,e,i){i.d(e,{R:()=>t,x:()=>l});var r=i(6540);const s={},o=r.createContext(s);function t(n){const e=r.useContext(o);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:t(n.components),r.createElement(o.Provider,{value:e},n.children)}},9102(n,e,i){i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"chapters/chapter-05-ros2-for-humanoid-robots","title":"Chapter 5: ROS 2 for Humanoid Robots","description":"Learning Objectives","source":"@site/docs/chapters/chapter-05-ros2-for-humanoid-robots.md","sourceDirName":"chapters","slug":"/chapters/chapter-05-ros2-for-humanoid-robots","permalink":"/Physical-AI-Humanoid-Robotics/chapters/chapter-05-ros2-for-humanoid-robots","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"weeklySidebar","previous":{"title":"Chapter 4: Building with ROS 2","permalink":"/Physical-AI-Humanoid-Robotics/chapters/chapter-04-building-with-ros2"},"next":{"title":"Chapter 6: Physics Simulation with Gazebo","permalink":"/Physical-AI-Humanoid-Robotics/chapters/chapter-06-physics-simulation-with-gazebo"}}');var s=i(4848),o=i(8453);const t={},l="Chapter 5: ROS 2 for Humanoid Robots",a={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"URDF: Unified Robot Description Format",id:"urdf-unified-robot-description-format",level:2},{value:"What is URDF?",id:"what-is-urdf",level:3},{value:"URDF Structure",id:"urdf-structure",level:3},{value:"Joint Types",id:"joint-types",level:3},{value:"Visual vs. Collision Geometry",id:"visual-vs-collision-geometry",level:3},{value:"Inertial Properties",id:"inertial-properties",level:3},{value:"Xacro: Programmable URDF",id:"xacro-programmable-urdf",level:3},{value:"URDF Best Practices",id:"urdf-best-practices",level:3},{value:"Kinematic Chains and Joint Hierarchies",id:"kinematic-chains-and-joint-hierarchies",level:2},{value:"Understanding Kinematic Chains",id:"understanding-kinematic-chains",level:3},{value:"Joint Hierarchy Representation",id:"joint-hierarchy-representation",level:3},{value:"Forward Kinematics",id:"forward-kinematics",level:3},{value:"Inverse Kinematics",id:"inverse-kinematics",level:3},{value:"Jacobian and Differential Kinematics",id:"jacobian-and-differential-kinematics",level:3},{value:"tf2: Transform System",id:"tf2-transform-system",level:2},{value:"Why Transform Management Matters",id:"why-transform-management-matters",level:3},{value:"tf2 Architecture",id:"tf2-architecture",level:3},{value:"Static vs. Dynamic Transforms",id:"static-vs-dynamic-transforms",level:3},{value:"Common Frame Conventions",id:"common-frame-conventions",level:3},{value:"Transform Broadcasting",id:"transform-broadcasting",level:3},{value:"Transform Listening",id:"transform-listening",level:3},{value:"Transform Tree Example",id:"transform-tree-example",level:3},{value:"Time Synchronization",id:"time-synchronization",level:3},{value:"robot_state_publisher and joint_state_publisher",id:"robot_state_publisher-and-joint_state_publisher",level:2},{value:"robot_state_publisher",id:"robot_state_publisher",level:3},{value:"joint_state_publisher",id:"joint_state_publisher",level:3},{value:"Joint State Message",id:"joint-state-message",level:3},{value:"Workflow: URDF to Visualization",id:"workflow-urdf-to-visualization",level:3},{value:"Controller Interfaces and ros2_control",id:"controller-interfaces-and-ros2_control",level:2},{value:"What is ros2_control?",id:"what-is-ros2_control",level:3},{value:"ros2_control Architecture",id:"ros2_control-architecture",level:3},{value:"Hardware Interface Concepts",id:"hardware-interface-concepts",level:3},{value:"Common Controllers",id:"common-controllers",level:3},{value:"Controller Manager",id:"controller-manager",level:3},{value:"Real-Time Considerations",id:"real-time-considerations",level:3},{value:"Bridging AI Agents to ROS Controllers",id:"bridging-ai-agents-to-ros-controllers",level:2},{value:"The AI-to-Robot Control Gap",id:"the-ai-to-robot-control-gap",level:3},{value:"Hierarchical Control Architecture",id:"hierarchical-control-architecture",level:3},{value:"Interface Patterns",id:"interface-patterns",level:3},{value:"Example: LLM-Controlled Humanoid",id:"example-llm-controlled-humanoid",level:3},{value:"Learned Policy Integration",id:"learned-policy-integration",level:3},{value:"RViz2: Visualization and Debugging",id:"rviz2-visualization-and-debugging",level:2},{value:"What is RViz2?",id:"what-is-rviz2",level:3},{value:"RViz2 Architecture",id:"rviz2-architecture",level:3},{value:"Visualizing the Robot",id:"visualizing-the-robot",level:3},{value:"Visualizing Sensor Data",id:"visualizing-sensor-data",level:3},{value:"Visualizing Coordinate Frames",id:"visualizing-coordinate-frames",level:3},{value:"Debugging with Markers",id:"debugging-with-markers",level:3},{value:"RViz2 for Humanoid Development",id:"rviz2-for-humanoid-development",level:3},{value:"RViz2 vs. Simulation",id:"rviz2-vs-simulation",level:3},{value:"Conceptual Diagrams",id:"conceptual-diagrams",level:2},{value:"Diagram 1: URDF Structure",id:"diagram-1-urdf-structure",level:3},{value:"Diagram 2: Kinematic Chain",id:"diagram-2-kinematic-chain",level:3},{value:"Diagram 3: tf2 Transform Tree",id:"diagram-3-tf2-transform-tree",level:3},{value:"Diagram 4: ros2_control Architecture",id:"diagram-4-ros2_control-architecture",level:3},{value:"Diagram 5: AI-to-Control Architecture",id:"diagram-5-ai-to-control-architecture",level:3},{value:"Key Concepts Summary",id:"key-concepts-summary",level:2},{value:"URDF (Unified Robot Description Format)",id:"urdf-unified-robot-description-format-1",level:3},{value:"Kinematic Chain",id:"kinematic-chain",level:3},{value:"Forward Kinematics",id:"forward-kinematics-1",level:3},{value:"Inverse Kinematics",id:"inverse-kinematics-1",level:3},{value:"tf2",id:"tf2",level:3},{value:"robot_state_publisher",id:"robot_state_publisher-1",level:3},{value:"ros2_control",id:"ros2_control",level:3},{value:"Hardware Interface",id:"hardware-interface",level:3},{value:"Controller",id:"controller",level:3},{value:"RViz2",id:"rviz2",level:3},{value:"Knowledge Checkpoint",id:"knowledge-checkpoint",level:2},{value:"Chapter Summary",id:"chapter-summary",level:2},{value:"Further Reading",id:"further-reading",level:2},{value:"Looking Ahead",id:"looking-ahead",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"chapter-5-ros-2-for-humanoid-robots",children:"Chapter 5: ROS 2 for Humanoid Robots"})}),"\n",(0,s.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Understand URDF (Unified Robot Description Format) and how it represents robot structure"}),"\n",(0,s.jsx)(e.li,{children:"Analyze kinematic chains and joint hierarchies in humanoid robots"}),"\n",(0,s.jsx)(e.li,{children:"Explain the tf2 transform system and coordinate frame management"}),"\n",(0,s.jsx)(e.li,{children:"Describe the roles of robot_state_publisher and joint_state_publisher"}),"\n",(0,s.jsx)(e.li,{children:"Understand controller interfaces and the ros2_control framework"}),"\n",(0,s.jsx)(e.li,{children:"Design architectures for bridging AI agents to robot controllers"}),"\n",(0,s.jsx)(e.li,{children:"Utilize RViz2 for visualization and debugging humanoid systems"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(e.p,{children:"Humanoid robots present unique challenges compared to simpler robotic systems. A humanoid has 20-30+ joints arranged in kinematic chains (legs, arms, torso, head), each joint requiring coordinated control. The robot's structure must be described precisely for physics simulation, collision checking, and motion planning. Coordinate frames must be managed for sensors, end effectors, and the environment. AI systems must translate high-level intentions into low-level motor commands."}),"\n",(0,s.jsx)(e.p,{children:"ROS 2 provides specialized tools for humanoid robotics: URDF for describing robot geometry and kinematics, tf2 for managing coordinate transformations, ros2_control for hardware abstraction and controller management, and RViz2 for visualization. This chapter explores these humanoid-specific tools and patterns, building on the ROS 2 foundations from previous chapters."}),"\n",(0,s.jsx)(e.h2,{id:"urdf-unified-robot-description-format",children:"URDF: Unified Robot Description Format"}),"\n",(0,s.jsx)(e.h3,{id:"what-is-urdf",children:"What is URDF?"}),"\n",(0,s.jsx)(e.p,{children:"URDF is an XML format for describing robot structure. A URDF file defines:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Links:"})," Rigid bodies (bones in humanoid analogy). Each link has:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Visual geometry (for visualization)"}),"\n",(0,s.jsx)(e.li,{children:"Collision geometry (for collision checking)"}),"\n",(0,s.jsx)(e.li,{children:"Inertial properties (mass, center of mass, inertia tensor)"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Joints:"})," Connections between links (like biological joints). Each joint has:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Type (revolute, prismatic, fixed, continuous, planar, floating)"}),"\n",(0,s.jsx)(e.li,{children:"Parent and child links"}),"\n",(0,s.jsx)(e.li,{children:"Axis of rotation/translation"}),"\n",(0,s.jsx)(e.li,{children:"Limits (position, velocity, effort)"}),"\n",(0,s.jsx)(e.li,{children:"Dynamics (damping, friction)"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Sensors:"})," Cameras, LiDAR, IMU specifications and mounting locations"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Actuators:"})," Motor specifications (for simulation)"]}),"\n",(0,s.jsx)(e.p,{children:"The URDF provides a complete geometric and kinematic description that physics simulators, motion planners, and visualization tools can interpret."}),"\n",(0,s.jsx)(e.h3,{id:"urdf-structure",children:"URDF Structure"}),"\n",(0,s.jsx)(e.p,{children:"A simple URDF snippet for a joint and links:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<robot name="humanoid">\n  \x3c!-- Base link (torso) --\x3e\n  <link name="torso">\n    <visual>\n      <geometry>\n        <box size="0.3 0.2 0.4"/>\n      </geometry>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.3 0.2 0.4"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="15.0"/>\n      <inertia ixx="1.0" ixy="0.0" ixz="0.0" iyy="1.0" iyz="0.0" izz="1.0"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Shoulder joint --\x3e\n  <joint name="right_shoulder_pitch" type="revolute">\n    <parent link="torso"/>\n    <child link="upper_arm_right"/>\n    <origin xyz="0.15 0 0.15" rpy="0 0 0"/>\n    <axis xyz="0 1 0"/>\n    <limit lower="-1.57" upper="1.57" effort="100" velocity="2.0"/>\n    <dynamics damping="0.5" friction="0.1"/>\n  </joint>\n\n  \x3c!-- Upper arm link --\x3e\n  <link name="upper_arm_right">\n    <visual>\n      <geometry>\n        <cylinder length="0.3" radius="0.05"/>\n      </geometry>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder length="0.3" radius="0.05"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="2.0"/>\n      <inertia ixx="0.1" ixy="0.0" ixz="0.0" iyy="0.1" iyz="0.0" izz="0.01"/>\n    </inertial>\n  </link>\n</robot>\n'})}),"\n",(0,s.jsx)(e.p,{children:"This defines a torso link, a revolute shoulder joint, and an upper arm link. The joint connects torso (parent) to upper arm (child), rotates around the Y-axis, and has position and torque limits."}),"\n",(0,s.jsx)(e.h3,{id:"joint-types",children:"Joint Types"}),"\n",(0,s.jsx)(e.p,{children:"URDF supports several joint types:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Revolute:"})," Rotates around an axis with limits (e.g., elbow, knee)"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Range: limited (e.g., -90\xb0 to +90\xb0)"}),"\n",(0,s.jsx)(e.li,{children:"Use: Most humanoid joints"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Continuous:"})," Rotates around an axis without limits (e.g., wheel)"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Range: unlimited"}),"\n",(0,s.jsx)(e.li,{children:"Use: Rare in humanoids (perhaps head yaw in some designs)"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Prismatic:"})," Translates along an axis (e.g., linear actuator)"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Range: limited linear motion"}),"\n",(0,s.jsx)(e.li,{children:"Use: Telescoping mechanisms, grippers"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Fixed:"})," No motion (rigid connection)"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Use: Connecting sensor mounts, cosmetic parts"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Planar:"})," Moves in a plane"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Use: Specialized mechanisms"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Floating:"})," Six degrees of freedom (3 translation, 3 rotation)"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Use: Base of mobile robot relative to world frame"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Humanoid joints are predominantly revolute (shoulders, elbows, hips, knees, ankles), with fixed joints for sensor mounts and floating joints for the base."}),"\n",(0,s.jsx)(e.h3,{id:"visual-vs-collision-geometry",children:"Visual vs. Collision Geometry"}),"\n",(0,s.jsx)(e.p,{children:"URDF separates visual and collision geometry for efficiency:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Visual Geometry:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"High-detail meshes for realistic visualization"}),"\n",(0,s.jsx)(e.li,{children:"Complex textures and colors"}),"\n",(0,s.jsx)(e.li,{children:"Computationally expensive for collision checking"}),"\n",(0,s.jsx)(e.li,{children:"Example: Detailed humanoid skin mesh"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Collision Geometry:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Simplified shapes (boxes, cylinders, spheres)"}),"\n",(0,s.jsx)(e.li,{children:"Approximate the link's envelope"}),"\n",(0,s.jsx)(e.li,{children:"Fast collision checking"}),"\n",(0,s.jsx)(e.li,{children:"Example: Cylinder approximating arm"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"This separation allows beautiful visualization while maintaining real-time collision detection performance."}),"\n",(0,s.jsx)(e.h3,{id:"inertial-properties",children:"Inertial Properties"}),"\n",(0,s.jsx)(e.p,{children:"Accurate inertial properties are critical for physics simulation:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Mass:"})," Total mass of the link (kilograms)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Center of Mass:"})," Point around which mass is distributed (relative to link frame)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Inertia Tensor:"})," 3x3 matrix describing resistance to rotation"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Diagonal elements (Ixx, Iyy, Izz): moments of inertia around principal axes"}),"\n",(0,s.jsx)(e.li,{children:"Off-diagonal elements (Ixy, Ixz, Iyz): products of inertia"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Inaccurate inertial properties cause unrealistic simulation behavior\u2014robots that collapse, spin uncontrollably, or float. For real humanoid robots, inertial properties should match physical measurements."}),"\n",(0,s.jsx)(e.h3,{id:"xacro-programmable-urdf",children:"Xacro: Programmable URDF"}),"\n",(0,s.jsx)(e.p,{children:"Raw URDF is verbose and repetitive. Xacro (XML Macros) adds programming constructs:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Variables:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<xacro:property name="arm_length" value="0.3"/>\n<cylinder length="${arm_length}" radius="0.05"/>\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Macros:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<xacro:macro name="arm" params="prefix">\n  <link name="${prefix}_upper_arm">...</link>\n  <joint name="${prefix}_shoulder">...</joint>\n  <link name="${prefix}_forearm">...</link>\n  <joint name="${prefix}_elbow">...</joint>\n</xacro:macro>\n\n\x3c!-- Instantiate for both arms --\x3e\n<xacro:arm prefix="left"/>\n<xacro:arm prefix="right"/>\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Includes:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<xacro:include filename="common_materials.xacro"/>\n<xacro:include filename="sensors.xacro"/>\n'})}),"\n",(0,s.jsx)(e.p,{children:"Xacro reduces duplication, especially for symmetric humanoids (left/right arms and legs identical)."}),"\n",(0,s.jsx)(e.h3,{id:"urdf-best-practices",children:"URDF Best Practices"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Modular Design:"})," Separate robot into logical components (torso, arms, legs, head)."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Consistent Naming:"})," Use clear, systematic names (",(0,s.jsx)(e.code,{children:"left_shoulder_pitch"}),", not ",(0,s.jsx)(e.code,{children:"ls_p"}),")."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Coordinate Frame Conventions:"})," Follow ROS standards (X forward, Y left, Z up)."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Realistic Inertia:"})," Use CAD software or measurement to get accurate inertial properties."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Simplified Collision:"})," Use primitive shapes when possible for performance."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Test Incrementally:"})," Build URDF incrementally, testing visualization and simulation at each step."]}),"\n",(0,s.jsx)(e.h2,{id:"kinematic-chains-and-joint-hierarchies",children:"Kinematic Chains and Joint Hierarchies"}),"\n",(0,s.jsx)(e.h3,{id:"understanding-kinematic-chains",children:"Understanding Kinematic Chains"}),"\n",(0,s.jsx)(e.p,{children:"A kinematic chain is a series of rigid links connected by joints. In humanoids:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Serial Chains:"})," Links connected end-to-end (e.g., shoulder \u2192 upper arm \u2192 forearm \u2192 wrist \u2192 hand)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Tree Structure:"})," Humanoids are kinematic trees with the torso as root and limbs as branches"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Degrees of Freedom:"})," Number of independent joint motions. A typical humanoid:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Torso: 3 DOF (roll, pitch, yaw)"}),"\n",(0,s.jsx)(e.li,{children:"Arm: 7 DOF (3 shoulder, 1 elbow, 3 wrist)"}),"\n",(0,s.jsx)(e.li,{children:"Leg: 6 DOF (3 hip, 1 knee, 2 ankle)"}),"\n",(0,s.jsx)(e.li,{children:"Head: 2 DOF (pan, tilt)"}),"\n",(0,s.jsx)(e.li,{children:"Hand: 5+ DOF (finger joints)"}),"\n",(0,s.jsx)(e.li,{children:"Total: 30+ DOF"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"joint-hierarchy-representation",children:"Joint Hierarchy Representation"}),"\n",(0,s.jsx)(e.p,{children:"Humanoid joint hierarchy (simplified):"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"[base_link] (floating base)\n    \u2502\n[torso]\n    \u251c\u2500\u2500 [left_upper_leg]\n    \u2502       \u2514\u2500\u2500 [left_lower_leg]\n    \u2502               \u2514\u2500\u2500 [left_foot]\n    \u2502\n    \u251c\u2500\u2500 [right_upper_leg]\n    \u2502       \u2514\u2500\u2500 [right_lower_leg]\n    \u2502               \u2514\u2500\u2500 [right_foot]\n    \u2502\n    \u251c\u2500\u2500 [left_upper_arm]\n    \u2502       \u2514\u2500\u2500 [left_forearm]\n    \u2502               \u2514\u2500\u2500 [left_hand]\n    \u2502\n    \u251c\u2500\u2500 [right_upper_arm]\n    \u2502       \u2514\u2500\u2500 [right_forearm]\n    \u2502               \u2514\u2500\u2500 [right_hand]\n    \u2502\n    \u2514\u2500\u2500 [head]\n"})}),"\n",(0,s.jsx)(e.p,{children:"Each link inherits transformations from its parent. Moving the torso moves all limbs; moving the shoulder moves the entire arm."}),"\n",(0,s.jsx)(e.h3,{id:"forward-kinematics",children:"Forward Kinematics"}),"\n",(0,s.jsx)(e.p,{children:"Forward kinematics computes end effector position/orientation from joint angles:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Input:"})," Joint angles (\u03b81, \u03b82, ..., \u03b8n)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Output:"})," End effector pose (position + orientation) in world frame"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Process:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Start at base link"}),"\n",(0,s.jsx)(e.li,{children:"Apply transformation from each joint in chain"}),"\n",(0,s.jsx)(e.li,{children:"Multiply transformations sequentially"}),"\n",(0,s.jsx)(e.li,{children:"Result is end effector pose"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Example:"})," Given shoulder, elbow, and wrist angles, compute hand position."]}),"\n",(0,s.jsx)(e.p,{children:"Forward kinematics is straightforward\u2014just matrix multiplication through the chain."}),"\n",(0,s.jsx)(e.h3,{id:"inverse-kinematics",children:"Inverse Kinematics"}),"\n",(0,s.jsx)(e.p,{children:"Inverse kinematics computes joint angles needed to achieve a target end effector pose:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Input:"})," Desired end effector pose"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Output:"})," Joint angles (\u03b81, \u03b82, ..., \u03b8n)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Challenge:"})," Inverse kinematics is much harder than forward kinematics:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"May have no solution (target unreachable)"}),"\n",(0,s.jsx)(e.li,{children:"May have multiple solutions (elbow up vs. elbow down)"}),"\n",(0,s.jsx)(e.li,{children:"May have infinite solutions (redundant arms with 7 DOF)"}),"\n",(0,s.jsx)(e.li,{children:"Computational complexity increases with DOF"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solution Methods:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Analytical: Closed-form equations (fast but limited to specific geometries)"}),"\n",(0,s.jsx)(e.li,{children:"Numerical: Iterative optimization (general but slower)"}),"\n",(0,s.jsx)(e.li,{children:"Learning-based: Neural networks trained on IK solutions"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Motion planning systems heavily rely on IK to convert desired end effector goals into joint trajectories."}),"\n",(0,s.jsx)(e.h3,{id:"jacobian-and-differential-kinematics",children:"Jacobian and Differential Kinematics"}),"\n",(0,s.jsx)(e.p,{children:"The Jacobian matrix relates joint velocities to end effector velocities:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Jacobian (J):"})," Partial derivatives of end effector position with respect to joint angles"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Velocity Relationship:"})," \u1e8b = J \u03b8\u0307"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"\u1e8b: End effector velocity (6D: 3 linear, 3 angular)"}),"\n",(0,s.jsx)(e.li,{children:"\u03b8\u0307: Joint velocities"}),"\n",(0,s.jsx)(e.li,{children:"J: 6 \xd7 n Jacobian matrix (n = number of joints)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Uses:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Velocity Control:"})," Compute joint velocities for desired end effector velocity"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Singularity Detection:"})," When J loses rank, robot loses DOF (singularity)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Force Control:"})," Map joint torques to end effector forces"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"The Jacobian is fundamental to many robot control algorithms."}),"\n",(0,s.jsx)(e.h2,{id:"tf2-transform-system",children:"tf2: Transform System"}),"\n",(0,s.jsx)(e.h3,{id:"why-transform-management-matters",children:"Why Transform Management Matters"}),"\n",(0,s.jsx)(e.p,{children:"Humanoid robots have dozens of coordinate frames:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Robot Frames:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Base frame (robot origin)"}),"\n",(0,s.jsx)(e.li,{children:"Each link has a frame"}),"\n",(0,s.jsx)(e.li,{children:"Each joint has a frame"}),"\n",(0,s.jsx)(e.li,{children:"End effectors (hands, feet) have frames"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Sensor Frames:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Camera frame"}),"\n",(0,s.jsx)(e.li,{children:"LiDAR frame"}),"\n",(0,s.jsx)(e.li,{children:"IMU frame"}),"\n",(0,s.jsx)(e.li,{children:"Force sensor frames"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"World Frames:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Map frame (global reference)"}),"\n",(0,s.jsx)(e.li,{children:"Odom frame (odometry reference)"}),"\n",(0,s.jsx)(e.li,{children:"Base frame (robot's current location)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Questions requiring transforms:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Where is the detected object (camera frame) relative to the robot's hand (hand frame)?"}),"\n",(0,s.jsx)(e.li,{children:"What is the robot's position (base frame) in the map (map frame)?"}),"\n",(0,s.jsx)(e.li,{children:"Where should the foot (foot frame) be placed relative to the detected step (world frame)?"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"tf2 manages these coordinate transformations automatically."}),"\n",(0,s.jsx)(e.h3,{id:"tf2-architecture",children:"tf2 Architecture"}),"\n",(0,s.jsx)(e.p,{children:"tf2 maintains a transform tree:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Tree Structure:"})," Frames connected in a tree (no loops). Each frame has one parent."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Transform Specification:"})," Each transform specifies:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Parent frame"}),"\n",(0,s.jsx)(e.li,{children:"Child frame"}),"\n",(0,s.jsx)(e.li,{children:"Translation (x, y, z)"}),"\n",(0,s.jsx)(e.li,{children:"Rotation (quaternion: x, y, z, w)"}),"\n",(0,s.jsx)(e.li,{children:"Timestamp (when transform is valid)"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Transform Lookup:"}),' Query "what is the transform from frame A to frame B at time t?"']}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Chain Computation:"})," tf2 finds the path through the tree from A to B and multiplies transforms along the path."]}),"\n",(0,s.jsx)(e.h3,{id:"static-vs-dynamic-transforms",children:"Static vs. Dynamic Transforms"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Static Transforms:"})," Don't change over time"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Sensor mounting positions (camera on head)"}),"\n",(0,s.jsx)(e.li,{children:"Link-to-link transforms (defined by URDF)"}),"\n",(0,s.jsx)(e.li,{children:"Calibration offsets"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Dynamic Transforms:"})," Change over time"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Joint angles (link positions change as joints move)"}),"\n",(0,s.jsx)(e.li,{children:"Robot pose in world (changes as robot moves)"}),"\n",(0,s.jsx)(e.li,{children:"Object tracking (objects move in environment)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Static transforms published once; dynamic transforms published continuously."}),"\n",(0,s.jsx)(e.h3,{id:"common-frame-conventions",children:"Common Frame Conventions"}),"\n",(0,s.jsx)(e.p,{children:"ROS 2 follows standard naming and conventions:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"map:"})," Global fixed frame (environment map reference)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"odom:"})," Odometry frame (continuous, drift-prone estimate of robot pose)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"base_link:"})," Robot's base (usually at center of mass or between feet)"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Relationship:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"map \u2192 odom: Corrects odometry drift (from localization)"}),"\n",(0,s.jsx)(e.li,{children:"odom \u2192 base_link: Odometry estimate (from wheel encoders, VIO)"}),"\n",(0,s.jsx)(e.li,{children:"base_link \u2192 sensors/links: Robot structure (from URDF + joint states)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Coordinate Convention:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"X: Forward"}),"\n",(0,s.jsx)(e.li,{children:"Y: Left"}),"\n",(0,s.jsx)(e.li,{children:"Z: Up"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Following conventions ensures interoperability between packages."}),"\n",(0,s.jsx)(e.h3,{id:"transform-broadcasting",children:"Transform Broadcasting"}),"\n",(0,s.jsx)(e.p,{children:"Nodes publish transforms to tf2:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Static Transform Broadcaster:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Publishes fixed transforms"}),"\n",(0,s.jsx)(e.li,{children:"Example: Camera mount position on robot head"}),"\n",(0,s.jsx)(e.li,{children:"Published once at startup or infrequently"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Transform Broadcaster:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Publishes dynamic transforms"}),"\n",(0,s.jsx)(e.li,{children:"Example: Robot position in world, joint angles"}),"\n",(0,s.jsx)(e.li,{children:"Published continuously (10-50 Hz typically)"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Example:"})," ",(0,s.jsx)(e.code,{children:"robot_state_publisher"})," broadcasts transforms for all robot links based on joint angles."]}),"\n",(0,s.jsx)(e.h3,{id:"transform-listening",children:"Transform Listening"}),"\n",(0,s.jsx)(e.p,{children:"Nodes query transforms from tf2:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Transform Listener:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Subscribes to transform topics"}),"\n",(0,s.jsx)(e.li,{children:"Maintains transform buffer (history of transforms)"}),"\n",(0,s.jsx)(e.li,{children:"Provides lookup interface"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Lookup Query:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Source frame"}),"\n",(0,s.jsx)(e.li,{children:"Target frame"}),"\n",(0,s.jsx)(e.li,{children:"Time (can query historical transforms)"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Example:"}),' Motion planner queries "hand position in base frame" to check if target is reachable.']}),"\n",(0,s.jsx)(e.h3,{id:"transform-tree-example",children:"Transform Tree Example"}),"\n",(0,s.jsx)(e.p,{children:"Humanoid robot transform tree:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"[map]\n  \u2193\n[odom]\n  \u2193\n[base_link]\n  \u251c\u2500\u2500 [torso]\n  \u2502     \u251c\u2500\u2500 [head]\n  \u2502     \u2502     \u251c\u2500\u2500 [camera_left]\n  \u2502     \u2502     \u2514\u2500\u2500 [camera_right]\n  \u2502     \u251c\u2500\u2500 [left_shoulder]\n  \u2502     \u2502     \u2514\u2500\u2500 [left_upper_arm]\n  \u2502     \u2502           \u2514\u2500\u2500 [left_forearm]\n  \u2502     \u2502                 \u2514\u2500\u2500 [left_hand]\n  \u2502     \u2514\u2500\u2500 [right_shoulder]\n  \u2502           \u2514\u2500\u2500 [right_upper_arm]\n  \u2502                 \u2514\u2500\u2500 [right_forearm]\n  \u2502                       \u2514\u2500\u2500 [right_hand]\n  \u251c\u2500\u2500 [left_hip]\n  \u2502     \u2514\u2500\u2500 [left_upper_leg]\n  \u2502           \u2514\u2500\u2500 [left_lower_leg]\n  \u2502                 \u2514\u2500\u2500 [left_foot]\n  \u2514\u2500\u2500 [right_hip]\n        \u2514\u2500\u2500 [right_upper_leg]\n              \u2514\u2500\u2500 [right_lower_leg]\n                    \u2514\u2500\u2500 [right_foot]\n"})}),"\n",(0,s.jsx)(e.p,{children:'To find "left hand position in map frame", tf2 multiplies transforms along path: map \u2192 odom \u2192 base_link \u2192 torso \u2192 left_shoulder \u2192 left_upper_arm \u2192 left_forearm \u2192 left_hand.'}),"\n",(0,s.jsx)(e.h3,{id:"time-synchronization",children:"Time Synchronization"}),"\n",(0,s.jsx)(e.p,{children:"tf2 stores transform history, enabling time-synchronized queries:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Use Case:"})," Camera image captured at t=10.5s shows object. Robot's hand was at different position then vs. now (t=11.0s). Need transform at t=10.5s to accurately plan grasp."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Buffer Duration:"})," Typically 10-30 seconds of history. Older transforms discarded."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Interpolation:"})," If exact timestamp not available, tf2 interpolates between nearby transforms."]}),"\n",(0,s.jsx)(e.h2,{id:"robot_state_publisher-and-joint_state_publisher",children:"robot_state_publisher and joint_state_publisher"}),"\n",(0,s.jsx)(e.h3,{id:"robot_state_publisher",children:"robot_state_publisher"}),"\n",(0,s.jsxs)(e.p,{children:["The ",(0,s.jsx)(e.code,{children:"robot_state_publisher"})," node is central to humanoid robot operation:"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Purpose:"})," Publishes transforms for all robot links based on URDF and current joint states."]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Inputs:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"URDF (robot description)"}),"\n",(0,s.jsx)(e.li,{children:"Joint states (joint positions from controllers or sensors)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Outputs:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"tf2 transforms for all links"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Process:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Parse URDF to understand kinematic tree"}),"\n",(0,s.jsxs)(e.li,{children:["Subscribe to ",(0,s.jsx)(e.code,{children:"/joint_states"})," topic"]}),"\n",(0,s.jsxs)(e.li,{children:["For each joint state update:","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Compute forward kinematics for all links"}),"\n",(0,s.jsx)(e.li,{children:"Publish transforms to tf2"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Why Essential:"})," Provides real-time robot geometry to all other nodes. Motion planners, collision checkers, and visualizers need to know where every link is."]}),"\n",(0,s.jsx)(e.h3,{id:"joint_state_publisher",children:"joint_state_publisher"}),"\n",(0,s.jsxs)(e.p,{children:["The ",(0,s.jsx)(e.code,{children:"joint_state_publisher"})," node provides joint states when hardware is not available:"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Purpose:"})," Publish joint states for testing/visualization without real robot."]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Use Cases:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simulation:"})," Generate random or scripted joint movements"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Debugging:"})," Manually control joints via GUI to test robot description"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Demonstration:"})," Show robot capabilities without hardware"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"GUI Mode:"})," Provides sliders to manually control each joint position."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Not for Real Robots:"})," On real hardware, joint states come from motor encoders or other sensors, not ",(0,s.jsx)(e.code,{children:"joint_state_publisher"}),"."]}),"\n",(0,s.jsx)(e.h3,{id:"joint-state-message",children:"Joint State Message"}),"\n",(0,s.jsxs)(e.p,{children:["Joint states published on ",(0,s.jsx)(e.code,{children:"/joint_states"})," topic use ",(0,s.jsx)(e.code,{children:"sensor_msgs/JointState"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Header header\nstring[] name           # Joint names\nfloat64[] position      # Joint positions (radians or meters)\nfloat64[] velocity      # Joint velocities (rad/s or m/s)\nfloat64[] effort        # Joint efforts (torques or forces)\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Example:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"name: ['right_shoulder_pitch', 'right_elbow', 'right_wrist_roll']\nposition: [0.5, 1.2, -0.3]  # radians\nvelocity: [0.1, 0.0, 0.05]  # rad/s\neffort: [2.5, 1.0, 0.3]     # Nm\n"})}),"\n",(0,s.jsxs)(e.p,{children:["All controllers and sensors must publish joint states in this format for ",(0,s.jsx)(e.code,{children:"robot_state_publisher"})," to process."]}),"\n",(0,s.jsx)(e.h3,{id:"workflow-urdf-to-visualization",children:"Workflow: URDF to Visualization"}),"\n",(0,s.jsx)(e.p,{children:"Typical workflow for humanoid robot:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"URDF Creation:"})," Define robot structure (links, joints, geometry)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Parameter Server:"})," Load URDF to ROS 2 parameter server (typically via launch file)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"robot_state_publisher:"})," Reads URDF, subscribes to ",(0,s.jsx)(e.code,{children:"/joint_states"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Joint Source:"})," Either:","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"joint_state_publisher"})," (GUI for testing)"]}),"\n",(0,s.jsx)(e.li,{children:"Hardware interface (real robot motor encoders)"}),"\n",(0,s.jsx)(e.li,{children:"Simulation (Gazebo, Isaac Sim publishes joint states)"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Transform Publishing:"})," ",(0,s.jsx)(e.code,{children:"robot_state_publisher"})," computes and publishes all link transforms to tf2"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Visualization:"})," RViz2 subscribes to tf2 and ",(0,s.jsx)(e.code,{children:"/robot_description"})," to display robot"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"This pipeline enables seeing the robot move in RViz2 as joints change."}),"\n",(0,s.jsx)(e.h2,{id:"controller-interfaces-and-ros2_control",children:"Controller Interfaces and ros2_control"}),"\n",(0,s.jsx)(e.h3,{id:"what-is-ros2_control",children:"What is ros2_control?"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.code,{children:"ros2_control"})," is a framework for robot control in ROS 2. It provides:"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Hardware Abstraction:"})," Unified interface for different motors, sensors, and actuators"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Controller Management:"})," Loading, starting, stopping, and switching controllers"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Real-Time Support:"})," Designed for real-time control loops (1-10 kHz)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Modular Controllers:"})," Reusable controllers for common tasks (joint position, velocity, effort control)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Plugin Architecture:"})," Extend with custom hardware interfaces and controllers"]}),"\n",(0,s.jsx)(e.h3,{id:"ros2_control-architecture",children:"ros2_control Architecture"}),"\n",(0,s.jsx)(e.p,{children:"The framework has three layers:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Hardware Interface:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Communicates with physical hardware (motor drivers, sensors)"}),"\n",(0,s.jsx)(e.li,{children:"Reads joint states (position, velocity, effort)"}),"\n",(0,s.jsx)(e.li,{children:"Writes joint commands (position, velocity, effort)"}),"\n",(0,s.jsx)(e.li,{children:"Implemented per robot (each robot needs custom hardware interface)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Controller Manager:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Loads and manages controllers"}),"\n",(0,s.jsx)(e.li,{children:"Routes commands and states between controllers and hardware"}),"\n",(0,s.jsx)(e.li,{children:"Handles controller lifecycle (inactive, active, error states)"}),"\n",(0,s.jsx)(e.li,{children:"Ensures only one controller writes to each joint"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Controllers:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Implement control algorithms"}),"\n",(0,s.jsx)(e.li,{children:"Read joint states from hardware interface"}),"\n",(0,s.jsx)(e.li,{children:"Write commands to hardware interface"}),"\n",(0,s.jsx)(e.li,{children:"Examples: position controller, velocity controller, trajectory controller"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Data Flow:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"[Hardware] \u2190\u2192 [Hardware Interface] \u2190\u2192 [Controller Manager] \u2190\u2192 [Controllers]\n              (read states,              (route data,          (control\n               write commands)            manage lifecycle)     algorithms)\n"})}),"\n",(0,s.jsx)(e.h3,{id:"hardware-interface-concepts",children:"Hardware Interface Concepts"}),"\n",(0,s.jsx)(e.p,{children:"Hardware interface defines how to communicate with robot:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Resource Declaration:"})," Specify available joints and interfaces (position, velocity, effort)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"State Interfaces:"})," Hardware provides current state"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"position: Current joint angle"}),"\n",(0,s.jsx)(e.li,{children:"velocity: Current joint velocity"}),"\n",(0,s.jsx)(e.li,{children:"effort: Current joint torque"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Command Interfaces:"})," Hardware accepts commands"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"position: Target joint angle"}),"\n",(0,s.jsx)(e.li,{children:"velocity: Target joint velocity"}),"\n",(0,s.jsx)(e.li,{children:"effort: Target joint torque"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Example:"})," A humanoid arm with 3 joints might export:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["State interfaces: ",(0,s.jsx)(e.code,{children:"shoulder_pitch/position"}),", ",(0,s.jsx)(e.code,{children:"elbow/position"}),", ",(0,s.jsx)(e.code,{children:"wrist_roll/position"}),", plus velocity and effort for each"]}),"\n",(0,s.jsxs)(e.li,{children:["Command interfaces: ",(0,s.jsx)(e.code,{children:"shoulder_pitch/effort"}),", ",(0,s.jsx)(e.code,{children:"elbow/effort"}),", ",(0,s.jsx)(e.code,{children:"wrist_roll/effort"})," (torque control)"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Controllers read state interfaces and write command interfaces."}),"\n",(0,s.jsx)(e.h3,{id:"common-controllers",children:"Common Controllers"}),"\n",(0,s.jsx)(e.p,{children:"ros2_control provides standard controllers:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Joint State Broadcaster:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Reads joint states from hardware interface"}),"\n",(0,s.jsxs)(e.li,{children:["Publishes to ",(0,s.jsx)(e.code,{children:"/joint_states"})," topic"]}),"\n",(0,s.jsxs)(e.li,{children:["Required for ",(0,s.jsx)(e.code,{children:"robot_state_publisher"})," to work"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Position Controller:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Accepts target joint positions"}),"\n",(0,s.jsx)(e.li,{children:"Commands hardware to reach targets"}),"\n",(0,s.jsx)(e.li,{children:"Simple PID or more advanced control"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Velocity Controller:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Accepts target joint velocities"}),"\n",(0,s.jsx)(e.li,{children:"Maintains desired velocity"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Effort Controller:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Accepts target joint torques"}),"\n",(0,s.jsx)(e.li,{children:"Direct torque control"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Joint Trajectory Controller:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Executes trajectories (sequences of waypoints with timing)"}),"\n",(0,s.jsx)(e.li,{children:"Interpolates between waypoints"}),"\n",(0,s.jsx)(e.li,{children:"Used by motion planners"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Admittance Controller:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Compliant control (responds to external forces)"}),"\n",(0,s.jsx)(e.li,{children:"Essential for safe human-robot interaction"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"controller-manager",children:"Controller Manager"}),"\n",(0,s.jsx)(e.p,{children:"The controller manager orchestrates controllers:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Loading:"})," Load controller plugins dynamically"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"ros2 control load_controller joint_trajectory_controller\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Configuration:"})," Controllers configured via parameters (gains, limits, etc.)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Lifecycle Management:"})," Controllers have states:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Unconfigured: Just loaded"}),"\n",(0,s.jsx)(e.li,{children:"Inactive: Configured but not controlling"}),"\n",(0,s.jsx)(e.li,{children:"Active: Actively controlling hardware"}),"\n",(0,s.jsx)(e.li,{children:"Finalized: Cleaned up"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Switching:"})," Can switch between controllers:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Stop position controller"}),"\n",(0,s.jsx)(e.li,{children:"Start torque controller"}),"\n",(0,s.jsx)(e.li,{children:"Ensures smooth transitions"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Exclusive Access:"})," Prevents multiple controllers from fighting over same joints"]}),"\n",(0,s.jsx)(e.h3,{id:"real-time-considerations",children:"Real-Time Considerations"}),"\n",(0,s.jsx)(e.p,{children:"Humanoid control requires real-time performance:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Control Loop Frequency:"})," 1-10 kHz for balance and manipulation"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Balance: 1-2 kHz (fast response to disturbances)"}),"\n",(0,s.jsx)(e.li,{children:"Joint control: 100-1000 Hz"}),"\n",(0,s.jsx)(e.li,{children:"Planning: 10-100 Hz"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Determinism:"})," Control loops must execute at precise intervals. Late execution causes instability."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Real-Time OS:"})," For hard real-time, use PREEMPT_RT Linux kernel"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"ros2_control Design:"})," Separates real-time (hardware interface, controllers) from non-real-time (ROS 2 communication) components. Real-time components run in dedicated threads."]}),"\n",(0,s.jsx)(e.h2,{id:"bridging-ai-agents-to-ros-controllers",children:"Bridging AI Agents to ROS Controllers"}),"\n",(0,s.jsx)(e.h3,{id:"the-ai-to-robot-control-gap",children:"The AI-to-Robot Control Gap"}),"\n",(0,s.jsx)(e.p,{children:"Modern humanoid robots combine:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"High-Level AI:"})," Large language models, vision transformers, reinforcement learning policies"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:'Operate on abstract goals ("pick up the cup")'}),"\n",(0,s.jsx)(e.li,{children:"Run at low frequency (1-10 Hz)"}),"\n",(0,s.jsx)(e.li,{children:"Often run on GPU"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Low-Level Control:"})," Motor controllers, balance algorithms, trajectory execution"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Operate on joint commands"}),"\n",(0,s.jsx)(e.li,{children:"Run at high frequency (100-1000 Hz)"}),"\n",(0,s.jsx)(e.li,{children:"Often run on real-time CPU or microcontroller"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Gap:"})," AI outputs high-level intentions; controllers need low-level commands. Need architecture to bridge this gap."]}),"\n",(0,s.jsx)(e.h3,{id:"hierarchical-control-architecture",children:"Hierarchical Control Architecture"}),"\n",(0,s.jsx)(e.p,{children:"Effective architecture uses hierarchy:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Level 1: AI Agent (High-Level)"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Input: Sensor data (images, point clouds), task description"}),"\n",(0,s.jsx)(e.li,{children:"Processing: LLM reasoning, object detection, scene understanding"}),"\n",(0,s.jsx)(e.li,{children:'Output: High-level goals ("grasp object at position X,Y,Z")'}),"\n",(0,s.jsx)(e.li,{children:"Frequency: 1-10 Hz"}),"\n",(0,s.jsx)(e.li,{children:"Hardware: GPU"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Level 2: Motion Planning (Mid-Level)"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Input: High-level goals from AI"}),"\n",(0,s.jsx)(e.li,{children:"Processing: Path planning, inverse kinematics, collision avoidance"}),"\n",(0,s.jsx)(e.li,{children:"Output: Joint trajectories (sequences of joint angles with timing)"}),"\n",(0,s.jsx)(e.li,{children:"Frequency: 10-50 Hz"}),"\n",(0,s.jsx)(e.li,{children:"Hardware: CPU"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Level 3: Controllers (Low-Level)"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Input: Joint trajectories from planners"}),"\n",(0,s.jsx)(e.li,{children:"Processing: PID control, torque computation, balance"}),"\n",(0,s.jsx)(e.li,{children:"Output: Motor commands (voltages, torques)"}),"\n",(0,s.jsx)(e.li,{children:"Frequency: 100-1000 Hz"}),"\n",(0,s.jsx)(e.li,{children:"Hardware: Real-time CPU or microcontroller"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Level 4: Hardware"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Input: Motor commands from controllers"}),"\n",(0,s.jsx)(e.li,{children:"Processing: Motor driver electronics"}),"\n",(0,s.jsx)(e.li,{children:"Output: Actual joint motion"}),"\n",(0,s.jsx)(e.li,{children:"Frequency: 1-10 kHz"}),"\n",(0,s.jsx)(e.li,{children:"Hardware: Motor drivers, motors"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Data Flow:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"[AI Agent] --goals--\x3e [Motion Planner] --trajectories--\x3e [Controller] --commands--\x3e [Hardware]\n   \u2191                        \u2191                                \u2191\n   |                        |                                |\n[Sensors] <---- [State Estimation] <---- [Joint States] <----+\n"})}),"\n",(0,s.jsx)(e.h3,{id:"interface-patterns",children:"Interface Patterns"}),"\n",(0,s.jsx)(e.p,{children:"Several patterns bridge AI and control:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Pattern 1: Action-Based Interface"})}),"\n",(0,s.jsx)(e.p,{children:"AI sends high-level goals as ROS 2 actions:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"AI Agent --NavigateToPose action--\x3e Navigation Stack\n         --GraspObject action-----\x3e Manipulation Planner\n         --FollowPerson action----\x3e Person Tracking\n\nEach action server handles:\n- Goal decomposition\n- Motion planning\n- Execution\n- Feedback to AI\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Advantages:"})," Clean separation, asynchronous, progress feedback\n",(0,s.jsx)(e.strong,{children:"Use Case:"})," Discrete tasks with clear goals"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Pattern 2: Topic-Based Interface"})}),"\n",(0,s.jsx)(e.p,{children:"AI publishes commands on topics, controllers subscribe:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"AI Agent --/cmd_vel topic--\x3e Velocity Controller\n         --/target_pose---\x3e Position Controller\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Advantages:"})," Simple, low latency, continuous control\n",(0,s.jsx)(e.strong,{children:"Use Case:"})," Continuous control (teleoperation, learned policies)"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Pattern 3: Behavior Trees"})}),"\n",(0,s.jsx)(e.p,{children:"Hierarchical state machine coordinates AI and control:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"[Behavior Tree]\n    \u251c\u2500\u2500 Sequence: Grasp Object\n    \u2502     \u251c\u2500\u2500 [AI: Detect Object] --object pose--\x3e context\n    \u2502     \u251c\u2500\u2500 [Planning: Compute IK] --joint angles--\x3e context\n    \u2502     \u251c\u2500\u2500 [Control: Move Arm] --execute trajectory\n    \u2502     \u2514\u2500\u2500 [Control: Close Gripper]\n    \u2514\u2500\u2500 Fallback: Recovery\n          \u251c\u2500\u2500 [AI: Re-detect Object]\n          \u2514\u2500\u2500 [Control: Retreat to Safe Pose]\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Advantages:"})," Complex behaviors, error handling, modular\n",(0,s.jsx)(e.strong,{children:"Use Case:"})," Multi-step tasks requiring coordination"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Pattern 4: Shared Memory Interface"})}),"\n",(0,s.jsx)(e.p,{children:"AI and control share memory for high-frequency communication:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"AI Policy (GPU) --shared memory--\x3e Real-Time Controller (CPU)\n   writes: target joint positions\n   reads: current joint states\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Advantages:"})," Lowest latency, highest frequency\n",(0,s.jsx)(e.strong,{children:"Use Case:"})," Learned policies requiring tight control loop (RL policies)"]}),"\n",(0,s.jsx)(e.h3,{id:"example-llm-controlled-humanoid",children:"Example: LLM-Controlled Humanoid"}),"\n",(0,s.jsx)(e.p,{children:"Architecture for LLM-controlled humanoid:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Components:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"LLM Agent:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Receives natural language commands"}),"\n",(0,s.jsx)(e.li,{children:"Reasons about task decomposition"}),"\n",(0,s.jsx)(e.li,{children:"Publishes high-level action goals"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Task Planner:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Subscribes to LLM goals"}),"\n",(0,s.jsx)(e.li,{children:"Breaks down into motion primitives"}),"\n",(0,s.jsx)(e.li,{children:"Sends action requests to motion planners"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Motion Planners:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Navigation planner (MoveIt2 or Nav2)"}),"\n",(0,s.jsx)(e.li,{children:"Manipulation planner (MoveIt2)"}),"\n",(0,s.jsx)(e.li,{children:"Whole-body planner"}),"\n",(0,s.jsx)(e.li,{children:"Generate trajectories"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Controller Manager:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Executes trajectories via joint trajectory controller"}),"\n",(0,s.jsx)(e.li,{children:"Monitors execution, reports status"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Hardware Interface:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Sends commands to motors"}),"\n",(0,s.jsx)(e.li,{children:"Reads joint states"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Communication:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"LLM \u2192 Task Planner: ROS 2 service or topic"}),"\n",(0,s.jsx)(e.li,{children:"Task Planner \u2192 Motion Planners: ROS 2 actions"}),"\n",(0,s.jsx)(e.li,{children:"Motion Planners \u2192 Controllers: ROS 2 actions (FollowJointTrajectory)"}),"\n",(0,s.jsx)(e.li,{children:"Controllers \u2192 Hardware: ros2_control interfaces"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Example Flow:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:'User: "Pick up the red cup"\n  \u2193\n[LLM]: Parse command, identify object "red cup", task "pick up"\n  \u2193\n[LLM \u2192 Task Planner]: Goal: grasp(object="red cup", color="red")\n  \u2193\n[Task Planner]:\n  1. Detect red cup (call vision service)\n  2. Plan grasp approach (call manipulation planner)\n  3. Execute grasp trajectory\n  \u2193\n[Vision Service]: Returns cup pose\n  \u2193\n[Manipulation Planner]: Computes IK, plans collision-free path\n  \u2193\n[Manipulation Planner \u2192 Controller]: FollowJointTrajectory action\n  \u2193\n[Controller]: Executes trajectory, monitors joint states\n  \u2193\n[Hardware]: Motors move arm to grasp cup\n'})}),"\n",(0,s.jsx)(e.h3,{id:"learned-policy-integration",children:"Learned Policy Integration"}),"\n",(0,s.jsx)(e.p,{children:"For reinforcement learning policies:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Training:"})," Policy trained in simulation (Gazebo, Isaac Sim)"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Deployment:"})," Policy runs in ROS 2 node"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Interface:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Policy subscribes to sensor topics (joint states, camera images)"}),"\n",(0,s.jsx)(e.li,{children:"Policy publishes to command topics (joint positions or torques)"}),"\n",(0,s.jsx)(e.li,{children:"Control frequency: Match training frequency (often 50-100 Hz)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Challenges:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Sim-to-real gap: Policy trained in simulation may fail on real hardware"}),"\n",(0,s.jsx)(e.li,{children:"Safety: Learned policies can be unpredictable; need safety monitors"}),"\n",(0,s.jsx)(e.li,{children:"Timing: ROS 2 topic communication has jitter; may need shared memory for determinism"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Safety Wrapper:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"[Policy Node] --raw commands--\x3e [Safety Monitor] --safe commands--\x3e [Controller]\n                                      \u2191\n                                      |\n                               [Joint States]\n                               [Collision Detector]\n                               [Emergency Stop]\n"})}),"\n",(0,s.jsx)(e.p,{children:"Safety monitor validates policy commands before sending to hardware."}),"\n",(0,s.jsx)(e.h2,{id:"rviz2-visualization-and-debugging",children:"RViz2: Visualization and Debugging"}),"\n",(0,s.jsx)(e.h3,{id:"what-is-rviz2",children:"What is RViz2?"}),"\n",(0,s.jsx)(e.p,{children:"RViz2 is ROS 2's 3D visualization tool. It displays:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Robot models (from URDF)"}),"\n",(0,s.jsx)(e.li,{children:"Sensor data (cameras, LiDAR, point clouds)"}),"\n",(0,s.jsx)(e.li,{children:"Coordinate frames (tf2)"}),"\n",(0,s.jsx)(e.li,{children:"Planning results (trajectories, paths)"}),"\n",(0,s.jsx)(e.li,{children:"Markers (for debugging: arrows, spheres, text)"}),"\n",(0,s.jsx)(e.li,{children:"Maps and occupancy grids"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"RViz2 is essential for development, debugging, and demonstration."}),"\n",(0,s.jsx)(e.h3,{id:"rviz2-architecture",children:"RViz2 Architecture"}),"\n",(0,s.jsx)(e.p,{children:"RViz2 subscribes to ROS 2 topics and visualizes data:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Display Plugins:"})," Each data type has a display plugin"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"RobotModel: Visualizes URDF"}),"\n",(0,s.jsx)(e.li,{children:"Camera: Shows camera images"}),"\n",(0,s.jsx)(e.li,{children:"PointCloud2: Renders point clouds"}),"\n",(0,s.jsx)(e.li,{children:"TF: Shows coordinate frames"}),"\n",(0,s.jsx)(e.li,{children:"Marker: Displays custom visualization markers"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Configuration:"})," RViz2 configurations saved to files, allowing project-specific setups"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Interactive Markers:"})," Allow interacting with visualization (move target poses, trigger actions)"]}),"\n",(0,s.jsx)(e.h3,{id:"visualizing-the-robot",children:"Visualizing the Robot"}),"\n",(0,s.jsx)(e.p,{children:"To see humanoid robot in RViz2:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Requirements:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"URDF loaded to parameter server"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"robot_state_publisher"})," running"]}),"\n",(0,s.jsx)(e.li,{children:"Joint states being published"}),"\n",(0,s.jsx)(e.li,{children:"tf2 transforms available"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"RViz2 Configuration:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Add RobotModel display"}),"\n",(0,s.jsxs)(e.li,{children:["Set robot description topic (typically ",(0,s.jsx)(e.code,{children:"/robot_description"}),")"]}),"\n",(0,s.jsx)(e.li,{children:"Robot appears, colored by link"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Interactive Control:"})," With ",(0,s.jsx)(e.code,{children:"joint_state_publisher_gui"}),", slide joints to see robot move in real-time."]}),"\n",(0,s.jsx)(e.h3,{id:"visualizing-sensor-data",children:"Visualizing Sensor Data"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Camera Images:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Add Camera display"}),"\n",(0,s.jsxs)(e.li,{children:["Select image topic (e.g., ",(0,s.jsx)(e.code,{children:"/camera/image_raw"}),")"]}),"\n",(0,s.jsx)(e.li,{children:"Image appears in 3D view or separate panel"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Point Clouds:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Add PointCloud2 display"}),"\n",(0,s.jsxs)(e.li,{children:["Select point cloud topic (e.g., ",(0,s.jsx)(e.code,{children:"/scan"})," or ",(0,s.jsx)(e.code,{children:"/camera/depth/points"}),")"]}),"\n",(0,s.jsx)(e.li,{children:"Configure color by intensity, height, or RGB"}),"\n",(0,s.jsx)(e.li,{children:"Point cloud overlays robot model"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"LiDAR Scans:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Add LaserScan display"}),"\n",(0,s.jsx)(e.li,{children:"Select scan topic"}),"\n",(0,s.jsx)(e.li,{children:"Configure visualization (points, flat squares, etc.)"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"visualizing-coordinate-frames",children:"Visualizing Coordinate Frames"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"TF Display:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Add TF display"}),"\n",(0,s.jsx)(e.li,{children:"Toggle which frames to show (all frames can clutter view)"}),"\n",(0,s.jsx)(e.li,{children:"Each frame shown as RGB axes (X=red, Y=green, Z=blue)"}),"\n",(0,s.jsx)(e.li,{children:"Helps debug frame relationships and transform errors"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Use Cases:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Verify sensor mounting positions"}),"\n",(0,s.jsx)(e.li,{children:"Debug transform tree structure"}),"\n",(0,s.jsx)(e.li,{children:"Understand coordinate frame relationships"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"debugging-with-markers",children:"Debugging with Markers"}),"\n",(0,s.jsx)(e.p,{children:"Markers visualize custom data:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Marker Types:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Arrow: Direction vectors"}),"\n",(0,s.jsx)(e.li,{children:"Sphere: Points of interest"}),"\n",(0,s.jsx)(e.li,{children:"Line: Paths or connections"}),"\n",(0,s.jsx)(e.li,{children:"Cube: Bounding boxes"}),"\n",(0,s.jsx)(e.li,{children:"Text: Labels"}),"\n",(0,s.jsx)(e.li,{children:"Mesh: Custom 3D shapes"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Publishing Markers:"}),"\nNodes publish to ",(0,s.jsx)(e.code,{children:"/visualization_marker"})," topic. Markers specify:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Type, position, orientation"}),"\n",(0,s.jsx)(e.li,{children:"Color, scale"}),"\n",(0,s.jsx)(e.li,{children:"Lifetime (auto-deletion)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Example Uses:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Show detected object bounding boxes"}),"\n",(0,s.jsx)(e.li,{children:"Display planned path"}),"\n",(0,s.jsx)(e.li,{children:"Indicate target grasp pose"}),"\n",(0,s.jsx)(e.li,{children:"Show force vectors"}),"\n",(0,s.jsx)(e.li,{children:"Label objects with text"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"rviz2-for-humanoid-development",children:"RViz2 for Humanoid Development"}),"\n",(0,s.jsx)(e.p,{children:"Typical RViz2 setup for humanoid:"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Displays:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"RobotModel: Show robot structure"}),"\n",(0,s.jsx)(e.li,{children:"TF: Key frames (base, hands, feet, cameras)"}),"\n",(0,s.jsx)(e.li,{children:"Camera: Front camera view"}),"\n",(0,s.jsx)(e.li,{children:"PointCloud2: Depth camera or LiDAR"}),"\n",(0,s.jsx)(e.li,{children:"Marker: Planning visualization"}),"\n",(0,s.jsx)(e.li,{children:"Path: Planned trajectories"}),"\n",(0,s.jsx)(e.li,{children:"Axes: Target poses"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Workflow:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Start robot (hardware or simulation)"}),"\n",(0,s.jsx)(e.li,{children:"Launch RViz2 with configuration"}),"\n",(0,s.jsx)(e.li,{children:"See robot state in real-time"}),"\n",(0,s.jsx)(e.li,{children:"See sensor data overlaid on scene"}),"\n",(0,s.jsx)(e.li,{children:"See planning and control outputs"}),"\n",(0,s.jsx)(e.li,{children:"Debug by inspecting frames, data, and markers"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"rviz2-vs-simulation",children:"RViz2 vs. Simulation"}),"\n",(0,s.jsx)(e.p,{children:"Important distinction:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"RViz2:"})," Visualization only. Does not simulate physics. Shows what robot reports through topics and tf2."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Gazebo/Isaac Sim:"})," Full physics simulation. Simulates robot dynamics, sensors, environment."]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Combined Use:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Run Gazebo for physics simulation"}),"\n",(0,s.jsx)(e.li,{children:"Run RViz2 to visualize Gazebo's output"}),"\n",(0,s.jsx)(e.li,{children:"RViz2 shows what Gazebo publishes (joint states, sensor data, tf)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Both tools serve different purposes: RViz2 for visualization and debugging, simulators for testing in virtual environments."}),"\n",(0,s.jsx)(e.h2,{id:"conceptual-diagrams",children:"Conceptual Diagrams"}),"\n",(0,s.jsx)(e.h3,{id:"diagram-1-urdf-structure",children:"Diagram 1: URDF Structure"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"URDF Anatomy:\n\nRobot Description\n\u2502\n\u251c\u2500\u2500 Links (Rigid Bodies)\n\u2502   \u251c\u2500\u2500 Visual Geometry (what you see)\n\u2502   \u2502     \u2514\u2500\u2500 Mesh or primitives (box, cylinder, sphere)\n\u2502   \u251c\u2500\u2500 Collision Geometry (for collision checking)\n\u2502   \u2502     \u2514\u2500\u2500 Simplified shapes for performance\n\u2502   \u2514\u2500\u2500 Inertial Properties\n\u2502         \u251c\u2500\u2500 Mass\n\u2502         \u251c\u2500\u2500 Center of mass\n\u2502         \u2514\u2500\u2500 Inertia tensor\n\u2502\n\u251c\u2500\u2500 Joints (Connections)\n\u2502   \u251c\u2500\u2500 Type (revolute, prismatic, fixed, etc.)\n\u2502   \u251c\u2500\u2500 Parent Link\n\u2502   \u251c\u2500\u2500 Child Link\n\u2502   \u251c\u2500\u2500 Axis of motion\n\u2502   \u251c\u2500\u2500 Limits (position, velocity, effort)\n\u2502   \u2514\u2500\u2500 Dynamics (damping, friction)\n\u2502\n\u2514\u2500\u2500 Sensors/Actuators\n      \u2514\u2500\u2500 Specifications and mounting\n\nExample Hierarchy:\n[torso]\n   \u2502\n   \u251c\u2500[joint: right_shoulder]\u2500\u2192 [link: right_upper_arm]\n   \u2502                               \u2502\n   \u2502                               \u2514\u2500[joint: right_elbow]\u2500\u2192 [link: right_forearm]\n   \u2502\n   \u2514\u2500[joint: left_shoulder]\u2500\u2500\u2192 [link: left_upper_arm]\n                                   \u2502\n                                   \u2514\u2500[joint: left_elbow]\u2500\u2500\u2192 [link: left_forearm]\n"})}),"\n",(0,s.jsx)(e.h3,{id:"diagram-2-kinematic-chain",children:"Diagram 2: Kinematic Chain"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Humanoid Kinematic Tree:\n\n                    [base_link/torso]\n                           |\n        +------------------+------------------+\n        |                  |                  |\n    [left_leg]         [right_leg]         [arms & head]\n        |                  |                  |\n    [hip_yaw]          [hip_yaw]          [shoulders...]\n        |                  |\n    [hip_roll]         [hip_roll]\n        |                  |\n    [hip_pitch]        [hip_pitch]\n        |                  |\n    [knee]             [knee]\n        |                  |\n    [ankle_pitch]      [ankle_pitch]\n        |                  |\n    [ankle_roll]       [ankle_roll]\n        |                  |\n    [foot]             [foot]\n\nForward Kinematics Example (right arm):\n    Joint Angles: \u03b8 = [\u03b8_shoulder_pitch, \u03b8_shoulder_roll, \u03b8_shoulder_yaw, \u03b8_elbow]\n                                    \u2193\n    Transformations: T_base\u2192hand = T\u2080 \xd7 T\u2081(\u03b8_sp) \xd7 T\u2082(\u03b8_sr) \xd7 T\u2083(\u03b8_sy) \xd7 T\u2084(\u03b8_e)\n                                    \u2193\n    Hand Pose: [x, y, z, roll, pitch, yaw] in base frame\n\nInverse Kinematics Example:\n    Desired Hand Pose: [x, y, z, roll, pitch, yaw]\n                                    \u2193\n    Solver (analytical or numerical optimization)\n                                    \u2193\n    Joint Angles: \u03b8 = [\u03b8_shoulder_pitch, \u03b8_shoulder_roll, \u03b8_shoulder_yaw, \u03b8_elbow]\n"})}),"\n",(0,s.jsx)(e.h3,{id:"diagram-3-tf2-transform-tree",children:"Diagram 3: tf2 Transform Tree"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:'Transform Tree for Humanoid:\n\n[map] (global reference)\n  \u2193 (localization correction)\n[odom] (odometry frame)\n  \u2193 (odometry estimate)\n[base_link] (robot base)\n  \u2193\n[torso]\n  \u251c\u2500 [head]\n  \u2502    \u251c\u2500 [camera_left]\n  \u2502    \u251c\u2500 [camera_right]\n  \u2502    \u2514\u2500 [lidar]\n  \u2502\n  \u251c\u2500 [left_shoulder]\n  \u2502    \u2193\n  \u2502  [left_upper_arm]\n  \u2502    \u2193\n  \u2502  [left_forearm]\n  \u2502    \u2193\n  \u2502  [left_hand]\n  \u2502    \u2514\u2500 [left_gripper]\n  \u2502\n  \u251c\u2500 [right_shoulder]\n  \u2502    \u2193\n  \u2502  [right_upper_arm]\n  \u2502    \u2193\n  \u2502  [right_forearm]\n  \u2502    \u2193\n  \u2502  [right_hand]\n  \u2502    \u2514\u2500 [right_gripper]\n  \u2502\n  \u251c\u2500 [left_hip]\n  \u2502    \u2193\n  \u2502  [left_upper_leg]\n  \u2502    \u2193\n  \u2502  [left_lower_leg]\n  \u2502    \u2193\n  \u2502  [left_foot]\n  \u2502\n  \u2514\u2500 [right_hip]\n       \u2193\n     [right_upper_leg]\n       \u2193\n     [right_lower_leg]\n       \u2193\n     [right_foot]\n\nTransform Lookup Example:\nQuery: "camera_left to right_hand"\nPath: camera_left \u2192 head \u2192 torso \u2192 right_shoulder \u2192 ... \u2192 right_hand\nResult: Translation [x,y,z] and Rotation [qx,qy,qz,qw] at timestamp t\n'})}),"\n",(0,s.jsx)(e.h3,{id:"diagram-4-ros2_control-architecture",children:"Diagram 4: ros2_control Architecture"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"ros2_control Framework:\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  ROS 2 Ecosystem                    \u2502\n\u2502  [Motion Planners] [Nav Stack] [Teleoperation]     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502 (topics, actions, services)\n                 \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             Controller Manager                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Controllers:                                \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502\n\u2502  \u2502  \u2502Joint Trajectory \u2502  \u2502 Position Control \u2502  \u2502  \u2502\n\u2502  \u2502  \u2502   Controller    \u2502  \u2502                  \u2502  \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  \u2502\n\u2502  \u2502           \u2502                    \u2502            \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502\n\u2502  \u2502  \u2502Joint State      \u2502  \u2502 Effort Control   \u2502  \u2502  \u2502\n\u2502  \u2502  \u2502  Broadcaster    \u2502  \u2502                  \u2502  \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                 \u2193 (command/state interfaces)       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502           Hardware Interface                 \u2502  \u2502\n\u2502  \u2502  - Read joint states (position, vel, effort) \u2502  \u2502\n\u2502  \u2502  - Write joint commands                      \u2502  \u2502\n\u2502  \u2502  - Abstract hardware specifics               \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502 (hardware-specific protocol)\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Physical Hardware                      \u2502\n\u2502  [Motor Drivers] [Encoders] [Force Sensors]        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nData Flow:\n1. Planner sends trajectory \u2192 Controller Manager\n2. Controller Manager activates Joint Trajectory Controller\n3. Controller computes control commands\n4. Hardware Interface writes commands to motors\n5. Hardware Interface reads joint states from encoders\n6. Joint State Broadcaster publishes to /joint_states\n7. robot_state_publisher uses /joint_states to update tf2\n"})}),"\n",(0,s.jsx)(e.h3,{id:"diagram-5-ai-to-control-architecture",children:"Diagram 5: AI-to-Control Architecture"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:'Hierarchical AI-to-Control Architecture:\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Level 1: AI Agent (High-Level Reasoning)            \u2502\n\u2502  - Large Language Model                             \u2502\n\u2502  - Vision Transformers                              \u2502\n\u2502  - Task Planning                                    \u2502\n\u2502  Frequency: 1-10 Hz | Hardware: GPU                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502 (goals: "grasp cup", "walk to kitchen")\n                 \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Level 2: Motion Planning (Mid-Level)                \u2502\n\u2502  - Path Planning (RRT, A*)                          \u2502\n\u2502  - Inverse Kinematics                               \u2502\n\u2502  - Collision Avoidance                              \u2502\n\u2502  Frequency: 10-50 Hz | Hardware: CPU                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502 (trajectories: joint waypoints + timing)\n                 \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Level 3: Controllers (Low-Level)                    \u2502\n\u2502  - PID Controllers                                  \u2502\n\u2502  - Balance Controller                               \u2502\n\u2502  - Trajectory Execution                             \u2502\n\u2502  Frequency: 100-1000 Hz | Hardware: RT CPU/MCU      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502 (motor commands: torques, voltages)\n                 \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Level 4: Hardware                                   \u2502\n\u2502  - Motor Drivers                                    \u2502\n\u2502  - Actuators                                        \u2502\n\u2502  - Sensors                                          \u2502\n\u2502  Frequency: 1-10 kHz | Hardware: Motor Electronics  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nFeedback Loop:\n[Sensors] \u2192 [State Estimation] \u2192 [Perception] \u2192 [AI Agent]\n    \u2191                                                 \u2193\n[Hardware] \u2190 [Controllers] \u2190 [Motion Planning] \u2190 [Goals]\n\nExample Data Flow (LLM-Controlled Humanoid):\nUser: "Pick up the red cup"\n    \u2193\n[LLM]: Understand intent, detect object, plan task\n    \u2193 (action goal: GraspObject)\n[Task Planner]: Decompose into motion primitives\n    \u2193 (action: MoveToPreGrasp)\n[Motion Planner]: Compute collision-free trajectory\n    \u2193 (FollowJointTrajectory action)\n[Controller]: Execute trajectory with feedback\n    \u2193 (joint torque commands)\n[Hardware]: Move arm to grasp pose\n'})}),"\n",(0,s.jsx)(e.h2,{id:"key-concepts-summary",children:"Key Concepts Summary"}),"\n",(0,s.jsx)(e.h3,{id:"urdf-unified-robot-description-format-1",children:"URDF (Unified Robot Description Format)"}),"\n",(0,s.jsx)(e.p,{children:"XML format describing robot structure: links (rigid bodies with geometry and inertia) and joints (connections with type, axis, limits)."}),"\n",(0,s.jsx)(e.h3,{id:"kinematic-chain",children:"Kinematic Chain"}),"\n",(0,s.jsx)(e.p,{children:"Series of rigid links connected by joints. Humanoids are kinematic trees with torso as root."}),"\n",(0,s.jsx)(e.h3,{id:"forward-kinematics-1",children:"Forward Kinematics"}),"\n",(0,s.jsx)(e.p,{children:"Computing end effector pose from joint angles. Straightforward matrix multiplication through chain."}),"\n",(0,s.jsx)(e.h3,{id:"inverse-kinematics-1",children:"Inverse Kinematics"}),"\n",(0,s.jsx)(e.p,{children:"Computing joint angles needed to achieve target end effector pose. More challenging, may have multiple or no solutions."}),"\n",(0,s.jsx)(e.h3,{id:"tf2",children:"tf2"}),"\n",(0,s.jsx)(e.p,{children:"ROS 2 transform library managing coordinate frames and transformations. Maintains transform tree, provides lookup and broadcasting."}),"\n",(0,s.jsx)(e.h3,{id:"robot_state_publisher-1",children:"robot_state_publisher"}),"\n",(0,s.jsx)(e.p,{children:"Node that computes and publishes transforms for all robot links based on URDF and joint states."}),"\n",(0,s.jsx)(e.h3,{id:"ros2_control",children:"ros2_control"}),"\n",(0,s.jsx)(e.p,{children:"Framework for robot control providing hardware abstraction, controller management, and real-time support."}),"\n",(0,s.jsx)(e.h3,{id:"hardware-interface",children:"Hardware Interface"}),"\n",(0,s.jsx)(e.p,{children:"Layer in ros2_control that communicates with physical hardware, reading states and writing commands."}),"\n",(0,s.jsx)(e.h3,{id:"controller",children:"Controller"}),"\n",(0,s.jsx)(e.p,{children:"Component implementing control algorithm. Reads states, computes commands, writes to hardware interface."}),"\n",(0,s.jsx)(e.h3,{id:"rviz2",children:"RViz2"}),"\n",(0,s.jsx)(e.p,{children:"3D visualization tool for ROS 2. Displays robot models, sensor data, coordinate frames, and debug information."}),"\n",(0,s.jsx)(e.h2,{id:"knowledge-checkpoint",children:"Knowledge Checkpoint"}),"\n",(0,s.jsx)(e.p,{children:"Test your understanding of this chapter's concepts:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"URDF Understanding:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Explain the difference between visual geometry and collision geometry in URDF. Why are they separated?"}),"\n",(0,s.jsx)(e.li,{children:"A humanoid arm has shoulder (3 DOF), elbow (1 DOF), and wrist (3 DOF). How many joints would you define in URDF?"}),"\n",(0,s.jsx)(e.li,{children:"Why are accurate inertial properties critical for physics simulation?"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Kinematics:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"What is the difference between forward kinematics and inverse kinematics?"}),"\n",(0,s.jsx)(e.li,{children:"A humanoid with 7-DOF arms (redundant) reaches for an object. Why might multiple joint configurations achieve the same hand pose?"}),"\n",(0,s.jsx)(e.li,{children:"Explain why the Jacobian matrix is important for robot control."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Transform Management:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Draw the transform tree for a humanoid robot including map, odom, base, and sensor frames."}),"\n",(0,s.jsx)(e.li,{children:"Why is tf2 necessary? Why not just compute transforms directly in each node?"}),"\n",(0,s.jsx)(e.li,{children:"Explain the difference between static and dynamic transforms. Give examples of each."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"robot_state_publisher:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"What are the inputs and outputs of robot_state_publisher?"}),"\n",(0,s.jsx)(e.li,{children:"Why is robot_state_publisher essential for visualization and motion planning?"}),"\n",(0,s.jsx)(e.li,{children:"When would you use joint_state_publisher versus getting joint states from hardware?"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"ros2_control:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Explain the three layers of ros2_control architecture: hardware interface, controller manager, controllers."}),"\n",(0,s.jsx)(e.li,{children:"Why is exclusive controller access important (preventing multiple controllers from writing to same joint)?"}),"\n",(0,s.jsx)(e.li,{children:"What is the difference between position control, velocity control, and effort (torque) control?"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"AI Integration:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Design a four-level hierarchy for an LLM-controlled humanoid: AI agent, motion planning, control, hardware. Specify frequency and data flow for each level."}),"\n",(0,s.jsx)(e.li,{children:"Why can't an AI agent directly command motor torques at 1 Hz for a balancing humanoid?"}),"\n",(0,s.jsx)(e.li,{children:"Propose an architecture for integrating a learned RL policy (trained at 50 Hz) with ros2_control."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Visualization:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"What is the difference between RViz2 and Gazebo?"}),"\n",(0,s.jsx)(e.li,{children:"List five types of data you would visualize in RViz2 when debugging a humanoid navigation system."}),"\n",(0,s.jsx)(e.li,{children:"How do visualization markers help debug motion planning?"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"chapter-summary",children:"Chapter Summary"}),"\n",(0,s.jsx)(e.p,{children:"This chapter explored ROS 2 tools and patterns specific to humanoid robotics:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"URDF:"})," The Unified Robot Description Format represents robot structure through links (rigid bodies with geometry and inertia) and joints (connections with type, axis, limits). Xacro adds programmability to reduce repetition. Accurate URDF is essential for simulation, planning, and visualization."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Kinematic Chains:"})," Humanoids are kinematic trees with serial chains for limbs. Forward kinematics computes end effector poses from joint angles; inverse kinematics (more challenging) computes joint angles for target poses. The Jacobian relates joint velocities to end effector velocities."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"tf2 Transform System:"})," Manages coordinate frames and transformations in tree structure. Static transforms (sensor mounts) publish once; dynamic transforms (joint angles, robot pose) publish continuously. Transform lookup finds paths through tree and computes combined transformations."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"robot_state_publisher:"})," Central node that computes and publishes transforms for all robot links based on URDF and current joint states. Essential for visualization, planning, and control."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"ros2_control:"})," Framework for robot control with hardware abstraction, controller management, and real-time support. Three layers: hardware interface (talks to motors/sensors), controller manager (orchestrates controllers), controllers (implement control algorithms)."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"AI-to-Control Integration:"})," Hierarchical architecture bridges high-level AI (goals at 1-10 Hz) to low-level control (motor commands at 100-1000 Hz). Motion planning layer translates goals into trajectories; controllers execute trajectories with feedback."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"RViz2 Visualization:"})," 3D tool for visualizing robot models, sensor data, coordinate frames, and planning outputs. Essential for development and debugging. Complements physics simulators (which simulate dynamics, not just visualize)."]}),"\n",(0,s.jsx)(e.p,{children:"These humanoid-specific tools build on ROS 2 foundations to enable sophisticated robot systems."}),"\n",(0,s.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Official Documentation:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"URDF Tutorials (wiki.ros.org/urdf)"}),"\n",(0,s.jsx)(e.li,{children:"tf2 Documentation (docs.ros.org)"}),"\n",(0,s.jsx)(e.li,{children:"ros2_control Documentation"}),"\n",(0,s.jsx)(e.li,{children:"RViz2 User Guide"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Books:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:'"Modern Robotics" by Lynch and Park (kinematics and dynamics)'}),"\n",(0,s.jsx)(e.li,{children:'"Robotics: Modelling, Planning and Control" by Siciliano et al.'}),"\n",(0,s.jsx)(e.li,{children:'"Springer Handbook of Robotics" (comprehensive reference)'}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Papers:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:'"URDF: The Unified Robot Description Format" (Willow Garage)'}),"\n",(0,s.jsx)(e.li,{children:'"ros_control: A Generic and Simple Control Framework for ROS"'}),"\n",(0,s.jsx)(e.li,{children:'"tf: The Transform Library" (Foote)'}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Online Resources:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"MoveIt 2 Tutorials (motion planning with ros2_control)"}),"\n",(0,s.jsx)(e.li,{children:"Gazebo tutorials with ros2_control"}),"\n",(0,s.jsx)(e.li,{children:"ROS 2 Control Demos (ros-controls/ros2_control_demos)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Tools:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"check_urdf: Validate URDF syntax"}),"\n",(0,s.jsx)(e.li,{children:"urdf_to_graphiz: Visualize kinematic tree"}),"\n",(0,s.jsx)(e.li,{children:"robot_state_publisher documentation"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"looking-ahead",children:"Looking Ahead"}),"\n",(0,s.jsx)(e.p,{children:"With understanding of humanoid-specific ROS 2 tools, we now turn to physics simulation. The next chapter explores Gazebo and Isaac Sim\u2014physics engines that simulate robot dynamics, sensors, and environments. Simulation enables developing and testing humanoid behaviors safely before deployment to hardware, and provides environments for training learned policies. The URDF, tf2, and ros2_control concepts from this chapter integrate directly into these simulation platforms."})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}}}]);
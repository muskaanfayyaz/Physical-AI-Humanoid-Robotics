<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-chapters/chapter-13-manipulation-and-grasping" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Chapter 13: Manipulation and Grasping | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/chapters/chapter-13-manipulation-and-grasping"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Chapter 13: Manipulation and Grasping | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Introduction"><meta data-rh="true" property="og:description" content="Introduction"><link data-rh="true" rel="icon" href="/Physical-AI-Humanoid-Robotics/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/chapters/chapter-13-manipulation-and-grasping"><link data-rh="true" rel="alternate" href="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/chapters/chapter-13-manipulation-and-grasping" hreflang="en"><link data-rh="true" rel="alternate" href="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/chapters/chapter-13-manipulation-and-grasping" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Chapter 13: Manipulation and Grasping","item":"https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/chapters/chapter-13-manipulation-and-grasping"}]}</script><link rel="stylesheet" href="/Physical-AI-Humanoid-Robotics/assets/css/styles.f1b00d5d.css">
<script src="/Physical-AI-Humanoid-Robotics/assets/js/runtime~main.f590ba4e.js" defer="defer"></script>
<script src="/Physical-AI-Humanoid-Robotics/assets/js/main.832ee6b9.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Physical-AI-Humanoid-Robotics/"><div class="navbar__logo"><img src="/Physical-AI-Humanoid-Robotics/img/logo-transparent.png" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Physical-AI-Humanoid-Robotics/img/logo-transparent.png" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a class="navbar__item navbar__link" href="/Physical-AI-Humanoid-Robotics/">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/muskaanfayyaz/Physical-AI-Humanoid-Robotics" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Physical-AI-Humanoid-Robotics/"><span title="About" class="linkLabel_WmDU">About</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-01-introduction-to-physical-ai"><span title="Weeks 1-2: Foundations" class="categoryLinkLabel_W154">Weeks 1-2: Foundations</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-03-introduction-to-ros2"><span title="Weeks 3-5: ROS 2 Fundamentals" class="categoryLinkLabel_W154">Weeks 3-5: ROS 2 Fundamentals</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-06-physics-simulation-with-gazebo"><span title="Weeks 6-7: Simulation" class="categoryLinkLabel_W154">Weeks 6-7: Simulation</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-08-nvidia-isaac-platform"><span title="Weeks 8-10: NVIDIA Isaac Platform" class="categoryLinkLabel_W154">Weeks 8-10: NVIDIA Isaac Platform</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-11-humanoid-robot-kinematics-and-dynamics"><span title="Weeks 11-12: Humanoid Development" class="categoryLinkLabel_W154">Weeks 11-12: Humanoid Development</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-11-humanoid-robot-kinematics-and-dynamics"><span title="Chapter 11: Humanoid Robot Kinematics and Dynamics" class="linkLabel_WmDU">Chapter 11: Humanoid Robot Kinematics and Dynamics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-12-bipedal-locomotion-and-balance"><span title="Chapter 12: Bipedal Locomotion and Balance" class="linkLabel_WmDU">Chapter 12: Bipedal Locomotion and Balance</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-13-manipulation-and-grasping"><span title="Chapter 13: Manipulation and Grasping" class="linkLabel_WmDU">Chapter 13: Manipulation and Grasping</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-14-natural-human-robot-interaction"><span title="Chapter 14: Natural Human-Robot Interaction" class="linkLabel_WmDU">Chapter 14: Natural Human-Robot Interaction</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-15-conversational-robotics"><span title="Week 13: Conversational AI" class="categoryLinkLabel_W154">Week 13: Conversational AI</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-16-sim-to-real-transfer"><span title="Final Weeks: Deployment &amp; Capstone" class="categoryLinkLabel_W154">Final Weeks: Deployment &amp; Capstone</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/appendix-a-hardware-setup-guides"><span title="Reference Materials" class="categoryLinkLabel_W154">Reference Materials</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Physical-AI-Humanoid-Robotics/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Weeks 11-12: Humanoid Development</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Chapter 13: Manipulation and Grasping</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Chapter 13: Manipulation and Grasping</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>The ability to grasp and manipulate objects distinguishes truly capable robots from those limited to observation and locomotion. A humanoid that can walk but cannot pick up objects, open doors, or use tools remains severely limited in its utility. Manipulation transforms passive observers into active participants in the physical world, enabling robots to modify their environment and accomplish complex tasks.</p>
<p>Grasping presents unique challenges that differ fundamentally from locomotion. While walking involves intermittent contact with predictable surfaces (the ground), manipulation requires establishing and maintaining stable contact with diverse objects of varying shapes, sizes, materials, and weights. A hand must apply sufficient force to prevent slipping while avoiding crushing fragile items. Fingers must coordinate precisely to maintain force closure while adapting to object geometry.</p>
<p>Anthropomorphic hands, inspired by human hand anatomy, provide remarkable versatility through many degrees of freedom and distributed tactile sensing. However, this versatility comes with control complexity: coordinating 15-20 joints to perform smooth, stable grasps requires sophisticated planning and feedback. Understanding grasp stability, force distribution, and tactile feedback enables effective use of these capable manipulators.</p>
<p>This chapter explores the principles and techniques underlying robotic manipulation and grasping. We begin with anthropomorphic hand design, examining the mechanical structures that enable dexterous manipulation. Grasp taxonomies categorize the wide variety of hand-object interactions humans naturally employ. The mathematics of force closure provides rigorous criteria for grasp stability. We investigate grasp planning algorithms that select finger placements and contact forces, explore in-hand manipulation for reorienting grasped objects, and examine bi-manual coordination where two arms work together.</p>
<p>By understanding these concepts, you will grasp (pun intended) how humanoid robots achieve dexterous manipulation, why certain grasps succeed while others fail, and how motion planning, force control, and tactile feedback integrate to enable robust object interaction in unstructured environments.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="core-concepts">Core Concepts<a href="#core-concepts" class="hash-link" aria-label="Direct link to Core Concepts" title="Direct link to Core Concepts" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="anthropomorphic-hand-design-principles">Anthropomorphic Hand Design Principles<a href="#anthropomorphic-hand-design-principles" class="hash-link" aria-label="Direct link to Anthropomorphic Hand Design Principles" title="Direct link to Anthropomorphic Hand Design Principles" translate="no">​</a></h3>
<p>Human hands achieve remarkable dexterity through a sophisticated mechanical design: 27 bones, over 30 joints, numerous muscles and tendons, and rich tactile sensing across the palm and fingertips. Anthropomorphic robotic hands seek to replicate this capability through similar kinematic structures and actuation strategies.</p>
<p>The typical humanoid hand features four fingers and an opposable thumb, arranged to provide both power grasps (full-hand grips on large objects) and precision grasps (fingertip control of small objects). Each finger generally contains three joints: the metacarpophalangeal (MCP) joint at the base, proximal interphalangeal (PIP) joint in the middle, and distal interphalangeal (DIP) joint near the fingertip. The thumb includes similar joints but with different orientations enabling opposition.</p>
<p>Underactuation plays a central role in practical hand designs. Fully actuating every joint would require one motor per joint, creating hands too heavy and complex for most applications. Instead, clever mechanical coupling allows fewer motors to drive multiple joints. For instance, tendons routed through multiple finger segments distribute one motor&#x27;s torque across several joints, with springs providing passive compliance.</p>
<p>The Shadow Dexterous Hand exemplifies high-fidelity anthropomorphic design with 20 degrees of freedom and individual actuation of most joints. Air muscles provide compliant actuation resembling biological muscle. Rich tactile sensing covers the palm and fingertips. This design prioritizes capability over simplicity, suitable for research exploring the limits of dexterous manipulation.</p>
<p>Alternatively, the Barrett Hand demonstrates effective underactuated design with only four motors controlling eight degrees of freedom. Three fingers with two joints each use differential mechanisms that automatically adapt finger posture to object shape. This design prioritizes robustness and practical grasping capability, suitable for industrial and service applications.</p>
<p>The choice between full actuation and underactuation involves fundamental trade-offs. Full actuation provides precise control of each joint, enabling complex manipulations but requiring more motors, power, and control complexity. Underactuation achieves robust grasping with fewer resources by exploiting passive adaptation but limits control authority for complex in-hand manipulation.</p>
<p>Material selection significantly impacts hand performance. Rigid links provide precise position control but can damage objects during contact. Compliant materials absorb impact and conform to object geometry but complicate position control. Hybrid designs use rigid structures for primary kinematics with compliant coverings on contact surfaces, balancing control precision with contact safety.</p>
<p>Sensor integration enables feedback-driven grasping. Tactile sensors at fingertips detect contact forces and slip. Joint encoders measure finger configurations. Force/torque sensors at the wrist measure overall hand loading. Integrating these sensing modalities provides comprehensive awareness of hand-object interaction essential for stable manipulation.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="grasp-taxonomies">Grasp Taxonomies<a href="#grasp-taxonomies" class="hash-link" aria-label="Direct link to Grasp Taxonomies" title="Direct link to Grasp Taxonomies" translate="no">​</a></h3>
<p>Human grasping exhibits remarkable diversity: we use vastly different hand configurations when holding a pencil, carrying a briefcase, opening a jar, or handling fragile objects. Categorizing this diversity helps organize understanding and guide robotic grasp selection.</p>
<p>The Cutkosky taxonomy, developed through observation of human manufacturing tasks, categorizes grasps into power grasps, precision grasps, and intermediate types. Power grasps use the entire hand including palm to firmly secure objects, prioritizing stability over fine control. Precision grasps use fingertips without palm contact, prioritizing dexterity over maximum force.</p>
<p>Power grasps include the cylindrical grasp (wrapping fingers around a cylinder), spherical grasp (fingers distributed around a ball), and hook grasp (fingers curled to support object weight). These grasps generate large forces and resist disturbances well but offer limited ability to manipulate the grasped object.</p>
<p>Precision grasps include the pinch grasp (thumb opposing one or two fingers), tripod grasp (thumb, index, and middle finger forming a triangle), and lateral grasp (thumb pressing against the side of the index finger). These grasps enable fine position and orientation control but generate less force and are more sensitive to disturbances.</p>
<p>The Feix taxonomy extends this classification, identifying 33 distinct grasp types based on detailed analysis of human grasping. While comprehensive, this detailed taxonomy can overwhelm practical robot implementation. Most robotic systems focus on a subset of fundamental grasp types applicable to common manipulation tasks.</p>
<p>Beyond geometric classification, grasps can be categorized by stability properties. Form-closure grasps constrain all object motions through purely geometric contact, independent of friction. These represent the ideal stable grasp but require complex finger positioning. Force-closure grasps prevent object motion through appropriate contact forces, relying on friction. Most practical robotic grasps achieve force closure rather than form closure.</p>
<p>Enveloping versus fingertip grasps represent another important distinction. Enveloping grasps use large contact areas including palm and multiple finger segments, distributing forces widely. Fingertip grasps use small contact regions at fingertips, providing better control but concentrating forces. The choice depends on object fragility, required manipulation precision, and grasp stability requirements.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="force-closure-and-grasp-stability">Force Closure and Grasp Stability<a href="#force-closure-and-grasp-stability" class="hash-link" aria-label="Direct link to Force Closure and Grasp Stability" title="Direct link to Force Closure and Grasp Stability" translate="no">​</a></h3>
<p>A fundamental question underlies all grasping: will the hand maintain secure contact with the object under expected disturbances? Force closure provides the mathematical framework for answering this question rigorously.</p>
<p>A grasp achieves force closure if the contact forces and torques can resist arbitrary external forces and torques on the object. More precisely, the contacts must be able to generate any wrench (combined force and torque vector) within some region around zero. This ensures the hand can counteract disturbances from any direction.</p>
<p>The condition for force closure depends on contact models. Point contacts with friction can exert forces within a friction cone: the contact force must have a component normal to the surface (pushing, not pulling) and tangential components limited by the coefficient of friction. For a friction coefficient mu, the tangential force magnitude must not exceed mu times the normal force magnitude.</p>
<p>With k contact points, each can exert forces within its friction cone. The grasp achieves force closure if the union of all possible contact force combinations can generate any net wrench on the object. Mathematically, this requires the grasp matrix (mapping contact forces to object wrenches) to have certain properties related to its rank and positive spanning.</p>
<p>For planar grasping (2D), at least three contacts with friction are necessary for force closure, arranged so their normals don&#x27;t intersect at a common point. For spatial grasping (3D), at least four contacts with friction are generally necessary, with geometric conditions ensuring they span the wrench space.</p>
<p>Form closure represents a special case where contact geometry alone prevents object motion, without requiring friction. This requires more contacts (at least seven for general 3D objects with point contacts) but provides grasp stability independent of friction coefficient. Form closure is difficult to achieve with typical robotic hands but represents the theoretical ideal.</p>
<p>Grasp stability also depends on object dynamics. A static analysis considers force balance under constant external forces. A dynamic analysis includes inertial effects from object acceleration and impact forces during manipulation. Dynamic stability is generally more challenging, requiring larger safety margins in contact forces.</p>
<p>The concept of grasp equilibrium provides another perspective. A grasped object is in equilibrium if the sum of contact forces and external forces (including gravity) equals zero, and the sum of contact torques and external torques equals zero. Force closure ensures that for any external wrench, contact forces can be found that restore equilibrium.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="grasp-quality-metrics">Grasp Quality Metrics<a href="#grasp-quality-metrics" class="hash-link" aria-label="Direct link to Grasp Quality Metrics" title="Direct link to Grasp Quality Metrics" translate="no">​</a></h3>
<p>While force closure provides a binary yes/no answer to grasp stability, quality metrics quantify how good a force-closure grasp is. Better grasps resist larger disturbances, require less contact force, or provide more manipulation capability.</p>
<p>The epsilon quality metric measures the largest disturbance wrench the grasp can resist before failure. Compute the minimum over all directions of the maximum disturbance magnitude the grasp can counteract. Larger epsilon indicates better grasp quality. This metric directly relates to robustness: higher quality grasps tolerate larger disturbances without losing contact.</p>
<p>Computing epsilon quality requires optimization. For each potential disturbance direction, solve for the maximum disturbance magnitude such that contact forces remain within their friction cones while balancing the disturbance. The minimum across all directions gives epsilon. This computation can be expensive but provides meaningful physical interpretation.</p>
<p>The Ferrari-Canny metric takes a related approach based on the grasp wrench space (the set of all wrenches the grasp can apply to the object). The metric equals the radius of the largest ball centered at the origin that fits entirely within the grasp wrench space. Larger radii indicate the grasp can exert larger forces uniformly in all directions.</p>
<p>Volume-based metrics measure the volume of the grasp wrench space, with larger volumes indicating greater overall capability. These metrics are easier to compute than epsilon or Ferrari-Canny but don&#x27;t directly measure worst-case performance in the weakest direction.</p>
<p>Manipulability measures how easily the grasped object can be moved and reoriented. Analogous to manipulability for robot arms, grasp manipulability depends on the grasp Jacobian relating finger velocities to object velocities. Well-conditioned Jacobians enable easy object manipulation; poorly conditioned ones create directions where object motion is difficult.</p>
<p>Task-specific metrics evaluate grasps relative to particular manipulation goals. A grasp for carrying a heavy object should maximize force capability in the vertical direction. A grasp for precise insertion should maximize orientation control about certain axes. Optimizing task-specific metrics produces grasps well-suited to their intended use.</p>
<p>Multiple metrics can be combined to balance different objectives. A weighted sum might include stability (epsilon quality), efficiency (required contact forces), and manipulability. Multi-objective optimization can identify Pareto-optimal grasps that cannot be improved in one metric without degrading another.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="tactile-sensing-and-feedback">Tactile Sensing and Feedback<a href="#tactile-sensing-and-feedback" class="hash-link" aria-label="Direct link to Tactile Sensing and Feedback" title="Direct link to Tactile Sensing and Feedback" translate="no">​</a></h3>
<p>Vision provides crucial information for identifying objects and planning grasps, but tactile feedback becomes essential once contact begins. Touch reveals contact forces, object surface properties, slip detection, and shape information not accessible to vision (occluded surfaces, transparent objects, fine texture).</p>
<p>Tactile sensor technologies vary widely. Force-sensing resistors (FSRs) change resistance under applied force, providing simple, inexpensive force measurement but with limited spatial resolution. Capacitive sensors detect changes in capacitance from deformation, enabling high spatial resolution in slim packages. Optical tactile sensors use cameras to observe deformation of compliant surfaces, achieving very high resolution but requiring more space and processing.</p>
<p>BioTac sensors, inspired by human fingertips, combine multiple sensing modalities in a single package: force-sensitive electrodes detect contact forces and vibrations, a pressure sensor measures overall loading, and temperature sensors detect heat transfer. This multi-modal approach provides rich tactile information analogous to human touch.</p>
<p>Spatial resolution determines what features can be detected through touch. High-resolution sensor arrays (spacing below 1mm) can detect fine textures and small objects. Lower resolution sensors (5-10mm spacing) suffice for grasp stability monitoring but miss fine details. Trade-offs involve cost, wiring complexity, and data processing requirements.</p>
<p>Slip detection enables reactive grasp adjustment. When an object begins slipping, tangential forces at the contact change and vibrations occur. High-frequency tactile sensing (hundreds to thousands of Hz) can detect these signatures. Upon detecting slip, the controller increases grip force to restore stability before the object fully escapes.</p>
<p>Force control uses tactile feedback to regulate contact forces. The controller measures actual contact forces and compares them to desired values, adjusting motor commands to minimize error. This enables gentle grasping of fragile objects (minimal force) and firm grasping of heavy objects (sufficient force to prevent slip).</p>
<p>Tactile servoing uses tactile feedback to guide manipulation. Just as visual servoing uses vision to control motion, tactile servoing uses touch. For example, sliding a grasped object along a surface while maintaining constant contact force, or exploring object shape by moving fingers along its surface while monitoring contact.</p>
<p>Multi-modal integration combines vision and touch. Vision initially guides the hand toward the object. When contact begins, tactile feedback takes over for fine adjustment. During manipulation, vision tracks object motion while touch monitors contact stability. This sensory fusion provides robust perception despite individual sensor limitations.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="grasp-planning-algorithms">Grasp Planning Algorithms<a href="#grasp-planning-algorithms" class="hash-link" aria-label="Direct link to Grasp Planning Algorithms" title="Direct link to Grasp Planning Algorithms" translate="no">​</a></h3>
<p>Selecting where to place fingers and how much force to apply constitutes the grasp planning problem. Given an object model (shape, mass, friction), find contact locations and forces that achieve force closure, optimize quality metrics, and are kinematically reachable.</p>
<p>Analytical grasp planning uses geometric reasoning to identify candidate grasps. For simple shapes (cylinders, boxes, spheres), geometric rules directly specify good contact locations. A cylindrical object: place fingers around the circumference equidistant from each other and from the cylinder axis. A box: contact flat faces opposing each other. These heuristics work well for common shapes but don&#x27;t extend to arbitrary complex objects.</p>
<p>Sampling-based grasp planning generates many candidate grasps by randomly sampling contact locations on the object surface, then evaluates each grasp&#x27;s quality. High-quality grasps are retained; poor grasps are discarded. Sampling continues until sufficient good grasps are found or time limits are reached.</p>
<p>The sampling process typically proceeds as follows: randomly select a point on the object surface as the first contact, select subsequent contacts satisfying geometric constraints (appropriate distance from first contact, contact normals pointing toward object interior), check force closure, compute quality metrics, and store the grasp if quality exceeds a threshold.</p>
<p>Thousands or millions of candidate grasps might be evaluated in offline planning. Fast quality metric computation becomes essential. Approximations and bounds can quickly eliminate obviously poor grasps before expensive exact evaluation.</p>
<p>Simulation-based approaches test grasps in physics simulators. Candidate grasps are applied to simulated objects, disturbances are applied, and stability is observed. Grasps that maintain stability under large disturbances are preferred. This approach naturally accounts for dynamics but requires accurate simulation and significant computation.</p>
<p>Learning-based grasp planning uses machine learning to predict grasp success from object features. Training datasets contain objects with labeled successful and failed grasps. Neural networks learn to map object representations (point clouds, images) to grasp quality predictions. At test time, the network evaluates candidate grasps without explicit geometric analysis.</p>
<p>Dexterous grasping planners must consider hand kinematics. A grasp might satisfy force closure and achieve high quality metrics but be unreachable due to kinematic constraints or collisions. The planner must verify that inverse kinematics can find a collision-free hand configuration achieving the desired contacts.</p>
<p>Grasp planning for complex hands with many degrees of freedom creates high-dimensional search spaces. Optimization-based approaches formulate grasp planning as a constrained optimization problem: maximize quality subject to force closure, kinematic reachability, and collision avoidance. Gradient-based optimization or derivative-free methods search this space for good solutions.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="in-hand-manipulation">In-Hand Manipulation<a href="#in-hand-manipulation" class="hash-link" aria-label="Direct link to In-Hand Manipulation" title="Direct link to In-Hand Manipulation" translate="no">​</a></h3>
<p>Once an object is grasped, repositioning or reorienting it without releasing and re-grasping constitutes in-hand manipulation. This advanced capability enables assembling parts, adjusting tool pose, and adapting to changing task requirements without interrupting the manipulation sequence.</p>
<p>Finger gaiting involves sequentially breaking and making contacts to walk fingers around an object. One or more fingers release contact, move to new positions, and re-establish contact while remaining fingers maintain grasp stability. By repeating this process, the hand can significantly reorient the object.</p>
<p>The challenge in finger gaiting lies in maintaining force closure throughout the motion sequence. When some fingers release, the remaining fingers must still achieve force closure. Planning finger gaiting requires identifying sequences of intermediate grasps that form a path through the space of stable grasps from initial to final configuration.</p>
<p>Rolling contacts allow object rotation without sliding. Fingers maintain contact while the object rotates against them, like a ball rolling on a surface. The no-slip constraint couples object rotation to finger motion. Coordinating multiple rolling contacts enables controlled object reorientation.</p>
<p>The kinematics of rolling contact are more complex than point contact. The contact point on the finger surface changes as the object rolls, and the contact normal direction changes. Forward kinematics must account for these geometric changes. Control must coordinate finger motions to achieve desired object rotation while maintaining rolling without slip.</p>
<p>Pivoting uses gravity or contact forces to rotate an object about one contact point. For example, grasping a long object at one end and tilting it to rotate about the grasp point. Pivoting is mechanically simple but limits reorientation to specific axes and requires managing dynamic effects.</p>
<p>Pushing and sliding intentionally allow controlled slip to reposition objects. Rather than preventing all slip through force closure, the controller permits and exploits slip in controlled directions. This can be more efficient than maintaining rigid grasps but requires careful force regulation and slip monitoring through tactile feedback.</p>
<p>Coordinating multiple fingers for in-hand manipulation requires solving a coupled control problem. Each finger&#x27;s motion affects the object pose, and desired object motion must be distributed among fingers. The manipulation Jacobian relates finger velocities to object velocities, analogous to the robot arm Jacobian relating joint velocities to end-effector velocities.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="bi-manual-coordination">Bi-Manual Coordination<a href="#bi-manual-coordination" class="hash-link" aria-label="Direct link to Bi-Manual Coordination" title="Direct link to Bi-Manual Coordination" translate="no">​</a></h3>
<p>Many tasks benefit from or require using both hands: carrying large objects, assembly operations with one hand positioning and one hand fastening, and cooperative manipulation where hands work together. Bi-manual coordination extends single-hand manipulation with additional complexity from coordinating two kinematic chains.</p>
<p>Task decomposition separates bi-manual tasks into roles for each arm. Symmetric tasks divide the task evenly (both hands lifting opposite ends of a table). Asymmetric tasks assign different roles (one hand holds a jar while the other opens the lid). Identifying appropriate decomposition simplifies planning and control.</p>
<p>Relative motion matters more than absolute motion in many bi-manual tasks. When two hands carry an object together, the object pose depends on the relative positions and orientations of the hands, not their absolute positions. Control formulations using relative coordinates naturally capture these constraints.</p>
<p>The bi-manual manipulation Jacobian maps joint velocities of both arms to object velocity. It combines the individual arm Jacobians accounting for how each hand&#x27;s motion contributes to object motion. Coordinated control uses this combined Jacobian to achieve desired object velocities through appropriate joint commands to both arms.</p>
<p>Force distribution between hands requires careful consideration. When both hands grasp an object, internal forces can occur: the hands push against each other through the object without changing the object&#x27;s net force or torque. These internal forces should be minimized for efficiency but sufficient to maintain grasp stability.</p>
<p>The grasp force optimization problem for bi-manual manipulation seeks to minimize internal forces while ensuring force closure and satisfying task requirements. The solution typically has a null space: many force distributions achieve the same net object wrench. Optimization selects among these based on secondary criteria like minimizing total force or balancing load between hands.</p>
<p>Bi-manual assembly operations require precise coordination. Peg-in-hole insertion with two hands might use one hand to position the peg and the other to provide stabilizing forces or guide the base. Success requires aligning multiple degrees of freedom within tight tolerances while managing contact forces.</p>
<p>Cooperative manipulation where two robots (or one dual-arm robot) work together extends bi-manual concepts. The robots must communicate their states and intentions, coordinate their motions through shared world models, and distribute tasks effectively. Decentralized control allows each robot to respond quickly to local information while coordination protocols ensure coherent joint behavior.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="dexterous-manipulation-challenges">Dexterous Manipulation Challenges<a href="#dexterous-manipulation-challenges" class="hash-link" aria-label="Direct link to Dexterous Manipulation Challenges" title="Direct link to Dexterous Manipulation Challenges" translate="no">​</a></h3>
<p>Despite advances in hand design, planning algorithms, and control techniques, dexterous manipulation remains significantly more challenging than human manipulation suggests it should be. Understanding these challenges guides research priorities and practical system design.</p>
<p>Modeling uncertainty limits grasp planning accuracy. Object properties (shape, mass distribution, friction coefficient, compliance) are never perfectly known. Small errors can cause planned force-closure grasps to fail or require more grip force than expected. Robust planning must account for uncertainty through conservative force margins or adaptive approaches that adjust based on feedback.</p>
<p>Contact dynamics present both theoretical and practical difficulties. Analytical contact models make simplifying assumptions (rigid bodies, Coulomb friction, point contacts) that real contacts violate. Actual contacts involve deformation, complex friction behavior, and distributed contact patches. Simulation struggles to accurately predict contact behavior, and control must handle this model mismatch.</p>
<p>High-dimensional control spaces challenge real-time manipulation control. A hand with 20 degrees of freedom controlled at 100 Hz generates 2000 control outputs per second, each potentially affecting grasp stability. Computing optimal or even feasible controls in real-time requires efficient algorithms and simplified models.</p>
<p>Perception limitations hinder grasp planning and execution. Vision occlusions hide contact surfaces. Tactile sensing provides only local information at contacts. Estimating object pose and properties from limited observations introduces uncertainty. Active perception strategies that move sensors to gain better views can help but require coordination with manipulation goals.</p>
<p>Generalization across object classes remains difficult. Humans effortlessly transfer manipulation skills from one object to novel similar objects. Robots typically require explicit planning for each object or extensive training data. Learning representations that capture manipulation-relevant object properties and enable effective generalization is an active research area.</p>
<p>Real-time adaptation distinguishes robust from brittle manipulation. Disturbances, modeling errors, and unexpected events constantly arise. Systems that can detect problems (through tactile and visual feedback), diagnose causes, and adjust plans or control strategies online exhibit far better practical performance than purely feedforward systems.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="practical-understanding">Practical Understanding<a href="#practical-understanding" class="hash-link" aria-label="Direct link to Practical Understanding" title="Direct link to Practical Understanding" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hand-design-trade-offs-in-practice">Hand Design Trade-offs in Practice<a href="#hand-design-trade-offs-in-practice" class="hash-link" aria-label="Direct link to Hand Design Trade-offs in Practice" title="Direct link to Hand Design Trade-offs in Practice" translate="no">​</a></h3>
<p>Designing a robotic hand requires balancing numerous competing objectives. High dexterity demands many actuated degrees of freedom, but each additional motor adds weight, cost, and control complexity. Underactuation reduces these burdens but limits manipulation capability.</p>
<p>The finger length ratio affects grasp capability. Longer fingers reach around larger objects and achieve better form closure on irregular shapes. Shorter fingers are lighter, faster, and fit in tighter spaces. Human finger proportions provide a reasonable default, but task-specific optimization might suggest different ratios.</p>
<p>Thumb opposition angle determines the types of grasps possible. A thumb opposing at 90 degrees to the fingers enables strong pinch grasps and power grasps. Different angles optimize different grasp types. Some designs include an additional thumb degree of freedom to adjust opposition angle based on the task.</p>
<p>Actuator placement involves choosing between motors in the hand (direct drive) or in the forearm with tendon transmission. Hand-mounted motors simplify kinematics but add weight at the end of the arm, reducing payload capacity and increasing inertia. Forearm motors with tendons reduce hand weight but introduce compliance, friction, and tendon routing complexity.</p>
<p>Tendon transmission provides smooth, compliant force transmission and enables underactuation through differential mechanisms. However, tendons stretch under load, creating position errors, and can break or slip. Routing tendons through multiple joints while avoiding interference with other components requires careful mechanical design.</p>
<p>Linkage-based underactuation uses mechanical linkages to couple multiple joints. As one motor drives the linkage, multiple joints move in coordinated patterns determined by the linkage geometry. Different linkage designs produce different coupling behaviors. Adjusting linkage parameters tunes the hand&#x27;s automatic adaptation to object shape.</p>
<p>Compliant fingertips improve grasping robustness. Soft materials conform to object surfaces, increasing contact area and friction. They absorb position errors and impact forces during contact. However, compliance complicates position control and force sensing. Hybrid designs use compliant coverings over rigid cores, balancing these trade-offs.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="computing-force-closure">Computing Force Closure<a href="#computing-force-closure" class="hash-link" aria-label="Direct link to Computing Force Closure" title="Direct link to Computing Force Closure" translate="no">​</a></h3>
<p>Verifying force closure for a proposed grasp requires checking whether contact forces can balance arbitrary external wrenches. This involves geometric and linear algebra computations on the grasp configuration.</p>
<p>The grasp matrix G maps contact forces to object wrenches. Each column of G corresponds to one contact and describes the wrench that contact exerts per unit contact force. For a 3D point contact with friction at position p with contact normal n, the column includes the force components (within the friction cone) and torques (from p × force).</p>
<p>Constructing the grasp matrix proceeds systematically:</p>
<ol>
<li class="">For each contact i, determine its position p_i and contact normal n_i</li>
<li class="">Define the friction cone based on friction coefficient mu</li>
<li class="">Represent forces within the cone using a basis (e.g., normal direction plus tangential directions)</li>
<li class="">Compute the wrench each basis force generates: [force; p × force]</li>
<li class="">Assemble all basis wrenches into columns of G</li>
</ol>
<p>The grasp achieves force closure if the origin lies in the interior of the convex hull of G&#x27;s columns (and their negatives, since contacts can push in any direction within their friction cone). Checking this condition involves solving a linear programming problem or using computational geometry algorithms.</p>
<p>A simpler necessary condition checks G&#x27;s rank: for 3D objects, G must have full rank 6, indicating the contacts span the 6D wrench space. This is necessary but not sufficient for force closure—the contacts must also satisfy geometric conditions ensuring positive combinations can generate any wrench.</p>
<p>For planar grasping (2D objects), the grasp matrix is 3×n for n contacts (force in x, y and torque about z). Force closure requires rank 3 and geometric conditions on contact locations. A common rule: three or more contacts with friction coefficients above a minimum threshold, with contact normals not intersecting at a common point.</p>
<p>Practically implementing force closure checking requires numerical stability considerations. Near-grazing contacts (nearly tangent to object surface) create nearly-degenerate grasp matrices. Small numerical errors can incorrectly classify nearly-force-closure grasps. Robust implementations use tolerances and condition number checks.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="grasp-quality-evaluation">Grasp Quality Evaluation<a href="#grasp-quality-evaluation" class="hash-link" aria-label="Direct link to Grasp Quality Evaluation" title="Direct link to Grasp Quality Evaluation" translate="no">​</a></h3>
<p>Once force closure is verified, quantifying grasp quality enables comparing alternative grasps. Computing quality metrics involves optimization over contact forces and disturbance wrenches.</p>
<p>For epsilon quality, the algorithm iterates over many disturbance directions (sampled uniformly on the unit sphere in wrench space). For each direction, solve an optimization problem:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">maximize: magnitude</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">subject to:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - Contact forces balance disturbance: G * f = magnitude * direction</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - Contact forces within friction cones: |f_tangential| ≤ mu * f_normal</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - Contact forces non-negative normal components: f_normal ≥ 0</span><br></span></code></pre></div></div>
<p>The minimum magnitude across all directions gives epsilon. Larger epsilon indicates the grasp resists larger disturbances.</p>
<p>Computing Ferrari-Canny quality requires finding the largest ball centered at the origin within the grasp wrench space. The radius equals the minimum distance from the origin to the boundary of the convex hull of achievable wrenches. This can be computed by solving linear programs for many wrench directions, finding which boundary is closest.</p>
<p>Volume-based metrics integrate over the grasp wrench space, computing its volume. For low-dimensional spaces, numerical integration or Monte Carlo sampling estimates the volume. Alternatively, convex hull algorithms can compute exact volumes.</p>
<p>Manipulability for grasping uses the grasp Jacobian J_g relating finger velocities to object velocities. The manipulability measure is sqrt(det(J_g * J_g^T)), analogous to robot arm manipulability. Large values indicate the grasped object can be moved easily in all directions.</p>
<p>Weighted combinations of metrics allow multi-criteria optimization:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">quality = w1 * epsilon + w2 * manipulability - w3 * force_magnitude</span><br></span></code></pre></div></div>
<p>Weights encode task priorities. Weights should be normalized to account for different metric scales. Multi-objective optimization can identify the Pareto frontier of grasps, presenting trade-offs for designer selection.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="implementing-grasp-planning">Implementing Grasp Planning<a href="#implementing-grasp-planning" class="hash-link" aria-label="Direct link to Implementing Grasp Planning" title="Direct link to Implementing Grasp Planning" translate="no">​</a></h3>
<p>A practical grasp planning system integrates object perception, candidate generation, evaluation, and execution. The pipeline typically follows these stages:</p>
<p>Object segmentation and pose estimation uses vision to identify the object to be grasped and estimate its 3D pose. Point clouds from depth cameras or stereo vision provide geometric information. Object recognition identifies the object class, retrieving shape models from a database.</p>
<p>Candidate grasp generation samples many possible grasps. For database approaches, retrieve pre-computed grasps for this object class and transform them to the current object pose. For sampling approaches, randomly select contact points on the object surface, construct hand configurations achieving these contacts, and check collisions.</p>
<p>A typical sampling iteration:</p>
<ol>
<li class="">Sample a point on the object surface as the first contact</li>
<li class="">Sample the hand approach direction (often along the surface normal)</li>
<li class="">Sample hand orientation about the approach direction</li>
<li class="">Position the hand to achieve the first contact</li>
<li class="">Close fingers according to the hand&#x27;s underactuation or coupling</li>
<li class="">Record final finger positions as contact points</li>
<li class="">Check for collisions between hand and object or environment</li>
</ol>
<p>Grasp evaluation computes quality metrics for each candidate. This is the computational bottleneck; evaluating thousands of candidates requires efficient implementation. Parallelization across CPU cores or GPU acceleration can dramatically speed evaluation.</p>
<p>Filtering removes infeasible grasps: those with insufficient quality, kinematic unreachability, or collisions. A hierarchical filtering approach first applies fast approximate checks to eliminate obviously bad grasps, then applies expensive exact checks only to promising candidates.</p>
<p>Ranking orders the remaining grasps by quality. The highest-quality grasp is selected for execution. Some systems maintain a ranked list and attempt grasps in order if the first fails.</p>
<p>Execution planning computes a motion plan from the current arm configuration to the pre-grasp pose (hand positioned near the object but not contacting), then to the grasp pose (fingers achieving contact). Motion planning uses techniques covered in Chapter 14 to avoid obstacles.</p>
<p>Grasp execution follows the planned motion until contact. Force/torque sensing or tactile feedback detects contact. The controller transitions from position control to force control, applying desired grip forces. Feedback monitors contact stability, adjusting forces if slip is detected.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="force-control-for-manipulation">Force Control for Manipulation<a href="#force-control-for-manipulation" class="hash-link" aria-label="Direct link to Force Control for Manipulation" title="Direct link to Force Control for Manipulation" translate="no">​</a></h3>
<p>Once a grasp is established, maintaining appropriate contact forces ensures stability without damaging objects. Force control adjusts motor commands based on sensed forces, closing the feedback loop around force rather than position.</p>
<p>Impedance control specifies a dynamic relationship between force and position: F = K * (x - x_d), where K is stiffness. The controller acts like a spring connecting the actual position x to the desired position x_d. When external forces push the hand, it complies according to the stiffness. High stiffness resists disturbances firmly; low stiffness provides compliant behavior.</p>
<p>Implementing impedance control requires force sensing and position control. Measure the contact force F. Compute the desired position x_d based on the commanded force and stiffness: x_d = x - K^(-1) * F. Command the position controller to move to x_d. As forces change, x_d adjusts, creating the desired force-position relationship.</p>
<p>Hybrid position/force control separates task space into position-controlled and force-controlled directions. For example, when grasping a box: control position in the direction parallel to the surface (sliding along it) and control force in the normal direction (pressing against it). The controller switches between position and force control based on the task space direction.</p>
<p>The selection matrix S determines which directions use force control (S_f) and which use position control (S_p). Typically S_f and S_p are diagonal matrices with ones in controlled directions and zeros elsewhere, and S_p + S_f = I.</p>
<p>Grasp force optimization distributes contact forces among multiple fingers to achieve desired net object wrench while minimizing effort. The optimization problem:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">minimize: sum of squared contact forces</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">subject to:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - Net object wrench equals desired: G * f = w_desired</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - Forces within friction cones</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - Non-negative normal forces</span><br></span></code></pre></div></div>
<p>The solution balances load across fingers and uses friction efficiently. For redundant grasps (more contacts than necessary), the null space allows adjusting internal forces without changing net wrench.</p>
<p>Tactile servoing uses tactile feedback for fine manipulation. The controller monitors contact force magnitudes and locations, adjusting finger positions to achieve desired contact patterns. This enables tasks like sliding along an edge (maintaining constant edge contact) or surface exploration (scanning fingers across a surface).</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="in-hand-manipulation-implementation">In-Hand Manipulation Implementation<a href="#in-hand-manipulation-implementation" class="hash-link" aria-label="Direct link to In-Hand Manipulation Implementation" title="Direct link to In-Hand Manipulation Implementation" translate="no">​</a></h3>
<p>Repositioning a grasped object without releasing it requires coordinated finger motion and careful force management. The implementation combines planning (identifying intermediate configurations) and control (executing motion while maintaining stability).</p>
<p>Finger gaiting plans a sequence of intermediate grasps. Each intermediate grasp must satisfy force closure with a subset of fingers while others reposition. The planner searches the graph of stable grasps, finding a path from initial to goal configuration.</p>
<p>Graph construction represents grasps as nodes and single-finger motions as edges. A grasp is a node if it achieves force closure. An edge exists between two grasps if one finger can move from one configuration to another while the remaining fingers maintain force closure. Graph search algorithms (A*, Dijkstra) find shortest paths through this graph.</p>
<p>Executing finger gaiting follows the planned sequence. At each step:</p>
<ol>
<li class="">Verify remaining fingers achieve force closure</li>
<li class="">Increase forces at stable contacts to provide larger safety margin</li>
<li class="">Command one finger to release (reduce force to zero)</li>
<li class="">Move released finger to new position</li>
<li class="">Establish new contact and increase force</li>
<li class="">Decrease forces at remaining contacts to nominal levels</li>
</ol>
<p>Force sensing and tactile feedback monitor stability throughout. If slip is detected during a transition, abort the current step and increase forces at remaining contacts to restore stability.</p>
<p>Rolling manipulation requires coordinating finger velocities to achieve desired object rotation without slip. The rolling constraint couples object angular velocity omega to finger velocities: v_finger = omega × r, where r is the vector from the rotation axis to the contact point.</p>
<p>Computing required finger velocities:</p>
<ol>
<li class="">Specify desired object angular velocity omega</li>
<li class="">For each finger, compute the contact point&#x27;s velocity from the rolling constraint</li>
<li class="">Use the hand&#x27;s inverse kinematics to find joint velocities achieving these finger velocities</li>
<li class="">Send joint velocity commands to the motors</li>
</ol>
<p>Monitoring actual contact motion through tactile sensing detects slip violations. If actual motion deviates from the rolling constraint (slip occurs), adjust finger forces to increase friction or modify the rotation rate.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="bi-manual-grasp-planning-and-control">Bi-Manual Grasp Planning and Control<a href="#bi-manual-grasp-planning-and-control" class="hash-link" aria-label="Direct link to Bi-Manual Grasp Planning and Control" title="Direct link to Bi-Manual Grasp Planning and Control" translate="no">​</a></h3>
<p>Coordinating two hands to manipulate a single object extends single-hand techniques but introduces coupling between the arms. Both planning and control must account for this coupling.</p>
<p>Object modeling for bi-manual grasps includes attachment points for both hands. The relative configuration of hands determines object pose. If hand 1 is at T_1 and hand 2 at T_2, and the object-to-hand transforms are T_o1 and T_o2, then the object pose is T_obj = T_1 * T_o1 = T_2 * T_o2. Consistency requires these to match.</p>
<p>Grasp planning for bi-manual manipulation selects contact points for both hands simultaneously. The combined grasp must achieve force closure considering all contacts from both hands. Quality metrics evaluate the entire bi-manual grasp as a single system.</p>
<p>Sampling-based planning generates candidate bi-manual grasps by:</p>
<ol>
<li class="">Sample grasp for hand 1 on object</li>
<li class="">Sample grasp for hand 2 on object</li>
<li class="">Check geometric compatibility: hands don&#x27;t collide with each other</li>
<li class="">Verify combined force closure from all contacts</li>
<li class="">Compute quality metrics for the combined grasp</li>
<li class="">Check inverse kinematics feasibility for both arms</li>
</ol>
<p>Coordinated motion planning computes trajectories for both arms that avoid collisions with each other, the object, and the environment. The combined configuration space has dimension n_left + n_right (sum of both arm DOFs). Motion planners search this high-dimensional space for collision-free paths.</p>
<p>Prioritization simplifies coordination: designate one arm as primary (performs the main task) and the other as secondary (assists). Plan the primary arm&#x27;s motion first, treating it as an additional obstacle for secondary arm planning. This reduces complexity but may miss solutions requiring true coordination.</p>
<p>Controlling bi-manual manipulation uses the combined manipulation Jacobian J_bi = [J_left | J_right], mapping both arms&#x27; joint velocities to object velocity. Desired object velocity v_obj is achieved by joint velocities q_dot = J_bi^+ * v_obj, where J_bi^+ is the pseudo-inverse.</p>
<p>Force distribution optimizes internal forces:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">minimize: |f_internal|^2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">subject to:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - Net object wrench: f_left + f_right = f_desired</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - Force closure at each hand</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - Force limits at each contact</span><br></span></code></pre></div></div>
<p>The solution minimizes squeezing forces between hands while maintaining grasp stability and achieving desired object wrench.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="motion-planning-with-moveit-2">Motion Planning with MoveIt 2<a href="#motion-planning-with-moveit-2" class="hash-link" aria-label="Direct link to Motion Planning with MoveIt 2" title="Direct link to Motion Planning with MoveIt 2" translate="no">​</a></h3>
<p>MoveIt 2 provides a comprehensive framework for manipulation motion planning, integrating perception, planning algorithms, control, and execution. Understanding its conceptual architecture enables effective use for humanoid manipulation.</p>
<p>The planning scene represents the world model: robot configuration, object locations, and collision geometry. Perception updates the planning scene from sensor data (cameras, depth sensors). Octomap representations efficiently encode 3D occupied space from point clouds.</p>
<p>Planning requests specify motion goals: target end-effector pose, joint configuration, or Cartesian path. Constraints include collision avoidance, joint limits, and task-specific requirements (maintain upright orientation, keep object level).</p>
<p>Motion planners search configuration space for collision-free paths. MoveIt 2 includes multiple planners: RRT (Rapidly-exploring Random Trees), RRT-Connect, PRM (Probabilistic Roadmaps), and OMPL (Open Motion Planning Library) variants. Different planners have different strengths for various problem characteristics.</p>
<p>RRT and variants grow trees from the start configuration, randomly sampling new configurations and connecting them if collision-free. RRT-Connect grows trees from both start and goal, connecting them when they meet. These planners work well for high-dimensional spaces and complex obstacles.</p>
<p>Trajectory processing smooths and optimizes planned paths. Initial paths from sampling-based planners often contain unnecessary waypoints and jerky motion. Time parameterization adds velocity profiles respecting speed and acceleration limits. Smoothing algorithms adjust waypoints to reduce path length and improve motion quality.</p>
<p>Grasping with MoveIt 2 uses the MoveIt Task Constructor framework. Task decomposition breaks manipulation into stages: approach, grasp, retreat, move, release. Each stage specifies constraints and goals. The framework searches for plans satisfying all stages, handling the coupling between stages (grasp pose affects retreat direction).</p>
<p>Pick and place pipelines in MoveIt 2:</p>
<ol>
<li class="">Perceive object location and pose</li>
<li class="">Generate candidate grasps using grasp planning</li>
<li class="">For each grasp, plan approach (move arm to pre-grasp pose)</li>
<li class="">Plan grasp motion (close fingers to achieve contact)</li>
<li class="">Plan retreat (lift object)</li>
<li class="">Plan transport (move to place location)</li>
<li class="">Plan place (lower object)</li>
<li class="">Plan release (open fingers)</li>
<li class="">Execute highest-quality complete plan</li>
</ol>
<p>Execution monitoring tracks plan progress and handles failures. If unexpected collisions occur or the object is not grasped successfully, the system can replan or try alternative grasps.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conceptual-diagrams">Conceptual Diagrams<a href="#conceptual-diagrams" class="hash-link" aria-label="Direct link to Conceptual Diagrams" title="Direct link to Conceptual Diagrams" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="anthropomorphic-hand-structure">Anthropomorphic Hand Structure<a href="#anthropomorphic-hand-structure" class="hash-link" aria-label="Direct link to Anthropomorphic Hand Structure" title="Direct link to Anthropomorphic Hand Structure" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Side view of humanoid hand:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    DIP (Distal Interphalangeal)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    PIP (Proximal Interphalangeal)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    MCP (Metacarpophalangeal)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Fingertip---O</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                ---O</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                ---O</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            =========== Palm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Four fingers (Index, Middle, Ring, Pinky): 3 joints each (MCP, PIP, DIP)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Thumb: 3 joints with different orientation (enables opposition)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Typical DOF count:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Fully actuated: 15-20 DOF</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Underactuated: 4-8 actuators controlling 12-20 joints</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Sensors:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Joint encoders: measure finger positions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Tactile: palm and fingertips (force, pressure, slip)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- F/T sensor: wrist (overall hand loading)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="grasp-taxonomy">Grasp Taxonomy<a href="#grasp-taxonomy" class="hash-link" aria-label="Direct link to Grasp Taxonomy" title="Direct link to Grasp Taxonomy" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">POWER GRASPS (whole hand + palm contact):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Cylindrical Grasp:       Spherical Grasp:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ||||||                   ____</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ||obj||                 / obj \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ||||||                  \ __  /</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   =======palm             =======palm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   (wrap around cylinder)   (fingers distributed around sphere)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">PRECISION GRASPS (fingertip contact, no palm):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Pinch Grasp:             Tripod Grasp:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Thumb                    Thumb</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     |  |Index                |  Index</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     |  |                     | /</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     [O]                      ||  Middle</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    object                   [O]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  (thumb opposes            object</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   index finger)        (three-finger grip)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">INTERMEDIATE GRASPS:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Lateral Grasp:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Thumb-||</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ||object  Index finger</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   (thumb presses against side of index)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="force-closure-concept">Force Closure Concept<a href="#force-closure-concept" class="hash-link" aria-label="Direct link to Force Closure Concept" title="Direct link to Force Closure Concept" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">2D Example - Three-Finger Grasp:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         Finger 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           [O]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          /   \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         v     v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Finger 1  Finger 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Each finger pushes within its friction cone:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Normal force: perpendicular to surface</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Friction cone: angle depends on friction coefficient μ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         / | \  &lt;-- Friction cone (angle = atan(μ))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        /  |  \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       /   v   \  Contact normal</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      -----------  Object surface</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FORCE CLOSURE CHECK:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Can contacts generate force in any direction? YES</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Can contacts generate torque in any direction? YES</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Forces within friction cones? YES</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Result: Force closure achieved</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FAILURE Example - Two-Finger Grasp (no friction):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Finger 1    Finger 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |           |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v           v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       [============]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Cannot resist horizontal forces → NOT force closure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Form Closure (geometry prevents motion):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    /|  Object  |\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   / |   ___    | \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  F1 |  |   |   | F2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     |  |___|   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      \ |  | /</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        \|_|/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         F3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Geometric constraint prevents motion even without friction.</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="grasp-quality-metrics-1">Grasp Quality Metrics<a href="#grasp-quality-metrics-1" class="hash-link" aria-label="Direct link to Grasp Quality Metrics" title="Direct link to Grasp Quality Metrics" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">EPSILON QUALITY:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Disturbance Wrench Space (3D for planar, 6D for spatial):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         F_y</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          ^</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          |   Worst direction (smallest resistance)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          |  /</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          | /  epsilon = min distance to failure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          |/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ------O------&gt; F_x</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         /|</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        / |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     Other directions (larger resistance)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Grasp can resist disturbances within epsilon ball.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Larger epsilon = better quality.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FERRARI-CANNY METRIC:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Grasp Wrench Space (wrenches grasp can exert):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           Wrench_y</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               ^</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              /|\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">             / | \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            /  |  \   &lt;-- Convex hull of achievable wrenches</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           /   O   \      (O = origin)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          /    .    \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         /     .     \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        /      .radius\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       /              \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      -----------------&gt; Wrench_x</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Ferrari-Canny = radius of largest ball centered at origin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                inside wrench space</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="tactile-sensing-applications">Tactile Sensing Applications<a href="#tactile-sensing-applications" class="hash-link" aria-label="Direct link to Tactile Sensing Applications" title="Direct link to Tactile Sensing Applications" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">SLIP DETECTION:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Time series of tactile sensor readings:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Force        /\    /\    /\   &lt;-- Vibrations indicate slip</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ^         /  \  /  \  /  \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  |   _____/    \/    \/    \_____</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  |________________________&gt; time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Contact   Slip starts    Stable again</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      stable                   (increased force)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Response: Increase grip force upon detecting slip</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FORCE CONTROL:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Desired force: F_d = 5N</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Measured force: F_m (from tactile sensors)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Error: e = F_d - F_m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Control law: motor_command = motor_command + K_p * e</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Measured</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     F_m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ^     Target F_d</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      |    -----------</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      |   /</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      |  /  (approaches target)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      | /</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      |/____________&gt; time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SHAPE EXPLORATION:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Move finger along surface, record tactile readings:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Finger path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ------&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ┌─────┐  Tactile readings vary with surface geometry</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    │     │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    │ Obj │  High pressure on flat surfaces</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    │     │  Pressure changes at edges</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    └─────┘</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Build tactile map of object shape.</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="grasp-planning-pipeline">Grasp Planning Pipeline<a href="#grasp-planning-pipeline" class="hash-link" aria-label="Direct link to Grasp Planning Pipeline" title="Direct link to Grasp Planning Pipeline" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">INPUT: Object point cloud + pose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Generate Candidates  |  Sample contact points</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                      |  Construct hand configs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   | (1000s of candidates)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Filter: Fast Checks  |  Collision detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                      |  Basic reachability</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   | (100s remaining)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Evaluate Quality     |  Force closure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                      |  Epsilon/Ferrari-Canny</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                      |  Manipulability</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   | (10s of high-quality grasps)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Rank and Select      |  Sort by quality</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                      |  Select best</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   | (selected grasp)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Motion Planning      |  Plan approach</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                      |  Plan grasp closure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">OUTPUT: Grasp + motion plan</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="in-hand-manipulation---finger-gaiting">In-Hand Manipulation - Finger Gaiting<a href="#in-hand-manipulation---finger-gaiting" class="hash-link" aria-label="Direct link to In-Hand Manipulation - Finger Gaiting" title="Direct link to In-Hand Manipulation - Finger Gaiting" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Reorient object by walking fingers:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Initial Grasp:           Intermediate:              Final Grasp:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   F1  F2  F3              F1     F3                 F1  F2  F3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |   |   |              |      |                   |   |   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    [=======]              [======]                   [=======]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                          F2 repositions              (rotated)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                            (moving)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Sequence:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. F1, F2, F3 achieve force closure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Release F2, maintain force closure with F1, F3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Move F2 to new position</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Re-establish contact with F2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. Repeat with different fingers to continue rotation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Requirements:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Remaining fingers maintain force closure during transitions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Force margins prevent slip during reconfiguration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Planned path through stable grasp configurations</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="bi-manual-manipulation">Bi-Manual Manipulation<a href="#bi-manual-manipulation" class="hash-link" aria-label="Direct link to Bi-Manual Manipulation" title="Direct link to Bi-Manual Manipulation" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Top view - Two hands grasping box:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Left Hand              Right Hand</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         |                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         v                     v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    +----|-------OBJECT--------|----+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |    *                     *    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |                               |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |          [CoM]                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |                               |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    +-------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Forces:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Each hand exerts grasp forces on object</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Internal forces: hands squeeze object</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- External force: net force on object (lift, move)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Control objectives:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Net force: move object as desired</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Internal force: maintain grasp stability, minimize squeezing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Coordination: hands move together (object rigid)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Jacobian relationship:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">v_obj = J_left * q_dot_left = J_right * q_dot_right</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Combined: v_obj = [J_left | J_right] * [q_dot_left; q_dot_right]</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="moveit-2-architecture">MoveIt 2 Architecture<a href="#moveit-2-architecture" class="hash-link" aria-label="Direct link to MoveIt 2 Architecture" title="Direct link to MoveIt 2 Architecture" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">PLANNING SCENE (world model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Robot state (joint angles)        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Object locations                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Collision geometry                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Attached objects (grasped items)  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           | (updated from perception)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| MOTION PLANNING       |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Goal: target pose     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Constraints:          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Collision avoidance |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Joint limits        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Cartesian path      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           | (RRT, RRT-Connect, PRM, etc.)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| TRAJECTORY            |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| PROCESSING            |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Time parameterization|</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Smoothing           |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Optimization        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| EXECUTION             |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Send to controllers |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Monitor progress    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Handle failures     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      Robot Motion</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="pick-and-place-sequence">Pick and Place Sequence<a href="#pick-and-place-sequence" class="hash-link" aria-label="Direct link to Pick and Place Sequence" title="Direct link to Pick and Place Sequence" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">PICK AND PLACE STAGES:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. APPROACH</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Robot arm -----&gt; [Object]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   (move to pre-grasp pose)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. GRASP</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Hand -----&gt; [Object]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   (close fingers, establish contact)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. RETREAT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Robot arm /\ with [Object]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   (lift object)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. TRANSPORT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Robot arm -----------&gt; with [Object]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   (move to place location)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. PLACE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Robot arm \/ with [Object]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   (lower object to surface)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">6. RELEASE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Hand ----X [Object]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   (open fingers, release)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">7. WITHDRAW</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Robot arm &lt;----- from [Object]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   (move away)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Each stage has:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Constraints (collision avoidance, force limits)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Goals (target pose/configuration)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Success criteria (force sensing, vision confirmation)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="knowledge-checkpoint">Knowledge Checkpoint<a href="#knowledge-checkpoint" class="hash-link" aria-label="Direct link to Knowledge Checkpoint" title="Direct link to Knowledge Checkpoint" translate="no">​</a></h2>
<p>Test your understanding of manipulation and grasping:</p>
<ol>
<li class="">
<p><strong>Hand Design</strong>: Compare fully-actuated and underactuated hand designs. What advantages does each provide, and for what applications would you choose each design?</p>
</li>
<li class="">
<p><strong>Grasp Taxonomy</strong>: Explain the difference between power grasps and precision grasps. Provide examples of tasks that require each type and explain why.</p>
</li>
<li class="">
<p><strong>Force Closure</strong>: A three-fingered hand grasps a planar object with point contacts. What geometric conditions must the contact points satisfy to achieve force closure with friction? Why is friction necessary?</p>
</li>
<li class="">
<p><strong>Form vs Force Closure</strong>: Explain the difference between form closure and force closure. Which is more commonly achieved by robotic hands, and why?</p>
</li>
<li class="">
<p><strong>Friction Cone</strong>: Draw a friction cone for a contact with friction coefficient mu = 0.5. What does this cone represent, and how does it constrain the contact force?</p>
</li>
<li class="">
<p><strong>Grasp Quality</strong>: Two grasps both achieve force closure on the same object. One has epsilon quality of 2.0 N, the other has epsilon quality of 5.0 N. What does this difference mean in practical terms?</p>
</li>
<li class="">
<p><strong>Tactile Sensing</strong>: Explain how slip detection works using high-frequency tactile sensing. What changes in the tactile signal indicate slip, and how should the controller respond?</p>
</li>
<li class="">
<p><strong>Grasp Planning</strong>: Describe the trade-offs between analytical grasp planning (using geometric rules) and sampling-based grasp planning (randomly generating and evaluating candidates).</p>
</li>
<li class="">
<p><strong>In-Hand Manipulation</strong>: During finger gaiting, why must the remaining fingers maintain force closure while one finger repositions? What happens if this condition is violated?</p>
</li>
<li class="">
<p><strong>Impedance Control</strong>: Explain how impedance control differs from pure position control or pure force control. When is impedance control preferable for manipulation tasks?</p>
</li>
<li class="">
<p><strong>Bi-Manual Coordination</strong>: When two hands grasp a rigid object, internal forces can arise without changing the net object wrench. Explain what internal forces are and why minimizing them is desirable.</p>
</li>
<li class="">
<p><strong>Manipulability</strong>: The manipulability measure for a grasp quantifies how easily the grasped object can be moved. What factors contribute to high manipulability? How does manipulability relate to the grasp Jacobian?</p>
</li>
<li class="">
<p><strong>Contact Modeling</strong>: Real contacts between robotic fingers and objects violate the point-contact assumption used in many grasp models. Name three ways real contacts differ from idealized point contacts and how these differences affect grasp planning.</p>
</li>
<li class="">
<p><strong>Grasp Execution</strong>: During grasp execution, vision initially guides the hand toward the object, but tactile feedback becomes more important after contact. Explain why this sensory transition occurs and what each modality contributes.</p>
</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="chapter-summary">Chapter Summary<a href="#chapter-summary" class="hash-link" aria-label="Direct link to Chapter Summary" title="Direct link to Chapter Summary" translate="no">​</a></h2>
<p>This chapter explored the principles and techniques enabling humanoid robots to grasp and manipulate objects. We began with anthropomorphic hand design, examining the mechanical structures, actuation strategies, and sensor integration that provide dexterous manipulation capability. The fundamental trade-off between full actuation (maximum control authority) and underactuation (practical simplicity and robustness) shapes hand design choices.</p>
<p>Grasp taxonomies organize the diverse ways hands interact with objects. Power grasps use the entire hand for stable, strong grips. Precision grasps use fingertips for fine manipulation control. Understanding this taxonomy helps select appropriate grasps for different tasks and objects.</p>
<p>Force closure provides the mathematical foundation for grasp stability. A grasp achieves force closure when contact forces can resist arbitrary external wrenches. Form closure, where geometry alone prevents motion, represents the ideal but is difficult to achieve practically. Most robotic grasps rely on force closure with friction.</p>
<p>Grasp quality metrics quantify how good force-closure grasps are. Epsilon quality measures robustness to disturbances. Ferrari-Canny metric characterizes uniform wrench capability. Manipulability indicates ease of object motion. These metrics guide grasp selection, preferring grasps that better serve task requirements.</p>
<p>Tactile sensing closes the feedback loop for manipulation. Force sensors detect contact forces, enabling force control. Slip detection triggers reactive grasp adjustment. Multi-modal tactile sensors provide rich information about contact state. Integration of vision and touch provides robust perception throughout manipulation.</p>
<p>Grasp planning algorithms select finger placements and contact forces. Analytical methods use geometric rules for simple shapes. Sampling-based approaches generate and evaluate many candidates for complex objects. Learning-based methods predict grasp success from training data. All approaches must verify kinematic reachability and collision avoidance.</p>
<p>In-hand manipulation enables repositioning grasped objects without releasing. Finger gaiting walks fingers around objects. Rolling contacts achieve reorientation through coordinated finger motion. These advanced techniques require carefully maintaining force closure through state transitions.</p>
<p>Bi-manual manipulation coordinates two arms to manipulate single objects or perform assembly tasks. The coupled kinematics require coordinated motion planning. Force distribution must balance load between hands while minimizing internal forces. Task decomposition simplifies planning by assigning appropriate roles to each arm.</p>
<p>Practical manipulation faces numerous challenges: modeling uncertainty, contact dynamics complexity, high-dimensional control spaces, perception limitations, and generalization across object classes. Robust systems combine feedforward planning with feedback adaptation, using vision and touch to detect and correct errors.</p>
<p>MoveIt 2 provides a comprehensive framework integrating planning, perception, and control for manipulation. Its modular architecture enables using different planners, trajectory processors, and controllers while handling common concerns like collision avoidance and constraint satisfaction.</p>
<p>The concepts developed in this chapter—force closure, quality metrics, tactile feedback, and coordinated control—form the foundation for capable manipulation systems. As humanoid robots take on increasingly complex tasks, robust grasping and dexterous manipulation become essential capabilities.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="further-reading">Further Reading<a href="#further-reading" class="hash-link" aria-label="Direct link to Further Reading" title="Direct link to Further Reading" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="foundational-textbooks">Foundational Textbooks<a href="#foundational-textbooks" class="hash-link" aria-label="Direct link to Foundational Textbooks" title="Direct link to Foundational Textbooks" translate="no">​</a></h3>
<ol>
<li class="">
<p>Murray, R. M., Li, Z., &amp; Sastry, S. S. (1994). &quot;A Mathematical Introduction to Robotic Manipulation.&quot; CRC Press.</p>
<ul>
<li class="">Rigorous mathematical treatment of kinematics, contact models, and force closure theory.</li>
</ul>
</li>
<li class="">
<p>Lynch, K. M., &amp; Park, F. C. (2017). &quot;Modern Robotics: Mechanics, Planning, and Control.&quot; Cambridge University Press.</p>
<ul>
<li class="">Comprehensive coverage including manipulation, grasping, and motion planning with clear explanations.</li>
</ul>
</li>
<li class="">
<p>Siciliano, B., &amp; Khatib, O. (Eds.). (2016). &quot;Springer Handbook of Robotics&quot; (2nd ed.). Springer.</p>
<ul>
<li class="">Extensive chapters on grasping, dexterous manipulation, and haptics by leading researchers.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="grasp-analysis-and-planning">Grasp Analysis and Planning<a href="#grasp-analysis-and-planning" class="hash-link" aria-label="Direct link to Grasp Analysis and Planning" title="Direct link to Grasp Analysis and Planning" translate="no">​</a></h3>
<ol start="4">
<li class="">
<p>Prattichizzo, D., &amp; Trinkle, J. C. (2016). &quot;Grasping.&quot; In Springer Handbook of Robotics (pp. 955-988). Springer.</p>
<ul>
<li class="">Comprehensive overview of grasp theory, including force closure, quality metrics, and planning algorithms.</li>
</ul>
</li>
<li class="">
<p>Sahbani, A., El-Khoury, S., &amp; Bidaud, P. (2012). &quot;An Overview of 3D Object Grasp Synthesis Algorithms.&quot; Robotics and Autonomous Systems, 60(3), 326-336.</p>
<ul>
<li class="">Survey of grasp planning approaches with taxonomy and comparative analysis.</li>
</ul>
</li>
<li class="">
<p>Miller, A. T., &amp; Allen, P. K. (2004). &quot;Graspit! A Versatile Simulator for Robotic Grasping.&quot; IEEE Robotics &amp; Automation Magazine, 11(4), 110-122.</p>
<ul>
<li class="">Description of influential grasp simulation and planning tool.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hand-design">Hand Design<a href="#hand-design" class="hash-link" aria-label="Direct link to Hand Design" title="Direct link to Hand Design" translate="no">​</a></h3>
<ol start="7">
<li class="">
<p>Piazza, C., Grioli, G., Catalano, M. G., &amp; Bicchi, A. (2019). &quot;A Century of Robotic Hands.&quot; Annual Review of Control, Robotics, and Autonomous Systems, 2, 1-32.</p>
<ul>
<li class="">Historical survey of robotic hand designs with analysis of design principles and trends.</li>
</ul>
</li>
<li class="">
<p>Dollar, A. M., &amp; Howe, R. D. (2010). &quot;The Highly Adaptive SDM Hand: Design and Performance Evaluation.&quot; International Journal of Robotics Research, 29(5), 585-597.</p>
<ul>
<li class="">Detailed analysis of underactuated hand design principles with experimental validation.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="tactile-sensing">Tactile Sensing<a href="#tactile-sensing" class="hash-link" aria-label="Direct link to Tactile Sensing" title="Direct link to Tactile Sensing" translate="no">​</a></h3>
<ol start="9">
<li class="">
<p>Dahiya, R. S., Metta, G., Valle, M., &amp; Sandini, G. (2010). &quot;Tactile Sensing—From Humans to Humanoids.&quot; IEEE Transactions on Robotics, 26(1), 1-20.</p>
<ul>
<li class="">Comprehensive review of tactile sensor technologies and their application to robotics.</li>
</ul>
</li>
<li class="">
<p>Wettels, N., Santos, V. J., Johansson, R. S., &amp; Loeb, G. E. (2008). &quot;Biomimetic Tactile Sensor Array.&quot; Advanced Robotics, 22(8), 829-849.</p>
<ul>
<li class="">BioTac sensor design and capabilities for rich tactile perception.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="dexterous-manipulation">Dexterous Manipulation<a href="#dexterous-manipulation" class="hash-link" aria-label="Direct link to Dexterous Manipulation" title="Direct link to Dexterous Manipulation" translate="no">​</a></h3>
<ol start="11">
<li class="">
<p>Okamura, A. M., Smaby, N., &amp; Cutkosky, M. R. (2000). &quot;An Overview of Dexterous Manipulation.&quot; Proceedings of IEEE International Conference on Robotics and Automation.</p>
<ul>
<li class="">Survey of in-hand manipulation techniques and challenges.</li>
</ul>
</li>
<li class="">
<p>Rus, D. (1999). &quot;In-Hand Dexterous Manipulation of Piecewise-Smooth 3-D Objects.&quot; International Journal of Robotics Research, 18(4), 355-381.</p>
<ul>
<li class="">Theoretical framework and algorithms for finger gaiting and reorientation.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-based-grasping">Learning-Based Grasping<a href="#learning-based-grasping" class="hash-link" aria-label="Direct link to Learning-Based Grasping" title="Direct link to Learning-Based Grasping" translate="no">​</a></h3>
<ol start="13">
<li class="">
<p>Bohg, J., Morales, A., Asfour, T., &amp; Kragic, D. (2014). &quot;Data-Driven Grasp Synthesis—A Survey.&quot; IEEE Transactions on Robotics, 30(2), 289-309.</p>
<ul>
<li class="">Survey of learning and data-driven approaches to grasp planning.</li>
</ul>
</li>
<li class="">
<p>Levine, S., Pastor, P., Krizhevsky, A., Ibarz, J., &amp; Quillen, D. (2018). &quot;Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection.&quot; International Journal of Robotics Research, 37(4-5), 421-436.</p>
<ul>
<li class="">Deep learning approach to grasp planning with large-scale robot data.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="bi-manual-manipulation-1">Bi-Manual Manipulation<a href="#bi-manual-manipulation-1" class="hash-link" aria-label="Direct link to Bi-Manual Manipulation" title="Direct link to Bi-Manual Manipulation" translate="no">​</a></h3>
<ol start="15">
<li class="">Smith, C., Karayiannidis, Y., Nalpantidis, L., Gratal, X., Qi, P., Dimarogonas, D. V., &amp; Kragic, D. (2012). &quot;Dual Arm Manipulation—A Survey.&quot; Robotics and Autonomous Systems, 60(10), 1340-1353.<!-- -->
<ul>
<li class="">Comprehensive survey of bi-manual and dual-arm manipulation techniques.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="moveit-2-and-motion-planning">MoveIt 2 and Motion Planning<a href="#moveit-2-and-motion-planning" class="hash-link" aria-label="Direct link to MoveIt 2 and Motion Planning" title="Direct link to MoveIt 2 and Motion Planning" translate="no">​</a></h3>
<ol start="16">
<li class="">
<p>MoveIt 2 Documentation: <a href="https://moveit.ros.org/" target="_blank" rel="noopener noreferrer" class="">https://moveit.ros.org/</a></p>
<ul>
<li class="">Official documentation, tutorials, and API reference for the MoveIt 2 framework.</li>
</ul>
</li>
<li class="">
<p>Chitta, S., Sucan, I., &amp; Cousins, S. (2012). &quot;MoveIt! [ROS Topics].&quot; IEEE Robotics &amp; Automation Magazine, 19(1), 18-19.</p>
<ul>
<li class="">Overview of the MoveIt framework architecture and capabilities.</li>
</ul>
</li>
<li class="">
<p>Sucan, I. A., Moll, M., &amp; Kavraki, L. E. (2012). &quot;The Open Motion Planning Library.&quot; IEEE Robotics &amp; Automation Magazine, 19(4), 72-82.</p>
<ul>
<li class="">Description of OMPL, the motion planning library underlying MoveIt.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="practical-implementation">Practical Implementation<a href="#practical-implementation" class="hash-link" aria-label="Direct link to Practical Implementation" title="Direct link to Practical Implementation" translate="no">​</a></h3>
<ol start="19">
<li class="">
<p>Ciocarlie, M., Lackner, C., &amp; Allen, P. (2007). &quot;Soft Finger Model with Adaptive Contact Geometry for Grasping and Manipulation Tasks.&quot; Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces.</p>
<ul>
<li class="">Practical contact modeling for compliant fingertips.</li>
</ul>
</li>
<li class="">
<p>Hsiao, K., Kaelbling, L. P., &amp; Lozano-Pérez, T. (2010). &quot;Task-Driven Tactile Exploration.&quot; Robotics: Science and Systems.</p>
<ul>
<li class="">Using tactile feedback to guide manipulation and exploration.</li>
</ul>
</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="looking-ahead">Looking Ahead<a href="#looking-ahead" class="hash-link" aria-label="Direct link to Looking Ahead" title="Direct link to Looking Ahead" translate="no">​</a></h2>
<p>With manipulation capabilities established, Chapter 14 examines natural human-robot interaction—how humanoids communicate and collaborate with humans through gestures, gaze, speech, and safe physical contact. This final chapter integrates locomotion and manipulation with social and interactive capabilities.</p>
<p>Natural interaction requires anthropomorphic design extending beyond functional capability to include social signals. Gesture recognition and generation enable non-verbal communication. Gaze direction indicates attention and intention. Facial expressions (for robots equipped with expressive faces) convey emotional state and social engagement.</p>
<p>The manipulation techniques developed in this chapter directly support interactive tasks. Compliant control, introduced for gentle object handling, becomes essential for safe physical human-robot interaction. Force sensing and tactile feedback, used for grasp stability, enable detecting human contact and responding appropriately. Motion planning with collision avoidance extends to predicting and accommodating human motion.</p>
<p>Safety considerations become paramount when robots work alongside humans. ISO standards define safety requirements for collaborative robots. Collision detection must be fast and reliable. Control systems must limit forces and velocities to prevent injury. Understanding these constraints shapes interaction design.</p>
<p>The integration of perception, cognition, and control reaches its fullest expression in natural human-robot interaction. Vision tracks human position and recognizes gestures. Planning anticipates human intentions and coordinates robot actions. Control executes motions that are both effective and socially appropriate.</p>
<p>Chapter 14 will explore proxemics (spatial relationships), multi-modal interaction (combining speech, gesture, and gaze), compliant control for safe contact, and the standards and best practices for collaborative robotics. The goal is humanoid systems that work seamlessly alongside humans, understanding social cues and responding in natural, safe, and effective ways.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-12-bipedal-locomotion-and-balance"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Chapter 12: Bipedal Locomotion and Balance</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-14-natural-human-robot-interaction"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Chapter 14: Natural Human-Robot Interaction</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#core-concepts" class="table-of-contents__link toc-highlight">Core Concepts</a><ul><li><a href="#anthropomorphic-hand-design-principles" class="table-of-contents__link toc-highlight">Anthropomorphic Hand Design Principles</a></li><li><a href="#grasp-taxonomies" class="table-of-contents__link toc-highlight">Grasp Taxonomies</a></li><li><a href="#force-closure-and-grasp-stability" class="table-of-contents__link toc-highlight">Force Closure and Grasp Stability</a></li><li><a href="#grasp-quality-metrics" class="table-of-contents__link toc-highlight">Grasp Quality Metrics</a></li><li><a href="#tactile-sensing-and-feedback" class="table-of-contents__link toc-highlight">Tactile Sensing and Feedback</a></li><li><a href="#grasp-planning-algorithms" class="table-of-contents__link toc-highlight">Grasp Planning Algorithms</a></li><li><a href="#in-hand-manipulation" class="table-of-contents__link toc-highlight">In-Hand Manipulation</a></li><li><a href="#bi-manual-coordination" class="table-of-contents__link toc-highlight">Bi-Manual Coordination</a></li><li><a href="#dexterous-manipulation-challenges" class="table-of-contents__link toc-highlight">Dexterous Manipulation Challenges</a></li></ul></li><li><a href="#practical-understanding" class="table-of-contents__link toc-highlight">Practical Understanding</a><ul><li><a href="#hand-design-trade-offs-in-practice" class="table-of-contents__link toc-highlight">Hand Design Trade-offs in Practice</a></li><li><a href="#computing-force-closure" class="table-of-contents__link toc-highlight">Computing Force Closure</a></li><li><a href="#grasp-quality-evaluation" class="table-of-contents__link toc-highlight">Grasp Quality Evaluation</a></li><li><a href="#implementing-grasp-planning" class="table-of-contents__link toc-highlight">Implementing Grasp Planning</a></li><li><a href="#force-control-for-manipulation" class="table-of-contents__link toc-highlight">Force Control for Manipulation</a></li><li><a href="#in-hand-manipulation-implementation" class="table-of-contents__link toc-highlight">In-Hand Manipulation Implementation</a></li><li><a href="#bi-manual-grasp-planning-and-control" class="table-of-contents__link toc-highlight">Bi-Manual Grasp Planning and Control</a></li><li><a href="#motion-planning-with-moveit-2" class="table-of-contents__link toc-highlight">Motion Planning with MoveIt 2</a></li></ul></li><li><a href="#conceptual-diagrams" class="table-of-contents__link toc-highlight">Conceptual Diagrams</a><ul><li><a href="#anthropomorphic-hand-structure" class="table-of-contents__link toc-highlight">Anthropomorphic Hand Structure</a></li><li><a href="#grasp-taxonomy" class="table-of-contents__link toc-highlight">Grasp Taxonomy</a></li><li><a href="#force-closure-concept" class="table-of-contents__link toc-highlight">Force Closure Concept</a></li><li><a href="#grasp-quality-metrics-1" class="table-of-contents__link toc-highlight">Grasp Quality Metrics</a></li><li><a href="#tactile-sensing-applications" class="table-of-contents__link toc-highlight">Tactile Sensing Applications</a></li><li><a href="#grasp-planning-pipeline" class="table-of-contents__link toc-highlight">Grasp Planning Pipeline</a></li><li><a href="#in-hand-manipulation---finger-gaiting" class="table-of-contents__link toc-highlight">In-Hand Manipulation - Finger Gaiting</a></li><li><a href="#bi-manual-manipulation" class="table-of-contents__link toc-highlight">Bi-Manual Manipulation</a></li><li><a href="#moveit-2-architecture" class="table-of-contents__link toc-highlight">MoveIt 2 Architecture</a></li><li><a href="#pick-and-place-sequence" class="table-of-contents__link toc-highlight">Pick and Place Sequence</a></li></ul></li><li><a href="#knowledge-checkpoint" class="table-of-contents__link toc-highlight">Knowledge Checkpoint</a></li><li><a href="#chapter-summary" class="table-of-contents__link toc-highlight">Chapter Summary</a></li><li><a href="#further-reading" class="table-of-contents__link toc-highlight">Further Reading</a><ul><li><a href="#foundational-textbooks" class="table-of-contents__link toc-highlight">Foundational Textbooks</a></li><li><a href="#grasp-analysis-and-planning" class="table-of-contents__link toc-highlight">Grasp Analysis and Planning</a></li><li><a href="#hand-design" class="table-of-contents__link toc-highlight">Hand Design</a></li><li><a href="#tactile-sensing" class="table-of-contents__link toc-highlight">Tactile Sensing</a></li><li><a href="#dexterous-manipulation" class="table-of-contents__link toc-highlight">Dexterous Manipulation</a></li><li><a href="#learning-based-grasping" class="table-of-contents__link toc-highlight">Learning-Based Grasping</a></li><li><a href="#bi-manual-manipulation-1" class="table-of-contents__link toc-highlight">Bi-Manual Manipulation</a></li><li><a href="#moveit-2-and-motion-planning" class="table-of-contents__link toc-highlight">MoveIt 2 and Motion Planning</a></li><li><a href="#practical-implementation" class="table-of-contents__link toc-highlight">Practical Implementation</a></li></ul></li><li><a href="#looking-ahead" class="table-of-contents__link toc-highlight">Looking Ahead</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Course</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Physical-AI-Humanoid-Robotics/">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-01-introduction-to-physical-ai">Foundations</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://panaversity.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Panaversity<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://docs.ros.org/en/humble/" target="_blank" rel="noopener noreferrer" class="footer__link-item">ROS 2 Documentation<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://developer.nvidia.com/isaac-ros" target="_blank" rel="noopener noreferrer" class="footer__link-item">NVIDIA Isaac<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/muskaanfayyaz/Physical-AI-Humanoid-Robotics" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Panaversity. Built with Docusaurus.</div></div></div></footer><button class="rag-chatbot-toggle" aria-label="Toggle chatbot">💬</button></div>
</body>
</html>
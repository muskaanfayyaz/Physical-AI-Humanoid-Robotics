<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-chapters/chapter-10-navigation-and-path-planning" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Chapter 10: Navigation and Path Planning | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/chapters/chapter-10-navigation-and-path-planning"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Chapter 10: Navigation and Path Planning | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Introduction"><meta data-rh="true" property="og:description" content="Introduction"><link data-rh="true" rel="icon" href="/Physical-AI-Humanoid-Robotics/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/chapters/chapter-10-navigation-and-path-planning"><link data-rh="true" rel="alternate" href="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/chapters/chapter-10-navigation-and-path-planning" hreflang="en"><link data-rh="true" rel="alternate" href="https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/chapters/chapter-10-navigation-and-path-planning" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Chapter 10: Navigation and Path Planning","item":"https://muskaanfayyaz.github.io/Physical-AI-Humanoid-Robotics/chapters/chapter-10-navigation-and-path-planning"}]}</script><link rel="stylesheet" href="/Physical-AI-Humanoid-Robotics/assets/css/styles.f1b00d5d.css">
<script src="/Physical-AI-Humanoid-Robotics/assets/js/runtime~main.f590ba4e.js" defer="defer"></script>
<script src="/Physical-AI-Humanoid-Robotics/assets/js/main.832ee6b9.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Physical-AI-Humanoid-Robotics/"><div class="navbar__logo"><img src="/Physical-AI-Humanoid-Robotics/img/logo-transparent.png" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Physical-AI-Humanoid-Robotics/img/logo-transparent.png" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a class="navbar__item navbar__link" href="/Physical-AI-Humanoid-Robotics/">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/muskaanfayyaz/Physical-AI-Humanoid-Robotics" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Physical-AI-Humanoid-Robotics/"><span title="About" class="linkLabel_WmDU">About</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-01-introduction-to-physical-ai"><span title="Weeks 1-2: Foundations" class="categoryLinkLabel_W154">Weeks 1-2: Foundations</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-03-introduction-to-ros2"><span title="Weeks 3-5: ROS 2 Fundamentals" class="categoryLinkLabel_W154">Weeks 3-5: ROS 2 Fundamentals</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-06-physics-simulation-with-gazebo"><span title="Weeks 6-7: Simulation" class="categoryLinkLabel_W154">Weeks 6-7: Simulation</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-08-nvidia-isaac-platform"><span title="Weeks 8-10: NVIDIA Isaac Platform" class="categoryLinkLabel_W154">Weeks 8-10: NVIDIA Isaac Platform</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-08-nvidia-isaac-platform"><span title="Chapter 8: NVIDIA Isaac Platform" class="linkLabel_WmDU">Chapter 8: NVIDIA Isaac Platform</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-09-isaac-ros-hardware-accelerated-perception"><span title="Chapter 9: Isaac ROS - Hardware-Accelerated Perception" class="linkLabel_WmDU">Chapter 9: Isaac ROS - Hardware-Accelerated Perception</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-10-navigation-and-path-planning"><span title="Chapter 10: Navigation and Path Planning" class="linkLabel_WmDU">Chapter 10: Navigation and Path Planning</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-11-humanoid-robot-kinematics-and-dynamics"><span title="Weeks 11-12: Humanoid Development" class="categoryLinkLabel_W154">Weeks 11-12: Humanoid Development</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-15-conversational-robotics"><span title="Week 13: Conversational AI" class="categoryLinkLabel_W154">Week 13: Conversational AI</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-16-sim-to-real-transfer"><span title="Final Weeks: Deployment &amp; Capstone" class="categoryLinkLabel_W154">Final Weeks: Deployment &amp; Capstone</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics/chapters/appendix-a-hardware-setup-guides"><span title="Reference Materials" class="categoryLinkLabel_W154">Reference Materials</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Physical-AI-Humanoid-Robotics/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Weeks 8-10: NVIDIA Isaac Platform</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Chapter 10: Navigation and Path Planning</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Chapter 10: Navigation and Path Planning</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>Autonomous navigation represents one of the most fundamental capabilities of mobile robots. The ability to move purposefully through an environment—avoiding obstacles, reaching goals, and adapting to dynamic conditions—is essential for robots operating beyond controlled factory settings. From warehouse robots delivering packages to humanoid assistants navigating homes, navigation underpins practical autonomy.</p>
<p>The navigation problem appears deceptively simple: move from point A to point B without hitting anything. However, this simplicity masks substantial complexity. Real-world environments present numerous challenges:</p>
<p><strong>Dynamic Obstacles</strong>: People walk through hallways, doors open and close, objects move. Navigation systems must perceive and react to changing conditions in real-time.</p>
<p><strong>Incomplete Information</strong>: Sensors have limited range and field of view. Maps may be outdated or incomplete. Robots must make decisions under uncertainty about environment state.</p>
<p><strong>Kinematic Constraints</strong>: Robots cannot move arbitrarily. Wheeled robots have minimum turning radii and cannot move sideways. Legged robots must maintain balance while stepping. Navigation plans must respect physical limitations.</p>
<p><strong>Multiple Objectives</strong>: Navigation isn&#x27;t only about reaching goals. Robots must navigate efficiently (minimizing time and energy), safely (maintaining margins from obstacles), smoothly (avoiding jerky motions that disturb payloads or passengers), and socially (respecting personal space and social norms).</p>
<p><strong>Computational Constraints</strong>: Navigation algorithms must run in real-time on onboard computers with limited computational resources and power budgets. Optimal solutions might be computationally intractable, requiring practical approximations.</p>
<p>Consider a humanoid robot tasked with navigating from a living room to a kitchen in a home environment. This seemingly simple task involves:</p>
<ol>
<li class=""><strong>Localization</strong>: Determining where the robot currently is within a map of the home</li>
<li class=""><strong>Global Planning</strong>: Finding a high-level path through rooms and doorways from living room to kitchen</li>
<li class=""><strong>Local Planning</strong>: Executing motion along the path while avoiding furniture, people, and pets</li>
<li class=""><strong>Footstep Planning</strong>: Determining where to place each foot while maintaining balance on uneven surfaces</li>
<li class=""><strong>Recovery Behaviors</strong>: Handling situations where progress is blocked or the robot gets stuck</li>
<li class=""><strong>Dynamic Adaptation</strong>: Replanning when doors close, furniture moves, or new obstacles appear</li>
</ol>
<p>Each component requires sophisticated algorithms working together in a coordinated framework.</p>
<p>Modern navigation systems, exemplified by ROS 2&#x27;s Nav2 stack, provide comprehensive solutions to these challenges. They integrate perception (from Chapter 9) with planning, control, and behavior coordination to enable robust autonomous navigation. For humanoid robots, additional complexity arises from bipedal locomotion, requiring specialized planning and control approaches.</p>
<p>This chapter explores navigation and path planning from foundational algorithms through complete navigation systems. We&#x27;ll examine the Nav2 architecture and how behavior trees coordinate complex autonomous behaviors. We&#x27;ll investigate path planning algorithms—understanding how A*, RRT, and hybrid approaches find paths through environments. Local and global planning collaboration will be explored, along with costmap representations that integrate perceptual information. For bipedal robots, we&#x27;ll introduce footstep planning and the Zero Moment Point stability criterion. Finally, we&#x27;ll examine how reinforcement learning can learn navigation policies, leveraging the simulation and perception capabilities from previous chapters.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="core-concepts">Core Concepts<a href="#core-concepts" class="hash-link" aria-label="Direct link to Core Concepts" title="Direct link to Core Concepts" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-navigation-problem-formulation">The Navigation Problem Formulation<a href="#the-navigation-problem-formulation" class="hash-link" aria-label="Direct link to The Navigation Problem Formulation" title="Direct link to The Navigation Problem Formulation" translate="no">​</a></h3>
<p>Formally, the navigation problem can be decomposed into several interconnected subproblems, each with different characteristics and solution approaches.</p>
<p><strong>Configuration Space</strong>: A robot&#x27;s configuration is a complete specification of its pose—position and orientation. For a mobile robot in 2D, configuration is (x, y, theta), where (x, y) is position and theta is heading. The configuration space (C-space) is the space of all possible configurations.</p>
<p><strong>Free Space and Obstacles</strong>: The configuration space divides into free space (configurations where the robot doesn&#x27;t collide with obstacles) and obstacle space (configurations in collision). Navigation requires finding paths through free space.</p>
<p><strong>Motion Planning</strong>: Given a start configuration and goal configuration, find a path through free space connecting them. The path must be collision-free and respect the robot&#x27;s kinematic constraints.</p>
<p><strong>Localization</strong>: Determine the robot&#x27;s current configuration from sensor observations and a map. Localization provides the start configuration for planning.</p>
<p><strong>Mapping</strong>: Build or update a representation of the environment from sensor observations. Maps define obstacle space for planning.</p>
<p><strong>Simultaneous Localization and Mapping (SLAM)</strong>: When operating in unknown environments, the robot must simultaneously determine where it is while building a map. Visual SLAM (Chapter 9) addresses this problem using cameras.</p>
<p><strong>Path Execution</strong>: Follow a planned path using motor commands, accounting for dynamics, actuator limitations, and control errors.</p>
<p><strong>Replanning</strong>: Detect when plans become invalid (obstacles appear, goals change) and generate new plans.</p>
<p>Different navigation approaches emphasize different subproblems. Classical planning assumes known maps and localization, focusing on path planning. SLAM-based approaches jointly solve localization and mapping. Learning-based approaches may learn to navigate directly from perception without explicit planning.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="costmaps-representing-navigation-constraints">Costmaps: Representing Navigation Constraints<a href="#costmaps-representing-navigation-constraints" class="hash-link" aria-label="Direct link to Costmaps: Representing Navigation Constraints" title="Direct link to Costmaps: Representing Navigation Constraints" translate="no">​</a></h3>
<p>Costmaps provide a flexible representation for integrating diverse navigation constraints into a unified framework suitable for planning algorithms.</p>
<p><strong>Costmap Structure</strong>: A costmap is a grid where each cell has a cost value representing the difficulty or danger of traversing that location. Costs typically range from 0 (free space, no cost) to 254 (lethal obstacle, infinite cost), with 255 reserved for unknown space.</p>
<p><strong>Layered Composition</strong>: Modern costmaps (like Nav2&#x27;s costmap_2d) use layers that combine to produce a final cost map:</p>
<p><strong>Static Layer</strong>: Represents permanent obstacles from a pre-built map. This layer changes only when the map is updated. Buildings, walls, and fixed furniture appear in the static layer.</p>
<p><strong>Obstacle Layer</strong>: Represents obstacles detected by sensors at runtime. This layer updates continuously as the robot perceives its surroundings. People, moving objects, and dynamic obstacles appear here.</p>
<p><strong>Inflation Layer</strong>: Expands obstacle costs outward, creating gradients around obstacles. This serves two purposes: (1) keeping planned paths away from obstacles by a safety margin, and (2) providing smooth cost gradients for optimization-based planners.</p>
<p><strong>Voxel Layer</strong>: For 3D sensing (like 3D LiDAR), maintains a 3D representation of obstacles but projects to 2D for planning. This handles situations where obstacles exist at sensor height but not at ground level (tables, overhangs).</p>
<p><strong>Range Sensor Layer</strong>: Integrates sensors with limited fields of view (sonar, infrared) with appropriate uncertainty modeling.</p>
<p><strong>Custom Layers</strong>: Applications can add specialized layers for application-specific constraints (preferred regions, restricted zones, terrain costs).</p>
<p><strong>Layer Combination</strong>: Layers combine using maximum cost—the final cost is the maximum cost from any layer. This ensures that high-cost constraints from any source affect planning.</p>
<p><strong>Inflation Mechanics</strong>: The inflation layer computes costs based on distance to nearest obstacle. Cells containing obstacles have cost 254 (lethal). Cells within inscribed radius (minimum clearance) have cost 253 (inscribed). Cells farther out have costs decreasing with distance, reaching 0 beyond inflation radius.</p>
<p>The cost function is typically:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cost(d) = 253 * exp(-decay * (d - inscribed_radius))</span><br></span></code></pre></div></div>
<p>where d is distance to nearest obstacle, decay controls how quickly cost decreases, and inscribed_radius is the minimum safe clearance.</p>
<p><strong>Footprint Specification</strong>: The robot&#x27;s footprint (its shape and size) determines which cells it occupies at a given configuration. Circular robots use radius; rectangular robots use corner points; arbitrary shapes use polygons. When checking collision, the planner tests if the robot&#x27;s footprint at a configuration intersects lethal obstacles.</p>
<p><strong>Resolution Trade-offs</strong>: Fine resolution (small cells) provides accuracy but increases memory and computation. Coarse resolution reduces costs but loses detail. Typical resolutions range from 5cm for precise indoor navigation to 50cm for large outdoor areas.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="global-vs-local-planning">Global vs. Local Planning<a href="#global-vs-local-planning" class="hash-link" aria-label="Direct link to Global vs. Local Planning" title="Direct link to Global vs. Local Planning" translate="no">​</a></h3>
<p>Navigation systems typically separate planning into global and local components with complementary strengths.</p>
<p><strong>Global Planning</strong>: Computes a path from start to goal considering the entire known map. Global planners:</p>
<ul>
<li class="">Operate on static or slowly-changing maps</li>
<li class="">Run less frequently (when goals change or paths become invalid)</li>
<li class="">Find optimal or near-optimal routes considering large-scale structure</li>
<li class="">Use graph-based or sampling-based algorithms</li>
<li class="">May take hundreds of milliseconds to seconds for complex environments</li>
</ul>
<p><strong>Local Planning</strong>: Computes motion commands considering immediate surroundings and dynamic obstacles. Local planners:</p>
<ul>
<li class="">Operate on local costmaps around the robot</li>
<li class="">Run at high frequency (10-50 Hz) to react to dynamic obstacles</li>
<li class="">Generate velocity commands to follow the global path while avoiding obstacles</li>
<li class="">Use trajectory optimization or control-based methods</li>
<li class="">Must complete in tens of milliseconds to maintain real-time operation</li>
</ul>
<p><strong>Complementary Roles</strong>: Global planning provides strategic direction; local planning provides tactical obstacle avoidance. The global plan acts as a reference trajectory that local planning tracks while handling unexpected obstacles and dynamic conditions.</p>
<p><strong>Interaction</strong>: Local planners receive the global plan as input and attempt to follow it. If local planning repeatedly fails (obstacles block the global path), the navigation system requests a new global plan. This replanning handles situations where the environment has changed since the global plan was computed.</p>
<p><strong>Hybrid Planning</strong>: Some approaches blend global and local planning. Model Predictive Control (MPC) plans short-term trajectories considering dynamics and constraints. Sampling-based methods can replan globally at high frequency if computation permits.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-nav2-navigation-stack">The Nav2 Navigation Stack<a href="#the-nav2-navigation-stack" class="hash-link" aria-label="Direct link to The Nav2 Navigation Stack" title="Direct link to The Nav2 Navigation Stack" translate="no">​</a></h3>
<p>Nav2 (Navigation2) is the navigation framework for ROS 2, providing a complete, modular navigation system.</p>
<p><strong>Nav2 Architecture</strong>: Nav2 consists of several servers and plugins working together:</p>
<p><strong>BT Navigator Server</strong>: Executes behavior trees that coordinate navigation behaviors. The behavior tree determines high-level logic—when to plan, when to follow paths, when to recover from failures.</p>
<p><strong>Planner Server</strong>: Provides global path planning. Multiple planner plugins can be loaded (NavFn, Smac, ThetaStar), allowing selection based on application needs.</p>
<p><strong>Controller Server</strong>: Provides local planning and control. Multiple controller plugins are available (DWB, TEB, RPP), each with different approaches to trajectory generation.</p>
<p><strong>Smoother Server</strong>: Refines paths from global planners, removing unnecessary waypoints and smoothing turns for better trajectory tracking.</p>
<p><strong>Recovery Server</strong>: Executes recovery behaviors when navigation fails. Standard recoveries include spinning in place to clear costmaps, backing up, and waiting.</p>
<p><strong>Costmap 2D</strong>: Maintains global and local costmaps integrating sensor data and map information. Provides costmaps to planners and controllers.</p>
<p><strong>Lifecycle Management</strong>: Nav2 uses ROS 2 lifecycle nodes, enabling controlled startup, shutdown, and state transitions. This improves reliability and allows recovery from failure states.</p>
<p><strong>Plugin Architecture</strong>: Core servers use plugins for algorithms, allowing easy customization and extension. Applications can implement custom planners, controllers, or cost layers without modifying Nav2 core.</p>
<p><strong>Parameter Configuration</strong>: Extensive parameters control behavior—planning frequencies, costmap sizes, inflation parameters, recovery behaviors, etc. Configuration files specify these parameters for different robots and applications.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="behavior-trees-for-navigation">Behavior Trees for Navigation<a href="#behavior-trees-for-navigation" class="hash-link" aria-label="Direct link to Behavior Trees for Navigation" title="Direct link to Behavior Trees for Navigation" translate="no">​</a></h3>
<p>Behavior trees provide a structured way to coordinate complex autonomous behaviors, making them ideal for navigation task coordination.</p>
<p><strong>Behavior Tree Basics</strong>: A behavior tree is a hierarchical structure where nodes represent actions, conditions, or control flow:</p>
<p><strong>Action Nodes</strong>: Execute behaviors (plan path, follow path, spin, back up). Actions succeed, fail, or run continuously.</p>
<p><strong>Condition Nodes</strong>: Check conditions (goal reached? path blocked? battery low?). Conditions succeed or fail immediately.</p>
<p><strong>Control Nodes</strong>: Determine execution flow:</p>
<ul>
<li class=""><strong>Sequence</strong>: Execute children in order; succeed if all succeed, fail if any fails</li>
<li class=""><strong>Fallback (Selector)</strong>: Try children in order; succeed if any succeeds, fail if all fail</li>
<li class=""><strong>Parallel</strong>: Execute multiple children simultaneously</li>
</ul>
<p><strong>Decorators</strong>: Modify child behavior (repeat, invert, timeout).</p>
<p><strong>Navigation Behavior Tree</strong>: A typical Nav2 behavior tree might be:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Fallback (try to navigate, use recovery if fails)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Sequence (normal navigation)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── Condition: Goal Updated?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── Action: Compute Path to Goal</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── Action: Follow Path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └── Condition: Goal Reached?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── Fallback (recovery behaviors)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ├── Action: Clear Costmap (remove stale obstacles)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ├── Action: Spin (rotate to see surroundings)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ├── Action: Back Up (get unstuck)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    └── Action: Wait (pause for obstacles to clear)</span><br></span></code></pre></div></div>
<p><strong>Execution Flow</strong>: The tree evaluates from root. At each control node, children execute according to the node type. The tree ticks at regular frequency (e.g., 10 Hz), allowing reactive behavior.</p>
<p><strong>Advantages</strong>: Behavior trees are modular, composable, and human-readable. Adding new behaviors is straightforward. The hierarchical structure naturally handles priorities and fallbacks. Visual tools can edit and visualize trees.</p>
<p><strong>Nav2 Implementation</strong>: Nav2&#x27;s BT Navigator loads behavior trees from XML files. Custom action nodes can be added as plugins. Trees can include complex logic—checking battery levels, time-of-day routing, multi-goal navigation, and human interaction.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="motion-constraints-and-kinematic-models">Motion Constraints and Kinematic Models<a href="#motion-constraints-and-kinematic-models" class="hash-link" aria-label="Direct link to Motion Constraints and Kinematic Models" title="Direct link to Motion Constraints and Kinematic Models" translate="no">​</a></h3>
<p>Different robot platforms have different motion capabilities, affecting planning and control.</p>
<p><strong>Differential Drive</strong>: Two independently-controlled wheels on a common axis. Steering occurs by varying relative wheel speeds. Constraints:</p>
<ul>
<li class="">Cannot move sideways (nonholonomic constraint)</li>
<li class="">Minimum turning radius determined by wheelbase</li>
<li class="">Zero turning radius possible (spin in place)</li>
<li class="">Forward/backward symmetry</li>
</ul>
<p><strong>Ackermann Steering</strong>: Front wheels steer like a car. Constraints:</p>
<ul>
<li class="">Larger minimum turning radius than differential drive</li>
<li class="">Cannot spin in place</li>
<li class="">More complex kinematics (Ackermann steering geometry)</li>
<li class="">Different forward and backward capabilities</li>
</ul>
<p><strong>Omnidirectional (Holonomic)</strong>: Mecanum or omni wheels allow motion in any direction. Constraints:</p>
<ul>
<li class="">Can move sideways and diagonally</li>
<li class="">Simplified planning (holonomic system)</li>
<li class="">Reduced traction compared to standard wheels</li>
</ul>
<p><strong>Bipedal Locomotion</strong>: Legged robots walk using alternating footsteps. Constraints:</p>
<ul>
<li class="">Must maintain balance (ZMP or similar criteria)</li>
<li class="">Discrete footstep placements</li>
<li class="">Limited step length and frequency</li>
<li class="">Terrain constraints (foot must find stable contact)</li>
</ul>
<p><strong>Planning Implications</strong>: Planners must respect kinematic constraints. Grid-based planners for differential drive robots use 4 or 8 connectivity (cardinal and diagonal moves). State lattice planners precompute kinematically-feasible motion primitives. Optimization-based planners include kinematic constraints in their optimization formulation.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="path-smoothness-and-optimality-criteria">Path Smoothness and Optimality Criteria<a href="#path-smoothness-and-optimality-criteria" class="hash-link" aria-label="Direct link to Path Smoothness and Optimality Criteria" title="Direct link to Path Smoothness and Optimality Criteria" translate="no">​</a></h3>
<p>Different applications prioritize different path qualities, affecting algorithm selection.</p>
<p><strong>Path Length</strong>: Shortest distance from start to goal. Relevant for minimizing travel time at constant speed. A* with Euclidean heuristic optimizes path length.</p>
<p><strong>Curvature</strong>: Rate of change of heading. High curvature requires slow speeds or creates uncomfortable motion. Smoothing algorithms reduce curvature.</p>
<p><strong>Clearance</strong>: Distance to nearest obstacles. Paths with high clearance are safer and more robust to localization error. Voronoi diagrams and potential fields encourage high clearance.</p>
<p><strong>Smoothness</strong>: Rate of change of curvature (jerk) or acceleration. Smooth paths are comfortable for passengers and gentle on hardware. Spline-based smoothing optimizes smoothness.</p>
<p><strong>Kinematic Feasibility</strong>: Paths must be executable given the robot&#x27;s motion constraints. Some planners (RRT) can violate constraints and require post-processing. State lattice planners guarantee feasibility by construction.</p>
<p><strong>Computational Cost</strong>: Planning time affects reactivity. Optimal planners may be too slow for real-time replanning. Suboptimal but fast planners enable responsive navigation.</p>
<p><strong>Trade-offs</strong>: No single path optimizes all criteria. Applications must prioritize based on requirements. Warehouse robots prioritize efficiency; service robots near people prioritize safety; passenger transport prioritizes comfort.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="practical-understanding">Practical Understanding<a href="#practical-understanding" class="hash-link" aria-label="Direct link to Practical Understanding" title="Direct link to Practical Understanding" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-a-star-path-planning">A* (A-Star) Path Planning<a href="#a-a-star-path-planning" class="hash-link" aria-label="Direct link to A* (A-Star) Path Planning" title="Direct link to A* (A-Star) Path Planning" translate="no">​</a></h3>
<p>A* is a graph search algorithm that finds optimal paths by efficiently exploring the state space using heuristics.</p>
<p><strong>Graph Representation</strong>: The environment is represented as a graph where:</p>
<ul>
<li class="">Nodes are possible robot configurations (grid cells or sampled states)</li>
<li class="">Edges connect configurations reachable by feasible motions</li>
<li class="">Edge costs represent the cost of moving between configurations</li>
</ul>
<p>For grid-based planning, each grid cell is a node. Edges connect to neighboring cells (4-connected or 8-connected grids). Edge costs might be Euclidean distance, time to traverse, or energy consumption.</p>
<p><em><em>A</em> Algorithm</em>*: A* maintains two sets:</p>
<ul>
<li class=""><strong>Open set</strong>: Configurations to explore, prioritized by estimated total cost</li>
<li class=""><strong>Closed set</strong>: Configurations already explored</li>
</ul>
<p>For each configuration n, A* tracks:</p>
<ul>
<li class=""><strong>g(n)</strong>: Cost of the best path found so far from start to n</li>
<li class=""><strong>h(n)</strong>: Heuristic estimate of cost from n to goal</li>
<li class=""><strong>f(n) = g(n) + h(n)</strong>: Estimated total cost of path through n</li>
</ul>
<p><strong>Algorithm Steps</strong>:</p>
<ol>
<li class="">
<p>Initialize: Add start configuration to open set with g(start) = 0</p>
</li>
<li class="">
<p>While open set not empty:
a. Select configuration n from open set with minimum f(n)
b. If n is goal, reconstruct and return path
c. Move n from open set to closed set
d. For each neighbor m of n:</p>
<ul>
<li class="">Compute tentative cost: g_tentative = g(n) + cost(n, m)</li>
<li class="">If m in closed set and g_tentative &gt;= g(m), skip</li>
<li class="">If m not in open set or g_tentative &lt; g(m):<!-- -->
<ul>
<li class="">Set g(m) = g_tentative</li>
<li class="">Set parent(m) = n</li>
<li class="">Add m to open set (or update its priority)</li>
</ul>
</li>
</ul>
</li>
<li class="">
<p>If open set becomes empty without finding goal, no path exists</p>
</li>
</ol>
<p><strong>Path Reconstruction</strong>: When the goal is reached, reconstruct the path by following parent pointers from goal back to start, then reverse.</p>
<p><strong>Heuristic Function</strong>: The heuristic h(n) estimates cost from n to goal. Admissible heuristics (never overestimate true cost) guarantee A* finds optimal paths. Common heuristics:</p>
<ul>
<li class=""><strong>Euclidean distance</strong>: Straight-line distance to goal (admissible for any motion)</li>
<li class=""><strong>Manhattan distance</strong>: Sum of horizontal and vertical distances (for 4-connected grids)</li>
<li class=""><strong>Diagonal distance</strong>: Accounts for diagonal moves (for 8-connected grids)</li>
</ul>
<p>Better heuristics (closer to true cost without overestimating) make A* more efficient by focusing search toward the goal.</p>
<p><strong>Optimality</strong>: With an admissible heuristic, A* is optimal—it finds the lowest-cost path. This is proven by contradiction: if A* returned a suboptimal path, it would have explored the optimal path first (due to lower f-value).</p>
<p><strong>Efficiency</strong>: A* is efficient because the heuristic guides search toward the goal, avoiding exploration of irrelevant regions. In the best case (perfect heuristic), A* explores only the optimal path. In the worst case (no heuristic, h=0), A* degenerates to Dijkstra&#x27;s algorithm, exploring all reachable configurations.</p>
<p><strong>Practical Considerations</strong>:</p>
<ul>
<li class=""><strong>Grid Resolution</strong>: Finer grids increase accuracy but multiply the number of nodes quadratically (in 2D), increasing computation.</li>
<li class=""><strong>Tie Breaking</strong>: When multiple nodes have identical f-values, tie-breaking rules can reduce nodes explored. Preferring nodes closer to goal (by h-value) helps.</li>
<li class=""><strong>Early Termination</strong>: For real-time systems, A* can terminate after a time limit and return the best partial path found.</li>
</ul>
<p><strong>Limitations</strong>: A* finds optimal paths on the given graph. If the graph resolution is coarse, the &quot;optimal&quot; path may still have poor quality. A* struggles with high-dimensional configuration spaces (curse of dimensionality) as the number of nodes explodes.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="dijkstras-algorithm">Dijkstra&#x27;s Algorithm<a href="#dijkstras-algorithm" class="hash-link" aria-label="Direct link to Dijkstra&#x27;s Algorithm" title="Direct link to Dijkstra&#x27;s Algorithm" translate="no">​</a></h3>
<p>Dijkstra&#x27;s algorithm is a foundational graph search method that finds shortest paths from a start node to all other nodes.</p>
<p><strong>Algorithm Overview</strong>: Dijkstra&#x27;s is similar to A* but without a heuristic (equivalently, h(n) = 0 for all n). It explores configurations in order of increasing cost from the start.</p>
<p><strong>Algorithm Steps</strong>:</p>
<ol>
<li class="">Initialize all nodes with infinite cost; set start cost to 0</li>
<li class="">Add all nodes to a priority queue, prioritized by cost</li>
<li class="">While priority queue not empty:
a. Extract node n with minimum cost
b. For each neighbor m of n:<!-- -->
<ul>
<li class="">Compute tentative cost: cost_tentative = cost(n) + edge_cost(n,m)</li>
<li class="">If cost_tentative &lt; cost(m):<!-- -->
<ul>
<li class="">Update cost(m) = cost_tentative</li>
<li class="">Set parent(m) = n</li>
<li class="">Update m&#x27;s priority in queue</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>Optimality</strong>: Dijkstra&#x27;s finds the shortest path from start to all reachable nodes. It&#x27;s guaranteed optimal for non-negative edge costs.</p>
<p><strong>Comparison with A</strong>*: Dijkstra&#x27;s is A* with h(n) = 0. It explores more nodes because it lacks goal-directed guidance. However, Dijkstra&#x27;s finds shortest paths to all nodes, useful when planning to multiple goals or when the goal changes frequently.</p>
<p><strong>Computational Complexity</strong>: With a binary heap priority queue, Dijkstra&#x27;s has complexity O((V + E) log V), where V is the number of nodes and E is the number of edges. For dense graphs, Fibonacci heaps reduce complexity to O(E + V log V).</p>
<p><strong>Applications</strong>: Dijkstra&#x27;s is foundational in navigation. NavFn (Navigation Function), a popular Nav2 global planner, is essentially Dijkstra&#x27;s algorithm computing a potential field from the goal.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="rrt-rapidly-exploring-random-tree">RRT (Rapidly-Exploring Random Tree)<a href="#rrt-rapidly-exploring-random-tree" class="hash-link" aria-label="Direct link to RRT (Rapidly-Exploring Random Tree)" title="Direct link to RRT (Rapidly-Exploring Random Tree)" translate="no">​</a></h3>
<p>RRT is a sampling-based planning algorithm that efficiently explores high-dimensional configuration spaces.</p>
<p><strong>Motivation</strong>: Grid-based methods like A* struggle with high-dimensional spaces due to exponential growth in the number of cells. RRT avoids discretization by randomly sampling configurations and building a tree of feasible paths.</p>
<p><strong>Algorithm Overview</strong>: RRT builds a tree rooted at the start configuration by iteratively sampling random configurations and extending the tree toward them.</p>
<p><strong>Algorithm Steps</strong>:</p>
<ol>
<li class="">Initialize tree with start configuration</li>
<li class="">For i = 1 to max_iterations:
a. Sample random configuration q_rand (uniformly or with goal bias)
b. Find nearest configuration q_near in tree to q_rand
c. Extend from q_near toward q_rand by step size δ to get q_new
d. If motion from q_near to q_new is collision-free:<!-- -->
<ul>
<li class="">Add q_new to tree with parent q_near
e. If q_new is within goal region, return path from start to q_new</li>
</ul>
</li>
</ol>
<p><strong>Tree Expansion</strong>: The nearest-neighbor search finds q_near, the tree node closest to q_rand. Extension creates q_new by moving from q_near toward q_rand by a fixed distance δ. This biases expansion toward unexplored regions (represented by q_rand) while maintaining connectivity (from q_near).</p>
<p><strong>Collision Checking</strong>: Before adding q_new, verify that the path from q_near to q_new is collision-free. This typically involves checking configurations along the path at fine resolution.</p>
<p><strong>Goal Biasing</strong>: Purely random sampling may rarely sample near the goal. Goal biasing samples the goal configuration with some probability (e.g., 10%), directing search toward the goal.</p>
<p><strong>Probabilistic Completeness</strong>: RRT is probabilistically complete—if a path exists, RRT will find one given enough time (iterations). However, RRT does not guarantee optimality.</p>
<p><strong>RRT</strong>*: An optimized variant, RRT* (RRT-star), maintains optimality by rewiring the tree. After adding q_new, RRT* checks if using q_new as a parent for nearby nodes reduces their cost. Over time, paths improve toward optimality. RRT* is asymptotically optimal—as iterations increase, paths converge to optimal.</p>
<p><strong>Advantages</strong>:</p>
<ul>
<li class="">Handles high-dimensional configuration spaces efficiently</li>
<li class="">No need for discretization</li>
<li class="">Anytime algorithm (can return best solution found at any time)</li>
<li class="">Naturally handles complex kinematic constraints (using feasible extensions)</li>
</ul>
<p><strong>Limitations</strong>:</p>
<ul>
<li class="">Paths are often jagged and suboptimal without post-smoothing</li>
<li class="">Performance depends on distance metric and sampling distribution</li>
<li class="">Nearest-neighbor search can be expensive (mitigated with kd-trees)</li>
</ul>
<p><strong>Applications</strong>: RRT excels for high-DOF systems like robot arms (6+ dimensions). For mobile robots, RRT&#x27;s overhead may not be justified, but variants (like kinodynamic RRT considering dynamics) handle complex constraints.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hybrid-a-and-state-lattice-planning">Hybrid A* and State Lattice Planning<a href="#hybrid-a-and-state-lattice-planning" class="hash-link" aria-label="Direct link to Hybrid A* and State Lattice Planning" title="Direct link to Hybrid A* and State Lattice Planning" translate="no">​</a></h3>
<p>Hybrid A* and state lattice planning address the limitations of grid-based A* for nonholonomic robots.</p>
<p><em><em>Hybrid A</em> Overview</em>*: Hybrid A* combines A* graph search with continuous state space. Instead of discrete grid cells, nodes are continuous configurations (x, y, theta). Edges are kinematically-feasible motion primitives.</p>
<p><strong>State Space</strong>: Nodes are continuous configurations, but discretization is used for hashing and duplicate detection. A coarse grid discretizes (x, y, theta) to determine if two configurations are &quot;equivalent.&quot;</p>
<p><strong>Motion Primitives</strong>: From each configuration, a set of control inputs generates motion primitives (short trajectories). For a car-like robot, primitives might be:</p>
<ul>
<li class="">Forward with left turn</li>
<li class="">Forward straight</li>
<li class="">Forward with right turn</li>
<li class="">Backward with left turn</li>
<li class="">Backward straight</li>
<li class="">Backward with right turn</li>
</ul>
<p>Each primitive has a duration and resulting configuration after execution.</p>
<p><strong>Algorithm</strong>: Hybrid A* proceeds like A*, but:</p>
<ul>
<li class="">States are continuous configurations</li>
<li class="">Successors are generated by applying motion primitives</li>
<li class="">Collision checking verifies primitives don&#x27;t intersect obstacles</li>
<li class="">Heuristic is modified to account for nonholonomic constraints (e.g., Reeds-Shepp distance for cars)</li>
</ul>
<p><strong>Analytic Expansion</strong>: To improve solution quality, Hybrid A* periodically attempts to connect the current node directly to the goal using an analytical solution (e.g., Dubins or Reeds-Shepp paths for car-like robots). If successful, this provides a feasible, optimal (for the kinematic model) path.</p>
<p><strong>State Lattice Planning</strong>: State lattice is similar but precomputes a regular lattice of configurations and motion primitives connecting them. The lattice provides the graph for A* search. Advantages:</p>
<ul>
<li class="">Precomputation amortizes motion primitive generation cost</li>
<li class="">Lattice structure simplifies search</li>
<li class="">Easy to tune for different robot types</li>
</ul>
<p><strong>Applications</strong>: Hybrid A* is used in autonomous driving (e.g., by Tesla) for parking and low-speed maneuvering. State lattices are used in Nav2&#x27;s Smac planner family for both 2D and 3D planning.</p>
<p><strong>Comparison with RRT</strong>: Hybrid A* and lattice planning provide higher-quality, kinematically-feasible paths than RRT for low-dimensional problems. RRT remains preferable for high-dimensional spaces where lattice discretization becomes intractable.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="local-planning-and-trajectory-optimization">Local Planning and Trajectory Optimization<a href="#local-planning-and-trajectory-optimization" class="hash-link" aria-label="Direct link to Local Planning and Trajectory Optimization" title="Direct link to Local Planning and Trajectory Optimization" translate="no">​</a></h3>
<p>Local planners generate short-term trajectories that follow the global path while avoiding dynamic obstacles.</p>
<p><strong>Dynamic Window Approach (DWA)</strong>: DWA generates candidate trajectories by sampling velocity commands within the robot&#x27;s dynamic constraints.</p>
<p><strong>Dynamic Window</strong>: The set of achievable velocities given current velocity and acceleration limits. For a differential drive robot, this is a 2D window in (v, omega) space, where v is linear velocity and omega is angular velocity.</p>
<p><strong>DWA Algorithm</strong>:</p>
<ol>
<li class="">Sample velocity pairs (v, omega) from the dynamic window</li>
<li class="">For each sampled velocity, simulate forward for a short duration (e.g., 1 second) to predict trajectory</li>
<li class="">Evaluate each trajectory with an objective function considering:<!-- -->
<ul>
<li class="">Obstacle distance (maximize clearance)</li>
<li class="">Progress toward goal (minimize distance to global path or goal)</li>
<li class="">Velocity (prefer higher speeds when safe)</li>
</ul>
</li>
<li class="">Select velocity command that maximizes objective</li>
<li class="">Send command to robot, repeat at control frequency</li>
</ol>
<p><strong>Trajectory Evaluation</strong>: The objective function weights different criteria:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">score = w1 * heading_to_goal + w2 * clearance + w3 * velocity</span><br></span></code></pre></div></div>
<p>Tuning weights balances safety (clearance), efficiency (velocity), and goal-directedness (heading).</p>
<p><strong>Advantages</strong>: DWA is computationally efficient, handles dynamic obstacles naturally, and provides smooth motion. It&#x27;s widely used in ROS for differential drive robots.</p>
<p><strong>Limitations</strong>: DWA&#x27;s short look-ahead horizon can cause local minima—the robot gets stuck when all short-term trajectories appear unsafe, even though longer-term planning could escape. Combining DWA with a global planner mitigates this.</p>
<p><strong>Timed Elastic Band (TEB)</strong>: TEB is an optimization-based local planner that refines a path into a trajectory by optimizing a cost function subject to constraints.</p>
<p><strong>TEB Representation</strong>: The trajectory is represented as a sequence of poses with associated timings. This &quot;elastic band&quot; can deform to avoid obstacles while optimizing objectives.</p>
<p><strong>Optimization Objective</strong>: TEB minimizes a cost function including:</p>
<ul>
<li class="">Path length</li>
<li class="">Trajectory execution time</li>
<li class="">Distance to obstacles</li>
<li class="">Deviation from global path</li>
<li class="">Smoothness (acceleration and jerk)</li>
<li class="">Kinematic and dynamic constraints</li>
</ul>
<p><strong>Optimization</strong>: TEB uses nonlinear optimization (g2o or custom solvers) to refine the trajectory. Obstacles and kinematic limits are encoded as constraints or penalty terms.</p>
<p><strong>Advantages</strong>: TEB produces high-quality, smooth, time-optimal trajectories. It handles kinematic constraints well and can plan for Ackermann and omnidirectional robots.</p>
<p><strong>Limitations</strong>: Computational cost is higher than DWA. Tuning the many parameters can be complex. Performance depends on initial trajectory quality.</p>
<p><strong>Model Predictive Control (MPC)</strong>: MPC formulates trajectory generation as an optimal control problem. At each timestep, MPC solves an optimization problem to find control inputs over a receding horizon that minimize cost while satisfying constraints.</p>
<p><strong>MPC Process</strong>:</p>
<ol>
<li class="">Measure current state</li>
<li class="">Solve optimization: minimize cost over horizon subject to dynamics and constraints</li>
<li class="">Apply first control input from solution</li>
<li class="">Advance time, repeat</li>
</ol>
<p><strong>Advantages</strong>: MPC explicitly handles constraints and dynamics. It optimizes over longer horizons than DWA, avoiding some local minima. MPC provides provable stability and constraint satisfaction.</p>
<p><strong>Limitations</strong>: Real-time optimization can be computationally demanding. Performance depends on model accuracy. MPC is common in research but less prevalent in production systems than DWA or TEB.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="bipedal-locomotion-and-footstep-planning">Bipedal Locomotion and Footstep Planning<a href="#bipedal-locomotion-and-footstep-planning" class="hash-link" aria-label="Direct link to Bipedal Locomotion and Footstep Planning" title="Direct link to Bipedal Locomotion and Footstep Planning" translate="no">​</a></h3>
<p>Bipedal robots introduce unique challenges because they must maintain balance while moving.</p>
<p><strong>Balance and Stability</strong>: A bipedal robot is statically unstable—it cannot stand still without control. Dynamic stability requires continuous control to keep the robot&#x27;s center of mass above the support polygon (the convex hull of ground contact points).</p>
<p><strong>Zero Moment Point (ZMP)</strong>: ZMP is a criterion for dynamic stability during bipedal locomotion. The ZMP is the point on the ground where the total moment (torque) from gravity and inertia is zero.</p>
<p><strong>ZMP Stability Criterion</strong>: If the ZMP lies within the support polygon, the robot will not tip over. If the ZMP moves outside the support polygon, unbalanced torques cause rotation (tipping).</p>
<p><strong>ZMP in Walking</strong>: During single support (one foot on ground), the support polygon is just the support foot&#x27;s contact area. During double support (both feet on ground), the support polygon includes both feet. Walking controllers plan motions that keep the ZMP within the support polygon throughout the gait cycle.</p>
<p><strong>Footstep Planning</strong>: Bipedal navigation requires planning where to place each foot. Footstep planning determines:</p>
<ul>
<li class="">Foot placements (x, y, theta for each foot)</li>
<li class="">Step timing</li>
<li class="">Sequence (left, right, left, right...)</li>
</ul>
<p><strong>Footstep Planning Considerations</strong>:</p>
<ul>
<li class=""><strong>Reachability</strong>: Each step must be reachable given leg kinematics and previous step</li>
<li class=""><strong>Stability</strong>: Foot placements must allow ZMP to stay in support polygon</li>
<li class=""><strong>Terrain</strong>: Feet must land on stable, flat surfaces</li>
<li class=""><strong>Obstacle Avoidance</strong>: Feet and legs must clear obstacles during swing phase</li>
<li class=""><strong>Efficiency</strong>: Minimize number of steps or energy consumption</li>
</ul>
<p><strong>Planning Approaches</strong>:</p>
<p><strong>Grid-Based</strong>: Discretize the environment into foot placement locations. Use A* or similar to search for footstep sequences. Each state is a foot placement; edges are feasible steps.</p>
<p><strong>Optimization-Based</strong>: Formulate footstep planning as an optimization problem, minimizing cost (number of steps, energy) subject to constraints (reachability, stability, collision-free).</p>
<p><strong>Learning-Based</strong>: Train policies to select footsteps using reinforcement learning in simulation, potentially generalizing across terrain types.</p>
<p><strong>Integration with Whole-Body Control</strong>: Footstep planning provides high-level step targets. Whole-body controllers compute joint torques to execute steps while maintaining balance, handling dynamics and contact forces.</p>
<p><strong>Challenges</strong>: Bipedal locomotion on uneven terrain, stairs, or with obstacles is an active research area. Humanoid robots like Boston Dynamics&#x27; Atlas demonstrate impressive capabilities but rely on sophisticated perception, planning, and control integration.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="obstacle-avoidance-strategies">Obstacle Avoidance Strategies<a href="#obstacle-avoidance-strategies" class="hash-link" aria-label="Direct link to Obstacle Avoidance Strategies" title="Direct link to Obstacle Avoidance Strategies" translate="no">​</a></h3>
<p>Effective obstacle avoidance balances safety, efficiency, and smoothness.</p>
<p><strong>Potential Fields</strong>: Treat obstacles as repulsive potentials and goals as attractive potentials. The robot follows the negative gradient of the total potential field.</p>
<p><strong>Attractive Potential</strong>: Increases with distance from goal, pulling the robot toward the goal.</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">U_attractive = 0.5 * k_attractive * distance_to_goal^2</span><br></span></code></pre></div></div>
<p><strong>Repulsive Potential</strong>: Increases as the robot approaches obstacles, pushing the robot away.</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">U_repulsive = 0.5 * k_repulsive * (1/distance_to_obstacle - 1/threshold)^2</span><br></span></code></pre></div></div>
<p>for distance &lt; threshold, 0 otherwise.</p>
<p><strong>Control</strong>: Compute the total potential U = U_attractive + U_repulsive, and command velocity proportional to -∇U (negative gradient).</p>
<p><strong>Advantages</strong>: Simple, reactive, smooth motion.</p>
<p><strong>Limitations</strong>: Local minima where the robot gets stuck (gradient is zero but goal not reached). Oscillations in narrow passages. Poor performance with dynamic obstacles.</p>
<p><strong>Vector Field Histogram (VFH)</strong>: VFH builds a histogram of obstacles in polar coordinates around the robot. It identifies &quot;valleys&quot; (directions with low obstacle density) and selects steering toward the goal through the widest valley.</p>
<p><strong>Algorithm</strong>:</p>
<ol>
<li class="">Build histogram: For each angular sector around the robot, compute obstacle density (from sensor data or costmap)</li>
<li class="">Identify valleys: Sectors with obstacle density below threshold</li>
<li class="">Select direction: Choose valley direction closest to goal heading</li>
<li class="">Compute velocity: Move in selected direction at speed inversely proportional to obstacle proximity</li>
</ol>
<p><strong>Advantages</strong>: Handles dynamic obstacles, no local minima in practice, computationally efficient.</p>
<p><strong>Limitations</strong>: Short-sighted (considers only local information), may not find narrow passages.</p>
<p><strong>Elastic Bands</strong>: Represent the path as a sequence of waypoints connected by &quot;elastic bands.&quot; Obstacles apply repulsive forces; a tension force pulls waypoints toward each other (shortening the path). The band deforms to avoid obstacles while minimizing length.</p>
<p><strong>Deformation</strong>: Iteratively adjust waypoints based on attractive (tension) and repulsive (obstacle) forces until equilibrium.</p>
<p><strong>Advantages</strong>: Smooth, continuous path deformation. Handles dynamic obstacles by continuous replanning.</p>
<p><strong>Limitations</strong>: Can get stuck in local minima. Computationally more expensive than simpler reactive methods.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="recovery-behaviors">Recovery Behaviors<a href="#recovery-behaviors" class="hash-link" aria-label="Direct link to Recovery Behaviors" title="Direct link to Recovery Behaviors" translate="no">​</a></h3>
<p>Robots encounter situations where forward progress fails: obstacles block all paths, localization becomes uncertain, or wheels slip. Recovery behaviors provide fallback strategies.</p>
<p><strong>Common Recovery Behaviors</strong>:</p>
<p><strong>Clear Costmap</strong>: Sometimes obstacles in the costmap are stale (objects moved but costmap not updated). Clearing the obstacle layer removes these false obstacles, allowing replanning.</p>
<p><strong>Rotate in Place</strong>: Rotating allows the robot to perceive surroundings with its sensors, potentially finding a path not visible before. Rotation also can clear dynamic obstacles (people might move aside).</p>
<p><strong>Back Up</strong>: If forward paths are blocked, backing up creates space and may escape local minima.</p>
<p><strong>Wait</strong>: For dynamic obstacles (people walking), waiting allows the obstacle to pass. Waiting is preferable to aggressive maneuvering in crowded spaces.</p>
<p><strong>Get Help</strong>: If recovery behaviors fail repeatedly, the robot may request human assistance or teleoperation.</p>
<p><strong>Recovery Sequencing</strong>: Behavior trees naturally encode recovery sequences. A fallback node tries normal navigation first, then recovery behaviors in order of increasing severity:</p>
<ol>
<li class="">Clear costmap (lightweight, non-invasive)</li>
<li class="">Rotate in place (moderate, changes heading)</li>
<li class="">Back up (more severe, changes position)</li>
<li class="">Wait (passive, assumes environment changes)</li>
<li class="">Request help (last resort)</li>
</ol>
<p><strong>Preventing Thrashing</strong>: Recovery behaviors should not execute too frequently (thrashing). Implement timeout or success counters to detect persistent failures and escalate to higher-level recovery or abort.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="reinforcement-learning-for-navigation">Reinforcement Learning for Navigation<a href="#reinforcement-learning-for-navigation" class="hash-link" aria-label="Direct link to Reinforcement Learning for Navigation" title="Direct link to Reinforcement Learning for Navigation" translate="no">​</a></h3>
<p>Reinforcement learning (RL) offers an alternative to classical planning: learn navigation policies directly from interaction with environments.</p>
<p><strong>Problem Formulation</strong>: Formulate navigation as a Markov Decision Process (MDP):</p>
<ul>
<li class=""><strong>State</strong>: Robot&#x27;s observations (sensor data, goal relative pose, velocity)</li>
<li class=""><strong>Action</strong>: Motion commands (linear and angular velocities, or discrete actions like &quot;turn left&quot;)</li>
<li class=""><strong>Reward</strong>: Progress toward goal, penalties for collisions or inefficiency</li>
<li class=""><strong>Transition Dynamics</strong>: How states evolve given actions (unknown, learned implicitly)</li>
</ul>
<p><strong>Policy</strong>: A policy π(a|s) maps states to actions. The objective is to find a policy that maximizes cumulative reward.</p>
<p><strong>Training in Simulation</strong>: RL requires many interactions (millions of steps). Training in the physical world is impractical. Isaac Sim provides an ideal training environment:</p>
<ul>
<li class="">Parallel simulation instances (Chapter 8) enable massive throughput</li>
<li class="">Domain randomization (Chapter 8) creates diverse scenarios for robust policies</li>
<li class="">Perfect sensor simulation (Chapter 9) provides realistic observations</li>
</ul>
<p><strong>Training Process</strong>:</p>
<ol>
<li class="">Initialize policy (random or from supervised pre-training)</li>
<li class="">Collect experience by executing policy in simulated environments</li>
<li class="">Use collected experience to update policy (using PPO, SAC, or other RL algorithms)</li>
<li class="">Repeat until policy converges or performance plateaus</li>
<li class="">Evaluate in simulation and deploy to physical robots</li>
</ol>
<p><strong>Observation Space</strong>: What the policy observes affects its capabilities:</p>
<ul>
<li class=""><strong>Low-Dimensional</strong>: Goal relative position, LiDAR ranges, velocity. Faster learning, less expressive.</li>
<li class=""><strong>High-Dimensional</strong>: Raw camera images, depth maps. More expressive but requires more training.</li>
<li class=""><strong>Hybrid</strong>: Combine learned visual features with geometric information.</li>
</ul>
<p><strong>Reward Shaping</strong>: Reward design critically affects learned behavior:</p>
<ul>
<li class=""><strong>Sparse</strong>: +1 for reaching goal, 0 otherwise. Difficult to learn from.</li>
<li class=""><strong>Dense</strong>: Continuous reward based on distance to goal, encouraging progress.</li>
<li class=""><strong>Shaped</strong>: Add penalties for collisions, smoothness rewards for gentle motion, social rewards for respecting personal space.</li>
</ul>
<p><strong>Curriculum Learning</strong>: Start training with simple scenarios (few obstacles, short distances) and gradually increase difficulty (more obstacles, longer distances, narrow passages). This accelerates learning by providing easier learning objectives initially.</p>
<p><strong>Sim-to-Real Transfer</strong>: Policies trained in simulation must transfer to physical robots. Techniques to improve transfer:</p>
<ul>
<li class=""><strong>Domain Randomization</strong>: Vary simulation parameters to ensure the real world falls within training distribution.</li>
<li class=""><strong>System Identification</strong>: Measure physical robot parameters and configure simulation to match.</li>
<li class=""><strong>Fine-Tuning</strong>: After sim training, fine-tune on limited physical data.</li>
<li class=""><strong>Residual Learning</strong>: Learn a residual policy that corrects a classical controller, requiring less data.</li>
</ul>
<p><strong>Advantages of RL for Navigation</strong>:</p>
<ul>
<li class="">End-to-end learning from perception to control, avoiding hand-engineered features</li>
<li class="">Potential to discover novel strategies not considered by human designers</li>
<li class="">Adapts to diverse environments through training distribution</li>
</ul>
<p><strong>Challenges</strong>:</p>
<ul>
<li class="">Sample inefficiency (requires many interactions)</li>
<li class="">Reward engineering (designing rewards that encourage desired behavior)</li>
<li class="">Sim-to-real gap (simulation doesn&#x27;t perfectly match reality)</li>
<li class="">Safety (learned policies may exhibit unexpected behavior)</li>
</ul>
<p><strong>Hybrid Approaches</strong>: Combining RL with classical methods provides benefits of both:</p>
<ul>
<li class="">Use classical global planning for strategic routing, RL for local obstacle avoidance</li>
<li class="">Use RL to learn costs or heuristics for classical planners</li>
<li class="">Use classical controllers as baselines, RL learns residuals or corrections</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conceptual-diagrams">Conceptual Diagrams<a href="#conceptual-diagrams" class="hash-link" aria-label="Direct link to Conceptual Diagrams" title="Direct link to Conceptual Diagrams" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="nav2-architecture">Nav2 Architecture<a href="#nav2-architecture" class="hash-link" aria-label="Direct link to Nav2 Architecture" title="Direct link to Nav2 Architecture" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                     Nav2 Architecture Overview                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |                  Application Layer                         |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  (User Code: Send goals, monitor navigation status)        |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                            |                                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                            v                                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |              BT Navigator Server                           |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  (Executes Behavior Tree to coordinate navigation)         |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|           |                |               |                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|           v                v               v                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +---------------+  +---------------+  +------------------+      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  | Planner Server|  |Controller Srv |  | Recovery Server  |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +---------------+  +---------------+  +------------------+      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |               |  |               |  |                  |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  | Plugins:      |  | Plugins:      |  | Behaviors:       |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  | - NavFn       |  | - DWB         |  | - Spin           |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  | - SmacPlanner |  | - TEB         |  | - BackUp         |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  | - ThetaStar   |  | - RPP         |  | - Wait           |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |               |  | - MPC         |  | - ClearCostmap   |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +---------------+  +---------------+  +------------------+      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|           |                |                      |              |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|           +----------------+----------------------+              |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                            |                                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                            v                                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |                 Costmap 2D (Global &amp; Local)                |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |                                                            |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  Layers (composited to create final costmap):             |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |                                                            |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  +-------------+  +-------------+  +------------------+    |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  | Static Layer|  |Obstacle Lyr |  | Inflation Layer  |    |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  | (from map)  |  | (sensors)   |  | (safety margins) |    |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  +-------------+  +-------------+  +------------------+    |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |                                                            |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  +-------------+  +-------------+  +------------------+    |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  | Voxel Layer |  | Range Layer |  | Custom Layers    |    |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  | (3D-&gt;2D)    |  | (sonar,IR)  |  | (app-specific)   |    |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  +-------------+  +-------------+  +------------------+    |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |                                                            |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                            |                                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                            v                                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |                    Sensor Inputs                           |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  (LiDAR, Cameras, Depth, IMU, Odometry)                    |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|           |                                                       |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|           v                                                       |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |            Perception Stack (Isaac ROS)                    |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  (Visual SLAM, Stereo Depth, Object Detection, etc.)       |  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +------------------------------------------------------------+  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Data Flow:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Sensors → Perception → Costmap (obstacle layer updates)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Map → Costmap (static layer)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Costmap → Planner → Global path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Global path + Costmap → Controller → Velocity commands</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. Velocity commands → Robot actuators</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">6. BT Navigator orchestrates all interactions</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="behavior-tree-for-navigation">Behavior Tree for Navigation<a href="#behavior-tree-for-navigation" class="hash-link" aria-label="Direct link to Behavior Tree for Navigation" title="Direct link to Behavior Tree for Navigation" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|              Navigation Behavior Tree Example                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Root: Fallback (Try navigation, use recovery if fails)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─── Sequence: Normal Navigation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    ├─── Condition: Is Goal Updated?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    (Check if new goal received)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    Success → Continue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    Failure → Skip to next behavior</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    ├─── Action: Compute Path to Goal</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    (Call Planner Server)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    Running → Wait for plan</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    Success → Continue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    Failure → Propagate failure (try recovery)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    ├─── Action: Follow Path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    (Call Controller Server)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    Running → Continue execution</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    Success → Continue to check goal</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │    Failure → Propagate failure (try recovery)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│    └─── Condition: Is Goal Reached?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│         (Check distance to goal)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│         Success → Navigation complete!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│         Failure → Replan (loop to Compute Path)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└─── Fallback: Recovery Behaviors</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     (Try each recovery in sequence until one succeeds)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     ├─── Sequence: Clear Costmap Recovery</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    ├─── Action: Clear Costmap</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │    (Remove stale obstacles)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    └─── Action: Attempt Navigation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │         (Go back to Compute Path)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     ├─── Sequence: Spin Recovery</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    ├─── Action: Spin in Place</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │    (Rotate to see surroundings)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    └─── Action: Attempt Navigation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     ├─── Sequence: Back Up Recovery</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    ├─── Action: Back Up</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │    (Reverse to create space)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    └─── Action: Attempt Navigation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     ├─── Sequence: Wait Recovery</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    ├─── Action: Wait</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │    (Pause for dynamic obstacles to clear)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │    └─── Action: Attempt Navigation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     └─── Action: Request Human Assistance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          (Last resort: signal for help)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Execution:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Tree ticks at frequency (e.g., 10 Hz)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Control nodes determine flow based on child status</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Fallback tries children until one succeeds</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Sequence executes children in order, failing if any fails</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-path-planning-visualization">A* Path Planning Visualization<a href="#a-path-planning-visualization" class="hash-link" aria-label="Direct link to A* Path Planning Visualization" title="Direct link to A* Path Planning Visualization" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                   A* Algorithm Visualization                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Environment (10x10 grid):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  0 1 2 3 4 5 6 7 8 9</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0 . . . X X X . . . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1 . . . X X X . . . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2 S . . . . . . . . .   S = Start (2,0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3 . . . . X X X . . .   G = Goal (7,9)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4 . . . . X X X . . .   X = Obstacle</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5 . . . . . . . . . .   . = Free space</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">6 . . X X X . . . . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">7 . . X X X . . . . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">8 . . . . . . . . . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">9 . . . . . . . . G .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">A* Search Process:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Step 1: Initialize</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Open Set: {S(2,0)}  f(S)=0+9=9  (g=0, h=9 heuristic to goal)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Closed Set: {}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Step 2: Expand S(2,0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Neighbors: (2,1), (3,0), (1,0), (3,1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Open Set: {(2,1)[f=10], (3,0)[f=10], (1,0)[f=10], (3,1)[f=11]}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Closed Set: {S(2,0)}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Step 3: Expand (2,1) [lowest f-value]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Neighbors: (2,2), (3,1), (1,1), (2,0)[closed]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Open Set: {(3,0)[f=10], (1,0)[f=10], (3,1)[f=11], (2,2)[f=11], (1,1)[f=11]}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Closed Set: {S(2,0), (2,1)}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">... [continuing expansion]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Step N: Goal Found</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Open Set: {..., G(7,9)[f=17]}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Closed Set: {..., (7,8)}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Path Reconstruction (following parent pointers):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  G(7,9) ← (7,8) ← (7,7) ← (6,6) ← (5,5) ← (4,4) ← (3,3) ← (2,2) ← (2,1) ← S(2,0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Final Path (reversed):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  S → (2,1) → (2,2) → (3,3) → (4,4) → (5,5) → (6,6) → (7,7) → (7,8) → G</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Visualization of Explored Nodes:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  0 1 2 3 4 5 6 7 8 9</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0 + + + X X X . . . .    + = Explored by A*</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1 + + + X X X . . . .    * = Final path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2 S * + + + . . . . .    X = Obstacle</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3 . + * + X X X . . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4 . + + * X X X . . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5 . + + + * + . . . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">6 . . X X X * + . . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">7 . . X X X + * + . .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">8 . . + + + + + * + .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">9 . . + + + + + + G .</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Key Observations:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- A* explores far fewer nodes than Dijkstra (compares to exploring all + cells)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Heuristic guides search toward goal (upper-right direction)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Avoids exploring lower-left region (heuristic indicates it&#x27;s away from goal)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Found path is optimal (shortest given obstacle constraints)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="global-vs-local-planning-interaction">Global vs. Local Planning Interaction<a href="#global-vs-local-planning-interaction" class="hash-link" aria-label="Direct link to Global vs. Local Planning Interaction" title="Direct link to Global vs. Local Planning Interaction" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|          Global Planning vs. Local Planning                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Global Planning:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Input: Start pose, Goal pose, Static map                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Output: Path (sequence of waypoints)                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Frequency: 0.5-2 Hz (when needed)                        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Considers: Full map, static obstacles, path optimality   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        | Global Path (waypoints)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Example Global Path:                                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   *─────────────────┐                                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │                 │                                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │   ┌──────┐      │                                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │   │      │      │                                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   └───┤      │      │                                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|       │ Room │      │                                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|       │      ├──────┘                                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|       │      │ Hallway                                   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|       └──────┴──────────────────*                        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   Start                       Goal                       |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| High-level route through environment                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        | Provides reference trajectory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Local Planning:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Input: Global path, Local costmap, Current velocity     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Output: Velocity commands (v, omega)                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Frequency: 10-50 Hz (continuous)                         |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Considers: Nearby obstacles, dynamics, path following    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        | Velocity Commands</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Example Local Planning (DWA):                            |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   Local Costmap (robot-centered):                       |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   ┌─────────────────────┐                               |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │                     │                               |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │     ●               │  ● = Dynamic obstacle (person) |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │                     │  ☐ = Static obstacle          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │           ☐         │  ─ = Global path              |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │        ☐            │  ~ = Local trajectory         |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │    ☐                │                               |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │  ☐   ────────       │                               |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │ ☐  ──────────       │                               |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │☐  ─────────────     │                               |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   │  R ~~~~~~~~~~~      │  R = Robot                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   └─────────────────────┘                               |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Local planner:                                           |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 1. Samples trajectories (velocity commands)              |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 2. Simulates forward to predict paths                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 3. Scores based on: clearance, goal-direction, speed     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 4. Selects best trajectory (~)                           |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 5. Deviates from global path to avoid dynamic obstacle   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        | Motors</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Robot Motion                                             |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Follows global path when obstacles clear               |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Deviates to avoid dynamic obstacles                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Requests replan if global path blocked                 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Key Differences:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Global Planning:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Scope: Entire known map</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Horizon: Start to goal (potentially 10s of meters)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Update Rate: Infrequent (0.5-2 Hz)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Obstacles: Static (from map)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Optimal: Finds near-optimal paths</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Computation: Heavier (100-1000ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Local Planning:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Scope: Local region around robot</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Horizon: Short-term (1-5 seconds ahead)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Update Rate: Frequent (10-50 Hz)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Obstacles: Dynamic (from sensors)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Optimal: Locally optimal, follows global path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Computation: Light (10-50ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Collaboration:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Global provides strategy (route)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Local provides tactics (obstacle avoidance)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Local requests replan when global path invalid</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="costmap-layer-composition">Costmap Layer Composition<a href="#costmap-layer-composition" class="hash-link" aria-label="Direct link to Costmap Layer Composition" title="Direct link to Costmap Layer Composition" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                  Costmap Layer Composition                        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Layer 1: Static Layer (from pre-built map)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                  |    Costs:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ┌──────┐         |      254 = Lethal (obstacle)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| │██████│         |      0   = Free space</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| │██████├───┐     |      255 = Unknown</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| └──────┘   │     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|            │     |    Permanent obstacles (walls)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   ┌────────┴───┐ |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   └────────────┘ |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Layer 2: Obstacle Layer (from sensors)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                  |    Costs:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|         ●        |      254 = Lethal (detected obstacle)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                  |      0   = Free space</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    ●             |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                  |    Dynamic obstacles (people, objects)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                  |    Updated continuously from sensor data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|              ●   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Layer 3: Inflation Layer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                  |    Costs based on distance to obstacles:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ╔══════╗         |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ║██████║         |    ██ = 254 (lethal, at obstacle)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ║██████╠═══╗     |    ══ = 253 (inscribed radius)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ╚══════╝   ║     |    ── = Decreasing cost with distance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ──────────┐║     |    (exponential decay function)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ──┌────────╩═══╗ |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ──└────── ──────║ |    Ensures paths maintain clearance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+──────────────────+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        =</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Final Composed Costmap (max of all layers)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ──────────────── |    Each cell = max(layer1, layer2, layer3)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ╔══════╗─●────── |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ║██████║─●─────  |    Cost value determines planning:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ║██████╠═══╗●──  |      0-252: Traversable (weighted)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ╚══════╝───║●──  |      253: Inscribed (risky)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ──────────┐║●──  |      254: Lethal (avoid)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ──┌────────╩═══╗ |      255: Unknown</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| ──└────────────║ |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+──────────────────+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Planning on Final Costmap:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Path planners avoid lethal (254) cells</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Prefer low-cost cells (far from obstacles)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Balance path length vs. clearance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- A* uses costs to weight edges</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Example path preference:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Path A: Shorter, but near obstacles (higher cost cells)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Path B: Longer, but through free space (low cost cells)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  A* might choose B due to lower total path cost</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="bipedal-footstep-planning">Bipedal Footstep Planning<a href="#bipedal-footstep-planning" class="hash-link" aria-label="Direct link to Bipedal Footstep Planning" title="Direct link to Bipedal Footstep Planning" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                 Bipedal Footstep Planning                         |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Footstep Sequence (overhead view):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                Goal                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                 ↑                        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|              [R8][L8]                    |  L = Left foot</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|              [L7][R7]                    |  R = Right foot</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|              [R6][L6]                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|           [L5][R5]                       |  Numbers = step sequence</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|        [R4][L4]                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|           [L3][R3]                       |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|     [R2][L2]                             |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  [L1][R1]                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  [L0][R0]                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   Start                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Constraints:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Reachability:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   +-------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   | Next step must be |     Step too far</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   | within reachable  |          X</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   | region:           |         /</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |                   |     [Foot]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |     ●─────┐       |     /</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |     │ Max │       |  ○ Reachable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |     │Range│       |  X Unreachable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   |     └─────┘       |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   +-------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Stability (ZMP):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   During single support, ZMP must stay in support foot:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Support foot contact:        ZMP position:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ┌──────────┐                 ┌──────────┐</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   │          │                 │    ●     │  ✓ Stable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   │          │                 │          │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   └──────────┘                 └──────────┘</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ┌──────────┐                 ┌── ────────┐</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   │          │                 │          ● X Unstable (tipping)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   │          │                 │          │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   └──────────┘                 └──────────┘</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Terrain:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Foot must land on stable, flat surface:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Valid:                       Invalid:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ──────────── (flat ground)   ╱╲╱╲╱╲ (uneven)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       [Foot]                       [Foot] (unstable)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Collision-Free:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Swing foot must clear obstacles:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Valid swing:                 Invalid (collision):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ╱──╲                         ╱──╲</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ╱    ╲                       ╱    ╲</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     ┌┘      └┐                   ┌┘      X</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ─┴────────┴─                 ─┴───┌──┴─</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                      │ █ │ (obstacle)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                      └───┘</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Planning Algorithm (Grid-Based A*):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">State: (left_foot_pose, right_foot_pose)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Actions: Step left foot or step right foot to new pose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Cost: Number of steps (or energy)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Example state graph:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            (L0,R0)  [start]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               /\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              /  \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         (L1,R0) (L0,R1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            /\      /\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           /  \    /  \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      (L1,R2)(L3,R0)(L2,R1)(L0,R3)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Search finds lowest-cost footstep sequence to goal region.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Integration with Trajectory Planning:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 1. Footstep Planner                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    → Foot placements [L0,R0,L1,R1,...]   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|         |                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|         v                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 2. Walking Pattern Generator             |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    → Center of Mass trajectory           |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    → ZMP trajectory                      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    → Foot swing trajectories             |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|         |                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|         v                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 3. Whole-Body Controller                 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    → Joint trajectories (inverse kin)    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    → Torque commands (inverse dynamics)  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|         |                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|         v                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 4. Robot Execution                       |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------+</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="reinforcement-learning-navigation-training">Reinforcement Learning Navigation Training<a href="#reinforcement-learning-navigation-training" class="hash-link" aria-label="Direct link to Reinforcement Learning Navigation Training" title="Direct link to Reinforcement Learning Navigation Training" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|      Reinforcement Learning for Navigation Training              |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Training Setup (Isaac Sim):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Parallel Simulation Instances (e.g., 512 environments)   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Instance 0      Instance 1      ...      Instance 511    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +--------+      +--------+              +--------+      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |  Robot |      |  Robot |              |  Robot |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  |   ●─┐  |      |   ●──┐ |              |  ●─┐   |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  | Goal★  |      | Goal ★ |              | Goal★  |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  | ┌──┐   |      |  ┌─┐   |              | ┌───┐  |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  | │  │   |      |  └─┘   |              | │   │  |      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  +--------+      +--------+              +--------+      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  (Random env)   (Random env)            (Random env)     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        | Observations (batched)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Policy Network (GPU)                                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   Input: [depth_image, goal_direction, velocity]         |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   Architecture: CNN + MLP                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   Output: [linear_velocity, angular_velocity]            |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   Processes all 512 observations in parallel (batched)   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        | Actions (batched)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Simulation Step (all instances in parallel)              |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Apply actions to robots                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Step physics (GPU accelerated)                         |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Render depth images (GPU ray tracing)                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Compute rewards                                        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Store transitions (s, a, r, s&#x27;)                        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        | Transitions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Experience Buffer                                        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Stores: (state, action, reward, next_state)              |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Capacity: Last N timesteps (e.g., 1M)                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        | Sample batches</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| RL Algorithm (e.g., PPO)                                 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 1. Compute advantages from collected experience          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 2. Update policy to maximize expected return             |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 3. Update value function to predict returns              |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 4. Clip updates to prevent large policy changes          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        | Updated policy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   (Loop: Collect experience with updated policy, repeat)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Reward Function Example:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| r_total = w1*r_goal + w2*r_collision + w3*r_progress +   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|           w4*r_smoothness                                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                                          |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| r_goal = +10 if goal reached, else 0                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| r_collision = -5 if collision, else 0                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| r_progress = decrease_in_distance_to_goal (continuous)   |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| r_smoothness = -|angular_acceleration| (penalize jerky)  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Domain Randomization (per episode):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Obstacle positions, shapes, quantities                 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Goal positions                                         |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Lighting conditions                                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Floor textures                                         |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Robot dynamics (mass, friction)                        |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| - Sensor noise                                           |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Training Progress:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Episodes:     0       1k      10k      100k     500k</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Avg Reward:  -10     -5       0        +5       +8</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Success %:     5%    20%     50%       80%      95%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Sim-to-Real Transfer:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Simulated Policy                                         |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|        |                                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|        v                                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Domain Randomization (creates robust policy)             |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|        |                                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|        v                                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Deploy to Physical Robot                                 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|        |                                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|        v                                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Evaluate Performance                                     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|        |                                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|        v                                                  |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| (Optional) Fine-tune with real-world data                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+----------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Result: Policy that navigates in diverse environments,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        avoiding obstacles, reaching goals efficiently.</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="knowledge-checkpoint">Knowledge Checkpoint<a href="#knowledge-checkpoint" class="hash-link" aria-label="Direct link to Knowledge Checkpoint" title="Direct link to Knowledge Checkpoint" translate="no">​</a></h2>
<p>Test your understanding of navigation and path planning:</p>
<ol>
<li class="">
<p><strong>Problem Decomposition</strong>: Explain how the navigation problem decomposes into localization, mapping, path planning, and control. How do these subproblems interact?</p>
</li>
<li class="">
<p><strong>Costmaps</strong>: Describe the purpose and structure of costmaps in navigation. What are the different layers, and how do they combine to produce a final costmap?</p>
</li>
<li class="">
<p><strong>Global vs. Local Planning</strong>: Compare global and local planning approaches. What are their different roles, update frequencies, and computational characteristics?</p>
</li>
<li class="">
<p><em><em>A</em> Algorithm</em>*: Explain how A* finds optimal paths. What role does the heuristic function play, and what properties must it have to guarantee optimality?</p>
</li>
<li class="">
<p><strong>Behavior Trees</strong>: Describe how behavior trees coordinate navigation behaviors. What advantages do behavior trees offer over finite state machines for navigation?</p>
</li>
<li class="">
<p><strong>RRT vs. A</strong>*: Compare RRT and A* path planning algorithms. When is each preferable, and what are their computational trade-offs?</p>
</li>
<li class="">
<p><strong>DWA Local Planning</strong>: Explain how Dynamic Window Approach generates velocity commands. What factors does it consider when evaluating candidate trajectories?</p>
</li>
<li class="">
<p><strong>Bipedal Stability</strong>: Explain the Zero Moment Point (ZMP) criterion for bipedal stability. How does ZMP relate to the support polygon, and why is it important for footstep planning?</p>
</li>
<li class="">
<p><strong>Recovery Behaviors</strong>: Why are recovery behaviors necessary in autonomous navigation? Give examples of recovery behaviors and explain when each should be used.</p>
</li>
<li class="">
<p><strong>RL for Navigation</strong>: Describe how reinforcement learning can learn navigation policies. What are the advantages and challenges compared to classical planning approaches?</p>
</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="chapter-summary">Chapter Summary<a href="#chapter-summary" class="hash-link" aria-label="Direct link to Chapter Summary" title="Direct link to Chapter Summary" translate="no">​</a></h2>
<p>Autonomous navigation enables mobile robots to move purposefully through environments, combining perception, planning, and control into integrated systems. The navigation problem decomposes into localization (where am I?), mapping (what&#x27;s around me?), path planning (how do I get there?), and control (how do I execute the plan?).</p>
<p>Costmaps provide a unified representation for navigation constraints, integrating static obstacles from maps, dynamic obstacles from sensors, and inflation for safety margins. Layered composition allows flexible integration of diverse constraints.</p>
<p>Nav2 provides a comprehensive navigation framework for ROS 2, using behavior trees to coordinate planning, control, and recovery behaviors. Its plugin architecture enables customization for different robots and applications while providing robust, battle-tested navigation capabilities.</p>
<p>Path planning algorithms find collision-free paths through environments. A* efficiently finds optimal paths on graphs using heuristics to guide search. Dijkstra&#x27;s algorithm finds shortest paths to all locations. RRT samples configuration space to build trees connecting start and goal, excelling in high-dimensional spaces. Hybrid A* and state lattice planning respect kinematic constraints, producing feasible paths for nonholonomic robots.</p>
<p>Global and local planning collaborate to provide strategic routing and tactical obstacle avoidance. Global planners find routes through known maps; local planners execute motion while avoiding dynamic obstacles. Dynamic Window Approach, Timed Elastic Band, and Model Predictive Control represent different local planning philosophies, balancing computational efficiency, path quality, and constraint handling.</p>
<p>For bipedal robots, navigation requires additional complexity. Footstep planning determines where to place each foot while respecting reachability, stability (ZMP criterion), and terrain constraints. Integration with whole-body control enables humanoid robots to navigate complex environments.</p>
<p>Recovery behaviors handle situations where forward progress fails. Clearing costmaps, rotating, backing up, and waiting provide escalating recovery strategies coordinated through behavior trees.</p>
<p>Reinforcement learning offers an alternative to classical planning, learning navigation policies directly from interaction. Training in Isaac Sim with domain randomization enables learning robust policies that transfer to physical robots. Hybrid approaches combining classical planning with learned components may provide the best of both worlds.</p>
<p>Understanding navigation and path planning completes the picture of physical AI development with the Isaac platform. Simulation (Chapter 8) provides training environments and synthetic data. Hardware-accelerated perception (Chapter 9) enables real-time environmental understanding. Navigation (this chapter) integrates perception with planning and control to enable autonomous operation. Together, these capabilities enable robots to perceive, plan, and act in complex, dynamic environments.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="further-reading">Further Reading<a href="#further-reading" class="hash-link" aria-label="Direct link to Further Reading" title="Direct link to Further Reading" translate="no">​</a></h2>
<p><strong>Navigation Frameworks</strong>:</p>
<ul>
<li class="">Nav2 Documentation: Official ROS 2 navigation stack documentation</li>
<li class="">&quot;Navigation2: Mobile Robot Navigation&quot; (tutorial series)</li>
<li class="">Nav2 Behavior Tree XML Specification</li>
</ul>
<p><strong>Path Planning Algorithms</strong>:</p>
<ul>
<li class="">&quot;Principles of Robot Motion&quot; (Choset et al.): Comprehensive motion planning textbook</li>
<li class="">&quot;Planning Algorithms&quot; (LaValle): Free online book covering planning theory</li>
<li class="">&quot;A* Algorithm&quot; (Hart, Nilsson, Raphael): Original A* paper</li>
</ul>
<p><strong>Sampling-Based Planning</strong>:</p>
<ul>
<li class="">&quot;Rapidly-Exploring Random Trees&quot; (LaValle): Original RRT paper</li>
<li class="">&quot;Sampling-based Algorithms for Optimal Motion Planning&quot; (Karaman, Frazzoli): RRT* optimality</li>
<li class="">&quot;Kinodynamic RRT*&quot;: Planning with dynamics constraints</li>
</ul>
<p><strong>Local Planning and Control</strong>:</p>
<ul>
<li class="">&quot;The Dynamic Window Approach to Collision Avoidance&quot; (Fox et al.): DWA algorithm</li>
<li class="">&quot;Timed Elastic Bands for Time-Optimal Point-to-Point Nonlinear Model Predictive Control&quot; (Rösmann et al.): TEB planner</li>
<li class="">&quot;Model Predictive Control for Mobile Robots&quot; (survey paper)</li>
</ul>
<p><strong>Behavior Trees</strong>:</p>
<ul>
<li class="">&quot;Behavior Trees in Robotics and AI&quot; (Colledanchise, Ögren): Comprehensive behavior tree book</li>
<li class="">&quot;How Behavior Trees Modularize Hybrid Control Systems&quot; (original paper)</li>
<li class="">BehaviorTree.CPP documentation: Popular C++ BT library</li>
</ul>
<p><strong>Bipedal Locomotion</strong>:</p>
<ul>
<li class="">&quot;Biped Locomotion Control&quot; (Kajita et al.): ZMP-based walking control</li>
<li class="">&quot;Introduction to Humanoid Robotics&quot; (Kajita et al.): Comprehensive humanoid robotics</li>
<li class="">&quot;Footstep Planning for Biped Robots&quot; (survey paper)</li>
</ul>
<p><strong>Reinforcement Learning for Navigation</strong>:</p>
<ul>
<li class="">&quot;Learning to Navigate in Complex Environments&quot; (Mirowski et al., DeepMind): Deep RL navigation</li>
<li class="">&quot;Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics&quot; (survey paper)</li>
<li class="">&quot;Learning Agile and Dynamic Motor Skills for Legged Robots&quot; (recent RL locomotion work)</li>
</ul>
<p><strong>Costmaps and Representations</strong>:</p>
<ul>
<li class="">costmap_2d ROS Package Documentation: Implementation details</li>
<li class="">&quot;Occupancy Grid Mapping&quot; (Thrun et al.): Grid-based environment representation</li>
<li class="">&quot;3D Mapping for Navigation&quot; (survey paper)</li>
</ul>
<p><strong>Classical Navigation</strong>:</p>
<ul>
<li class="">&quot;Probabilistic Robotics&quot; (Thrun, Burgard, Fox): Foundational robotics textbook</li>
<li class="">&quot;Introduction to Autonomous Mobile Robots&quot; (Siegwart, Nourbakhsh): Comprehensive mobile robotics</li>
<li class="">Vector Field Histogram paper: VFH obstacle avoidance</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="looking-ahead">Looking Ahead<a href="#looking-ahead" class="hash-link" aria-label="Direct link to Looking Ahead" title="Direct link to Looking Ahead" translate="no">​</a></h2>
<p>This chapter completes our exploration of the NVIDIA Isaac ecosystem for physical AI development. We&#x27;ve progressed from simulation foundations (Chapter 8), through hardware-accelerated perception (Chapter 9), to navigation and planning (this chapter). This progression mirrors the actual development workflow: simulate environments, perceive surroundings, plan actions.</p>
<p>The integration of these components enables complete autonomous systems. Simulation in Isaac Sim provides photorealistic training environments with accurate physics, sensor simulation, and domain randomization. Synthetic data generation creates unlimited labeled training data for perception models.</p>
<p>Hardware-accelerated perception with Isaac ROS processes sensor streams in real-time using GPU parallelization and zero-copy communication. Visual SLAM, stereo depth, object detection, and semantic segmentation provide environmental understanding with minimal latency.</p>
<p>Navigation systems combine this perceptual information with planning and control. Global planners find strategic routes; local planners execute tactical obstacle avoidance. Behavior trees coordinate complex autonomous behaviors with recovery strategies for failure handling.</p>
<p>For humanoid robots, these challenges intensify. Bipedal locomotion requires maintaining dynamic balance while navigating. Footstep planning determines stable foot placements. Whole-body control coordinates many degrees of freedom. The full stack—from simulation through perception to locomotion control—must work together seamlessly.</p>
<p>Looking forward, several frontiers remain active research areas:</p>
<p><strong>Learning-Based Navigation</strong>: Reinforcement learning and imitation learning can learn navigation policies from experience, potentially discovering strategies not obvious to human designers. Combining learned and classical components may provide optimal performance.</p>
<p><strong>Long-Horizon Autonomy</strong>: Current systems handle navigation tasks lasting minutes to hours. Truly autonomous systems must operate for days or weeks, handling failures, adapting to environmental changes, and managing resources.</p>
<p><strong>Social Navigation</strong>: As robots operate in human-populated environments, navigation must respect social norms—maintaining appropriate distances, yielding right-of-way, and predicting human motion.</p>
<p><strong>Terrain Adaptation</strong>: Most current navigation assumes flat, stable terrain. Humanoid robots navigating real-world environments encounter stairs, slopes, uneven surfaces, and compliant ground requiring adaptation.</p>
<p><strong>Manipulation During Navigation</strong>: Mobile manipulation combines navigation with object interaction. Robots might carry objects, open doors, or manipulate the environment to enable passage.</p>
<p>The Isaac platform provides the foundation for addressing these challenges. Its simulation capabilities enable training and testing in diverse scenarios. Hardware acceleration enables real-time perception and planning. Integration with ROS 2 allows leveraging the broader robotics ecosystem.</p>
<p>By mastering the concepts in these chapters—simulation, perception, and navigation—you&#x27;re equipped to develop physical AI systems capable of autonomous operation in complex, dynamic environments. The future of robotics lies in systems that seamlessly integrate these capabilities, enabling robots to assist humans in homes, workplaces, and beyond.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-09-isaac-ros-hardware-accelerated-perception"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Chapter 9: Isaac ROS - Hardware-Accelerated Perception</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-11-humanoid-robot-kinematics-and-dynamics"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Chapter 11: Humanoid Robot Kinematics and Dynamics</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#core-concepts" class="table-of-contents__link toc-highlight">Core Concepts</a><ul><li><a href="#the-navigation-problem-formulation" class="table-of-contents__link toc-highlight">The Navigation Problem Formulation</a></li><li><a href="#costmaps-representing-navigation-constraints" class="table-of-contents__link toc-highlight">Costmaps: Representing Navigation Constraints</a></li><li><a href="#global-vs-local-planning" class="table-of-contents__link toc-highlight">Global vs. Local Planning</a></li><li><a href="#the-nav2-navigation-stack" class="table-of-contents__link toc-highlight">The Nav2 Navigation Stack</a></li><li><a href="#behavior-trees-for-navigation" class="table-of-contents__link toc-highlight">Behavior Trees for Navigation</a></li><li><a href="#motion-constraints-and-kinematic-models" class="table-of-contents__link toc-highlight">Motion Constraints and Kinematic Models</a></li><li><a href="#path-smoothness-and-optimality-criteria" class="table-of-contents__link toc-highlight">Path Smoothness and Optimality Criteria</a></li></ul></li><li><a href="#practical-understanding" class="table-of-contents__link toc-highlight">Practical Understanding</a><ul><li><a href="#a-a-star-path-planning" class="table-of-contents__link toc-highlight">A* (A-Star) Path Planning</a></li><li><a href="#dijkstras-algorithm" class="table-of-contents__link toc-highlight">Dijkstra&#39;s Algorithm</a></li><li><a href="#rrt-rapidly-exploring-random-tree" class="table-of-contents__link toc-highlight">RRT (Rapidly-Exploring Random Tree)</a></li><li><a href="#hybrid-a-and-state-lattice-planning" class="table-of-contents__link toc-highlight">Hybrid A* and State Lattice Planning</a></li><li><a href="#local-planning-and-trajectory-optimization" class="table-of-contents__link toc-highlight">Local Planning and Trajectory Optimization</a></li><li><a href="#bipedal-locomotion-and-footstep-planning" class="table-of-contents__link toc-highlight">Bipedal Locomotion and Footstep Planning</a></li><li><a href="#obstacle-avoidance-strategies" class="table-of-contents__link toc-highlight">Obstacle Avoidance Strategies</a></li><li><a href="#recovery-behaviors" class="table-of-contents__link toc-highlight">Recovery Behaviors</a></li><li><a href="#reinforcement-learning-for-navigation" class="table-of-contents__link toc-highlight">Reinforcement Learning for Navigation</a></li></ul></li><li><a href="#conceptual-diagrams" class="table-of-contents__link toc-highlight">Conceptual Diagrams</a><ul><li><a href="#nav2-architecture" class="table-of-contents__link toc-highlight">Nav2 Architecture</a></li><li><a href="#behavior-tree-for-navigation" class="table-of-contents__link toc-highlight">Behavior Tree for Navigation</a></li><li><a href="#a-path-planning-visualization" class="table-of-contents__link toc-highlight">A* Path Planning Visualization</a></li><li><a href="#global-vs-local-planning-interaction" class="table-of-contents__link toc-highlight">Global vs. Local Planning Interaction</a></li><li><a href="#costmap-layer-composition" class="table-of-contents__link toc-highlight">Costmap Layer Composition</a></li><li><a href="#bipedal-footstep-planning" class="table-of-contents__link toc-highlight">Bipedal Footstep Planning</a></li><li><a href="#reinforcement-learning-navigation-training" class="table-of-contents__link toc-highlight">Reinforcement Learning Navigation Training</a></li></ul></li><li><a href="#knowledge-checkpoint" class="table-of-contents__link toc-highlight">Knowledge Checkpoint</a></li><li><a href="#chapter-summary" class="table-of-contents__link toc-highlight">Chapter Summary</a></li><li><a href="#further-reading" class="table-of-contents__link toc-highlight">Further Reading</a></li><li><a href="#looking-ahead" class="table-of-contents__link toc-highlight">Looking Ahead</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Course</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Physical-AI-Humanoid-Robotics/">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/Physical-AI-Humanoid-Robotics/chapters/chapter-01-introduction-to-physical-ai">Foundations</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://panaversity.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Panaversity<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://docs.ros.org/en/humble/" target="_blank" rel="noopener noreferrer" class="footer__link-item">ROS 2 Documentation<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://developer.nvidia.com/isaac-ros" target="_blank" rel="noopener noreferrer" class="footer__link-item">NVIDIA Isaac<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/muskaanfayyaz/Physical-AI-Humanoid-Robotics" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Panaversity. Built with Docusaurus.</div></div></div></footer><button class="rag-chatbot-toggle" aria-label="Toggle chatbot">  💬</button></div>
</body>
</html>